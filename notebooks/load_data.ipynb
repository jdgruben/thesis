{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c3ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Datasets directory ready at: datasets\n",
      "Raw datasets directory ready at: raw_datasets\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import gdown\n",
    "\n",
    "# Create datasets and raw_datasets folders if they don't exist\n",
    "datasets_dir = Path('datasets')\n",
    "raw_datasets_dir = Path('raw_datasets')\n",
    "datasets_dir.mkdir(exist_ok=True)\n",
    "raw_datasets_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Setup complete. Datasets directory ready at: {datasets_dir}\")\n",
    "print(f\"Raw datasets directory ready at: {raw_datasets_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p3w9f1kbuoi",
   "metadata": {},
   "source": [
    "## 1. Load FILOSOFI Datasets (2013, 2017, 2021)\n",
    "FILOSOFI datasets contain income and living standards data at IRIS level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bpra809573q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1fRbArcfw_DHrycI11NsjbosnXCp6Nh26\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2013.xlsx\n",
      "100%|██████████| 5.04M/5.04M [00:00<00:00, 99.3MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6013', 'DISP_Q113', 'DISP_MED13', 'DISP_Q313', 'DISP_EQ13', 'DISP_D113', 'DISP_D213', 'DISP_D313', 'DISP_D413', 'DISP_D613', 'DISP_D713', 'DISP_D813', 'DISP_D913', 'DISP_RD13', 'DISP_S80S2013', 'DISP_GI13', 'DISP_PTSAC13', 'DISP_PBEN13', 'DISP_PPEN13', 'DISP_PPAT13', 'DISP_PPSOC13', 'DISP_PPFAM13', 'DISP_PPMINI13', 'DISP_PPLOGT13', 'DISP_PIMPOT13']\n",
      "FILOSOFI 2013: 853 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc', 'q1_uc', 'q3_uc', 'd9d1_ratio', 'gini', 'share_pensions', 'share_social_benefits']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2013\n",
    "print(\"Loading FILOSOFI 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1fRbArcfw_DHrycI11NsjbosnXCp6Nh26'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2013.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED13': 'median_uc',\n",
    "    'DISP_Q113': 'q1_uc',\n",
    "    'DISP_Q313': 'q3_uc',\n",
    "    'DISP_RD13': 'd9d1_ratio',\n",
    "    'DISP_GI13': 'gini',\n",
    "    'DISP_PACT13': 'share_activity_income',\n",
    "    'DISP_PPEN13': 'share_pensions',\n",
    "    'DISP_PPSOC13': 'share_social_benefits',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros (département 75)\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2013_paris = filosofi_2013[filosofi_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2013_paris.columns]\n",
    "filosofi_2013_paris = filosofi_2013_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2013_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2013_paris.to_parquet(datasets_dir / 'filosofi_2013_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2013: {len(filosofi_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "w0huionnxs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1IhvzpWGInGlDj7Xpi4kHP87msylR7hiQ\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2017.xlsx\n",
      "100%|██████████| 2.76M/2.76M [00:00<00:00, 81.2MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6017', 'DISP_Q117', 'DISP_MED17', 'DISP_Q317', 'DISP_EQ17', 'DISP_D117', 'DISP_D217', 'DISP_D317', 'DISP_D417', 'DISP_D617', 'DISP_D717', 'DISP_D817', 'DISP_D917', 'DISP_RD17', 'DISP_S80S2017', 'DISP_GI17', 'DISP_PACT17', 'DISP_PTSA17', 'DISP_PCHO17', 'DISP_PBEN17', 'DISP_PPEN17', 'DISP_PPAT17', 'DISP_PPSOC17', 'DISP_PPFAM17', 'DISP_PPMINI17', 'DISP_PPLOGT17', 'DISP_PIMPOT17', 'DISP_NOTE17']\n",
      "FILOSOFI 2017: 871 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc', 'q1_uc', 'q3_uc', 'd9d1_ratio', 'gini', 'share_activity_income', 'share_pensions', 'share_social_benefits']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2017\n",
    "print(\"Loading FILOSOFI 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1IhvzpWGInGlDj7Xpi4kHP87msylR7hiQ'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2017.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED17': 'median_uc',\n",
    "    'DISP_Q117': 'q1_uc',\n",
    "    'DISP_Q317': 'q3_uc',\n",
    "    'DISP_RD17': 'd9d1_ratio',\n",
    "    'DISP_GI17': 'gini',\n",
    "    'DISP_PACT17': 'share_activity_income',\n",
    "    'DISP_PPEN17': 'share_pensions',\n",
    "    'DISP_PPSOC17': 'share_social_benefits',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2017_paris = filosofi_2017[filosofi_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2017_paris.columns]\n",
    "filosofi_2017_paris = filosofi_2017_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2017_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2017_paris.to_parquet(datasets_dir / 'filosofi_2017_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2017: {len(filosofi_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hvqfjbnda9g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Har2wCg63dQZSTWYxmyXQ0DcQ0dHylX8\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2021.xlsx\n",
      "100%|██████████| 2.82M/2.82M [00:00<00:00, 72.7MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6021', 'DISP_INCERT21', 'DISP_Q121', 'DISP_MED21', 'DISP_Q321', 'DISP_EQ21', 'DISP_D121', 'DISP_D221', 'DISP_D321', 'DISP_D421', 'DISP_D621', 'DISP_D721', 'DISP_D821', 'DISP_D921', 'DISP_RD21', 'DISP_S80S2021', 'DISP_GI21', 'DISP_PACT21', 'DISP_PTSA21', 'DISP_PCHO21', 'DISP_PBEN21', 'DISP_PPEN21', 'DISP_PPAT21', 'DISP_PPSOC21', 'DISP_PPFAM21', 'DISP_PPMINI21', 'DISP_PPLOGT21', 'DISP_PIMPOT21', 'DISP_NOTE21']\n",
      "FILOSOFI 2021: 992 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc', 'q1_uc', 'q3_uc', 'd9d1_ratio', 'gini', 'share_activity_income', 'share_pensions', 'share_social_benefits']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2021\n",
    "print(\"Loading FILOSOFI 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1Har2wCg63dQZSTWYxmyXQ0DcQ0dHylX8'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2021.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED21': 'median_uc',\n",
    "    'DISP_Q121': 'q1_uc',\n",
    "    'DISP_Q321': 'q3_uc',\n",
    "    'DISP_RD21': 'd9d1_ratio',\n",
    "    'DISP_GI21': 'gini',\n",
    "    'DISP_PACT21': 'share_activity_income',\n",
    "    'DISP_PPEN21': 'share_pensions',\n",
    "    'DISP_PPSOC21': 'share_social_benefits',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2021_paris = filosofi_2021[filosofi_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2021_paris.columns]\n",
    "filosofi_2021_paris = filosofi_2021_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2021_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2021_paris.to_parquet(datasets_dir / 'filosofi_2021_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2021: {len(filosofi_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ukcqdhd3j",
   "metadata": {},
   "source": [
    "## 2. Load CENSUS Datasets (2013, 2017, 2021)\n",
    "Census datasets contain population structure and evolution data at IRIS level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "w3y327puth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1b2LTSza0fRFkuVnvni60cKWKi51g3BQh\n",
      "To: /workspaces/thesis/raw_datasets/census_2013.xlsx\n",
      "100%|██████████| 70.7M/70.7M [00:00<00:00, 171MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2013: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2013\n",
    "print(\"Loading CENSUS 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1b2LTSza0fRFkuVnvni60cKWKi51g3BQh'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2013.columns if 'IRIS' in col.upper()][0]\n",
    "census_2013_paris = census_2013[census_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P13_POP': 'pop_total',\n",
    "    'C13_POP15P': 'pop_15plus',\n",
    "    'C13_POP15P_CS3': 'pop_cadres',\n",
    "    'C13_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C13_POP15P_CS5': 'pop_employes',\n",
    "    'C13_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P13_POP1824': 'pop_18_24',\n",
    "    'P13_POP2539': 'pop_25_39',\n",
    "    'P13_POP65P': 'pop_65plus',\n",
    "    'P13_POP_IMM': 'pop_immigres',\n",
    "    'P13_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2013_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2013_paris = census_2013_paris[cols_to_keep].copy()\n",
    "census_2013_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "census_2013_paris.to_parquet(datasets_dir / 'census_2013_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2013: {len(census_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2jpiae70h58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1KHGwB0S8D-gj7f3d3LBCzRjqBWxaewzw\n",
      "To: /workspaces/thesis/raw_datasets/census_2017.xlsx\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 59.0MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2017: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2017\n",
    "print(\"Loading CENSUS 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1KHGwB0S8D-gj7f3d3LBCzRjqBWxaewzw'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2017.columns if 'IRIS' in col.upper()][0]\n",
    "census_2017_paris = census_2017[census_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables (2017 uses P17_ prefix)\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P17_POP': 'pop_total',\n",
    "    'C17_POP15P': 'pop_15plus',\n",
    "    'C17_POP15P_CS3': 'pop_cadres',\n",
    "    'C17_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C17_POP15P_CS5': 'pop_employes',\n",
    "    'C17_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P17_POP1824': 'pop_18_24',\n",
    "    'P17_POP2539': 'pop_25_39',\n",
    "    'P17_POP65P': 'pop_65plus',\n",
    "    'P17_POP_IMM': 'pop_immigres',\n",
    "    'P17_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2017_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2017_paris = census_2017_paris[cols_to_keep].copy()\n",
    "census_2017_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "census_2017_paris.to_parquet(datasets_dir / 'census_2017_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2017: {len(census_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adem7qp2of4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yfZ3EYbtnDaRhDWvP_u8ovC6HwQNuq9s\n",
      "To: /workspaces/thesis/raw_datasets/census_2021.xlsx\n",
      "100%|██████████| 49.7M/49.7M [00:00<00:00, 77.5MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2021: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2021\n",
    "print(\"Loading CENSUS 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1yfZ3EYbtnDaRhDWvP_u8ovC6HwQNuq9s'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2021.columns if 'IRIS' in col.upper()][0]\n",
    "census_2021_paris = census_2021[census_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables (2021 uses P21_ prefix)\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P21_POP': 'pop_total',\n",
    "    'C21_POP15P': 'pop_15plus',\n",
    "    'C21_POP15P_CS3': 'pop_cadres',\n",
    "    'C21_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C21_POP15P_CS5': 'pop_employes',\n",
    "    'C21_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P21_POP1824': 'pop_18_24',\n",
    "    'P21_POP2539': 'pop_25_39',\n",
    "    'P21_POP65P': 'pop_65plus',\n",
    "    'P21_POP_IMM': 'pop_immigres',\n",
    "    'P21_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2021_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2021_paris = census_2021_paris[cols_to_keep].copy()\n",
    "census_2021_paris.columns = final_names\n",
    "\n",
    "# Save to data folder\n",
    "census_2021_paris.to_parquet(datasets_dir / 'census_2021_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2021: {len(census_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u7o4zrdrvym",
   "metadata": {},
   "source": [
    "## 3. Load DVF Mutations Dataset\n",
    "Real estate transaction data (Demandes de Valeurs Foncières)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a7888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DVF Mutations dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN\n",
      "From (redirected): https://drive.google.com/uc?id=1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN&confirm=t&uuid=6b49dc48-4859-4688-93b2-b072997f9d72\n",
      "To: /workspaces/thesis/raw_datasets/dvf_mutations.gpkg\n",
      "100%|██████████| 358M/358M [00:02<00:00, 134MB/s]  \n",
      "\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pyogrio/geopandas.py:275: UserWarning: More than one layer found in 'dvf_mutations.gpkg': 'mutation_geompar' (default), 'mutation_geomparmut', 'mutation_geomlocmut'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pyogrio/geopandas.py:275: UserWarning: More than one layer found in 'dvf_mutations.gpkg': 'mutation_geompar' (default), 'mutation_geomparmut', 'mutation_geomlocmut'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVF Mutations: 457097 transactions in Paris saved\n",
      "Columns: ['datemut', 'anneemut', 'moismut', 'coddep', 'l_codinsee', 'valeurfonc', 'libtypbien', 'codtypbien', 'sbati', 'nblot', 'nbapt1pp', 'nbapt2pp', 'nbapt3pp', 'nbapt4pp', 'nbapt5pp', 'nbmai1pp', 'nbmai2pp', 'nbmai3pp', 'nbmai4pp', 'nbmai5pp']\n"
     ]
    }
   ],
   "source": [
    "# DVF Mutations - Download from Google Drive using gdown\n",
    "# File ID: 1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN\n",
    "print(\"Loading DVF Mutations dataset...\")\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# Download file\n",
    "file_id = '1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'dvf_mutations.gpkg'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "# Read and filter\n",
    "dvf_mutations = gpd.read_file(raw_file)\n",
    "dvf_mutations_paris = dvf_mutations[dvf_mutations['coddep'] == '75'].copy()\n",
    "\n",
    "# Keep only selected columns\n",
    "columns_to_keep = [\n",
    "    'datemut', 'anneemut', 'moismut',  # temporal\n",
    "    'coddep', 'l_codinsee',  # spatial\n",
    "    'valeurfonc',  # transaction value\n",
    "    'libtypbien', 'codtypbien',  # property type\n",
    "    'sbati',  # built surface\n",
    "    'nblot',  # lot characteristics\n",
    "    'nbapt1pp', 'nbapt2pp', 'nbapt3pp', 'nbapt4pp', 'nbapt5pp',  # apartments\n",
    "    'nbmai1pp', 'nbmai2pp', 'nbmai3pp', 'nbmai4pp', 'nbmai5pp'   # houses\n",
    "]\n",
    "\n",
    "# Only keep columns that exist\n",
    "existing_columns = [col for col in columns_to_keep if col in dvf_mutations_paris.columns]\n",
    "dvf_mutations_paris = dvf_mutations_paris[existing_columns].copy()\n",
    "\n",
    "# Save to parquet\n",
    "dvf_mutations_paris.to_parquet(datasets_dir / 'dvf_mutations_paris.parquet', index=False)\n",
    "print(f\"DVF Mutations: {len(dvf_mutations_paris)} transactions in Paris saved\")\n",
    "print(f\"Columns: {list(dvf_mutations_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aydqi2eol3",
   "metadata": {},
   "source": [
    "## 4. Load GEOFABRIK OSM Data\n",
    "OpenStreetMap data for Île-de-France region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "zl82496vf3o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GEOFABRIK OSM data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=10tnwqygnWErQRLZ__J6u2ez4Ct7qx_qo\n",
      "From (redirected): https://drive.google.com/uc?id=10tnwqygnWErQRLZ__J6u2ez4Ct7qx_qo&confirm=t&uuid=5a7e4507-a54e-43be-9104-cd47f6600d14\n",
      "To: /workspaces/thesis/raw_datasets/geofabrik_idf.osm.pbf\n",
      "100%|██████████| 324M/324M [00:02<00:00, 116MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOFABRIK OSM data downloaded to raw_datasets/geofabrik_idf.osm.pbf\n",
      "Note: This OSM file covers Île-de-France and includes Paris. Use osmium or other tools to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# GEOFABRIK Île-de-France OSM data\n",
    "print(\"Loading GEOFABRIK OSM data...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '10tnwqygnWErQRLZ__J6u2ez4Ct7qx_qo'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'geofabrik_idf.osm.pbf'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "print(f\"GEOFABRIK OSM data downloaded to {raw_file}\")\n",
    "print(\"Note: This OSM file covers Île-de-France and includes Paris. Use osmium or other tools to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s7uqc2xy30p",
   "metadata": {},
   "source": [
    "## 5. Load IRIS GeoJSON\n",
    "Geographic boundaries for IRIS zones in France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qu2zsga8psj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IRIS GeoJSON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yWwsp5LcykD5UtvVPj_S695ALSKsCskP\n",
      "To: /workspaces/thesis/raw_datasets/iris.geojson\n",
      "100%|██████████| 11.6M/11.6M [00:00<00:00, 106MB/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS GeoJSON: 25 IRIS zones in Paris saved\n",
      "Columns: ['dep', 'insee_com', 'nom_com', 'iris', 'code_iris', 'nom_iris', 'typ_iris', 'geo_point_2d', 'id', 'geometry']\n"
     ]
    }
   ],
   "source": [
    "# IRIS GeoJSON - Geographic boundaries\n",
    "print(\"Loading IRIS GeoJSON...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1yWwsp5LcykD5UtvVPj_S695ALSKsCskP'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'iris.geojson'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "iris_geo = gpd.read_file(raw_file)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in iris_geo.columns if 'iris' in col.lower() or 'code' in col.lower()][0]\n",
    "iris_geo_paris = iris_geo[iris_geo[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Save to datasets folder\n",
    "iris_geo_paris.to_file(datasets_dir / 'iris_paris.geojson', driver='GeoJSON')\n",
    "print(f\"IRIS GeoJSON: {len(iris_geo_paris)} IRIS zones in Paris saved\")\n",
    "print(f\"Columns: {list(iris_geo_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l2iykkxhu5h",
   "metadata": {},
   "source": [
    "## 6. Load Sirene Business Establishment Dataset\n",
    "Business establishment data from 2014 to 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7v0v9uhu27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sirene dataset (this may take a while, it's a large file)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Jh9vcCnblxJxbuMTrqxuyR1PPo1dkrBo\n",
      "From (redirected): https://drive.google.com/uc?id=1Jh9vcCnblxJxbuMTrqxuyR1PPo1dkrBo&confirm=t&uuid=6e5ab5a7-f505-48e4-a0dd-28cd2e161e8f\n",
      "To: /workspaces/thesis/raw_datasets/sirene.parquet\n",
      "100%|██████████| 2.14G/2.14G [00:35<00:00, 59.9MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Sirene data in batches to handle large file size...\n",
      "Parquet file has 338 row groups\n",
      "Available columns in Sirene: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n",
      "Processing row group 1/338...\n",
      "Parquet file has 338 row groups\n",
      "Available columns in Sirene: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n",
      "Processing row group 1/338...\n",
      "Processing row group 2/338...\n",
      "Processing row group 3/338...\n",
      "Processing row group 2/338...\n",
      "Processing row group 3/338...\n",
      "Processing row group 4/338...\n",
      "Processing row group 5/338...\n",
      "Processing row group 4/338...\n",
      "Processing row group 5/338...\n",
      "Processing row group 6/338...\n",
      "Processing row group 7/338...\n",
      "Processing row group 6/338...\n",
      "Processing row group 7/338...\n",
      "Processing row group 8/338...\n",
      "Processing row group 9/338...\n",
      "Processing row group 8/338...\n",
      "Processing row group 9/338...\n",
      "Processing row group 10/338...\n",
      "Processing row group 11/338...\n",
      "Processing row group 10/338...\n",
      "Processing row group 11/338...\n",
      "Processing row group 12/338...\n",
      "Processing row group 13/338...\n",
      "Processing row group 12/338...\n",
      "Processing row group 13/338...\n",
      "Processing row group 14/338...\n",
      "Processing row group 15/338...\n",
      "Processing row group 14/338...\n",
      "Processing row group 15/338...\n",
      "Processing row group 16/338...\n",
      "Processing row group 16/338...\n",
      "Processing row group 17/338...\n",
      "Processing row group 17/338...\n",
      "Processing row group 18/338...\n",
      "Processing row group 18/338...\n",
      "Processing row group 19/338...\n",
      "Processing row group 19/338...\n",
      "Processing row group 20/338...\n",
      "Processing row group 20/338...\n",
      "Processing row group 21/338...\n",
      "Processing row group 21/338...\n",
      "Processing row group 22/338...\n",
      "Processing row group 22/338...\n",
      "Processing row group 23/338...\n",
      "Processing row group 23/338...\n",
      "Processing row group 24/338...\n",
      "Processing row group 24/338...\n",
      "Processing row group 25/338...\n",
      "Processing row group 25/338...\n",
      "Processing row group 26/338...\n",
      "Processing row group 26/338...\n",
      "Processing row group 27/338...\n",
      "Processing row group 27/338...\n",
      "Processing row group 28/338...\n",
      "Processing row group 28/338...\n",
      "Processing row group 29/338...\n",
      "Processing row group 29/338...\n",
      "Processing row group 30/338...\n",
      "Processing row group 30/338...\n",
      "Processing row group 31/338...\n",
      "Processing row group 31/338...\n",
      "Processing row group 32/338...\n",
      "Processing row group 32/338...\n",
      "Processing row group 33/338...\n",
      "Processing row group 33/338...\n",
      "Processing row group 34/338...\n",
      "Processing row group 34/338...\n",
      "Processing row group 35/338...\n",
      "Processing row group 35/338...\n",
      "Processing row group 36/338...\n",
      "Processing row group 36/338...\n",
      "Processing row group 37/338...\n",
      "Processing row group 37/338...\n",
      "Processing row group 38/338...\n",
      "Processing row group 38/338...\n",
      "Processing row group 39/338...\n",
      "Processing row group 39/338...\n",
      "Processing row group 40/338...\n",
      "Processing row group 40/338...\n",
      "Processing row group 41/338...\n",
      "Processing row group 41/338...\n",
      "Processing row group 42/338...\n",
      "Processing row group 42/338...\n",
      "Processing row group 43/338...\n",
      "Processing row group 43/338...\n",
      "Processing row group 44/338...\n",
      "Processing row group 44/338...\n",
      "Processing row group 45/338...\n",
      "Processing row group 45/338...\n",
      "Processing row group 46/338...\n",
      "Processing row group 46/338...\n",
      "Processing row group 47/338...\n",
      "Processing row group 47/338...\n",
      "Processing row group 48/338...\n",
      "Processing row group 48/338...\n",
      "Processing row group 49/338...\n",
      "Processing row group 49/338...\n",
      "Processing row group 50/338...\n",
      "Processing row group 50/338...\n",
      "Processing row group 51/338...\n",
      "Processing row group 51/338...\n",
      "Processing row group 52/338...\n",
      "Processing row group 52/338...\n",
      "Processing row group 53/338...\n",
      "Processing row group 54/338...\n",
      "Processing row group 53/338...\n",
      "Processing row group 54/338...\n",
      "Processing row group 55/338...\n",
      "Processing row group 55/338...\n",
      "Processing row group 56/338...\n",
      "Processing row group 56/338...\n",
      "Processing row group 57/338...\n",
      "Processing row group 57/338...\n",
      "Processing row group 58/338...\n",
      "Processing row group 58/338...\n",
      "Processing row group 59/338...\n",
      "Processing row group 59/338...\n",
      "Processing row group 60/338...\n",
      "Processing row group 60/338...\n",
      "Processing row group 61/338...\n",
      "Processing row group 61/338...\n",
      "Processing row group 62/338...\n",
      "Processing row group 62/338...\n",
      "Processing row group 63/338...\n",
      "Processing row group 63/338...\n",
      "Processing row group 64/338...\n",
      "Processing row group 64/338...\n",
      "Processing row group 65/338...\n",
      "Processing row group 65/338...\n",
      "Processing row group 66/338...\n",
      "Processing row group 66/338...\n",
      "Processing row group 67/338...\n",
      "Processing row group 67/338...\n",
      "Processing row group 68/338...\n",
      "Processing row group 68/338...\n",
      "Processing row group 69/338...\n",
      "Processing row group 69/338...\n",
      "Processing row group 70/338...\n",
      "Processing row group 70/338...\n",
      "Processing row group 71/338...\n",
      "Processing row group 71/338...\n",
      "Processing row group 72/338...\n",
      "Processing row group 72/338...\n",
      "Processing row group 73/338...\n",
      "Processing row group 73/338...\n",
      "Processing row group 74/338...\n",
      "Processing row group 74/338...\n",
      "Processing row group 75/338...\n",
      "Processing row group 75/338...\n",
      "Processing row group 76/338...\n",
      "Processing row group 76/338...\n",
      "Processing row group 77/338...\n",
      "Processing row group 77/338...\n",
      "Processing row group 78/338...\n",
      "Processing row group 78/338...\n",
      "Processing row group 79/338...\n",
      "Processing row group 79/338...\n",
      "Processing row group 80/338...\n",
      "Processing row group 80/338...\n",
      "Processing row group 81/338...\n",
      "Processing row group 81/338...\n",
      "Processing row group 82/338...\n",
      "Processing row group 82/338...\n",
      "Processing row group 83/338...\n",
      "Processing row group 83/338...\n",
      "Processing row group 84/338...\n",
      "Processing row group 84/338...\n",
      "Processing row group 85/338...\n",
      "Processing row group 85/338...\n",
      "Processing row group 86/338...\n",
      "Processing row group 86/338...\n",
      "Processing row group 87/338...\n",
      "Processing row group 87/338...\n",
      "Processing row group 88/338...\n",
      "Processing row group 88/338...\n",
      "Processing row group 89/338...\n",
      "Processing row group 89/338...\n",
      "Processing row group 90/338...\n",
      "Processing row group 90/338...\n",
      "Processing row group 91/338...\n",
      "Processing row group 91/338...\n",
      "Processing row group 92/338...\n",
      "Processing row group 92/338...\n",
      "Processing row group 93/338...\n",
      "Processing row group 93/338...\n",
      "Processing row group 94/338...\n",
      "Processing row group 94/338...\n",
      "Processing row group 95/338...\n",
      "Processing row group 95/338...\n",
      "Processing row group 96/338...\n",
      "Processing row group 96/338...\n",
      "Processing row group 97/338...\n",
      "Processing row group 97/338...\n",
      "Processing row group 98/338...\n",
      "Processing row group 98/338...\n",
      "Processing row group 99/338...\n",
      "Processing row group 99/338...\n",
      "Processing row group 100/338...\n",
      "Processing row group 100/338...\n",
      "Processing row group 101/338...\n",
      "Processing row group 101/338...\n",
      "Processing row group 102/338...\n",
      "Processing row group 102/338...\n",
      "Processing row group 103/338...\n",
      "Processing row group 103/338...\n",
      "Processing row group 104/338...\n",
      "Processing row group 104/338...\n",
      "Processing row group 105/338...\n",
      "Processing row group 105/338...\n",
      "Processing row group 106/338...\n",
      "Processing row group 106/338...\n",
      "Processing row group 107/338...\n",
      "Processing row group 107/338...\n",
      "Processing row group 108/338...\n",
      "Processing row group 108/338...\n",
      "Processing row group 109/338...\n",
      "Processing row group 109/338...\n",
      "Processing row group 110/338...\n",
      "Processing row group 110/338...\n",
      "Processing row group 111/338...\n",
      "Processing row group 111/338...\n",
      "Processing row group 112/338...\n",
      "Processing row group 112/338...\n",
      "Processing row group 113/338...\n",
      "Processing row group 113/338...\n",
      "Processing row group 114/338...\n",
      "Processing row group 114/338...\n",
      "Processing row group 115/338...\n",
      "Processing row group 115/338...\n",
      "Processing row group 116/338...\n",
      "Processing row group 116/338...\n",
      "Processing row group 117/338...\n",
      "Processing row group 117/338...\n",
      "Processing row group 118/338...\n",
      "Processing row group 118/338...\n",
      "Processing row group 119/338...\n",
      "Processing row group 119/338...\n",
      "Processing row group 120/338...\n",
      "Processing row group 120/338...\n",
      "Processing row group 121/338...\n",
      "Processing row group 121/338...\n",
      "Processing row group 122/338...\n",
      "Processing row group 122/338...\n",
      "Processing row group 123/338...\n",
      "Processing row group 123/338...\n",
      "Processing row group 124/338...\n",
      "Processing row group 124/338...\n",
      "Processing row group 125/338...\n",
      "Processing row group 125/338...\n",
      "Processing row group 126/338...\n",
      "Processing row group 126/338...\n",
      "Processing row group 127/338...\n",
      "Processing row group 127/338...\n",
      "Processing row group 128/338...\n",
      "Processing row group 128/338...\n",
      "Processing row group 129/338...\n",
      "Processing row group 129/338...\n",
      "Processing row group 130/338...\n",
      "Processing row group 130/338...\n",
      "Processing row group 131/338...\n",
      "Processing row group 131/338...\n",
      "Processing row group 132/338...\n",
      "Processing row group 132/338...\n",
      "Processing row group 133/338...\n",
      "Processing row group 133/338...\n",
      "Processing row group 134/338...\n",
      "Processing row group 134/338...\n",
      "Processing row group 135/338...\n",
      "Processing row group 135/338...\n",
      "Processing row group 136/338...\n",
      "Processing row group 136/338...\n",
      "Processing row group 137/338...\n",
      "Processing row group 137/338...\n",
      "Processing row group 138/338...\n",
      "Processing row group 138/338...\n",
      "Processing row group 139/338...\n",
      "Processing row group 139/338...\n",
      "Processing row group 140/338...\n",
      "Processing row group 140/338...\n",
      "Processing row group 141/338...\n",
      "Processing row group 141/338...\n",
      "Processing row group 142/338...\n",
      "Processing row group 142/338...\n",
      "Processing row group 143/338...\n",
      "Processing row group 143/338...\n",
      "Processing row group 144/338...\n",
      "Processing row group 144/338...\n",
      "Processing row group 145/338...\n",
      "Processing row group 145/338...\n",
      "Processing row group 146/338...\n",
      "Processing row group 146/338...\n",
      "Processing row group 147/338...\n",
      "Processing row group 147/338...\n",
      "Processing row group 148/338...\n",
      "Processing row group 148/338...\n",
      "Processing row group 149/338...\n",
      "Processing row group 149/338...\n",
      "Processing row group 150/338...\n",
      "Processing row group 150/338...\n",
      "Processing row group 151/338...\n",
      "Processing row group 151/338...\n",
      "Processing row group 152/338...\n",
      "Processing row group 152/338...\n",
      "Processing row group 153/338...\n",
      "Processing row group 153/338...\n",
      "Processing row group 154/338...\n",
      "Processing row group 154/338...\n",
      "Processing row group 155/338...\n",
      "Processing row group 155/338...\n",
      "Processing row group 156/338...\n",
      "Processing row group 156/338...\n",
      "Processing row group 157/338...\n",
      "Processing row group 157/338...\n",
      "Processing row group 158/338...\n",
      "Processing row group 158/338...\n",
      "Processing row group 159/338...\n",
      "Processing row group 159/338...\n",
      "Processing row group 160/338...\n",
      "Processing row group 160/338...\n",
      "Processing row group 161/338...\n",
      "Processing row group 161/338...\n",
      "Processing row group 162/338...\n",
      "Processing row group 162/338...\n",
      "Processing row group 163/338...\n",
      "Processing row group 163/338...\n",
      "Processing row group 164/338...\n",
      "Processing row group 164/338...\n",
      "Processing row group 165/338...\n",
      "Processing row group 165/338...\n",
      "Processing row group 166/338...\n",
      "Processing row group 166/338...\n",
      "Processing row group 167/338...\n",
      "Processing row group 167/338...\n",
      "Processing row group 168/338...\n",
      "Processing row group 168/338...\n",
      "Processing row group 169/338...\n",
      "Processing row group 169/338...\n",
      "Processing row group 170/338...\n",
      "Processing row group 170/338...\n",
      "Processing row group 171/338...\n",
      "Processing row group 171/338...\n",
      "Processing row group 172/338...\n",
      "Processing row group 172/338...\n",
      "Processing row group 173/338...\n",
      "Processing row group 173/338...\n",
      "Processing row group 174/338...\n",
      "Processing row group 174/338...\n",
      "Processing row group 175/338...\n",
      "Processing row group 175/338...\n",
      "Processing row group 176/338...\n",
      "Processing row group 176/338...\n",
      "Processing row group 177/338...\n",
      "Processing row group 177/338...\n",
      "Processing row group 178/338...\n",
      "Processing row group 178/338...\n",
      "Processing row group 179/338...\n",
      "Processing row group 179/338...\n",
      "Processing row group 180/338...\n",
      "Processing row group 180/338...\n",
      "Processing row group 181/338...\n",
      "Processing row group 181/338...\n",
      "Processing row group 182/338...\n",
      "Processing row group 182/338...\n",
      "Processing row group 183/338...\n",
      "Processing row group 183/338...\n",
      "Processing row group 184/338...\n",
      "Processing row group 184/338...\n",
      "Processing row group 185/338...\n",
      "Processing row group 185/338...\n",
      "Processing row group 186/338...\n",
      "Processing row group 186/338...\n",
      "Processing row group 187/338...\n",
      "Processing row group 187/338...\n",
      "Processing row group 188/338...\n",
      "Processing row group 188/338...\n",
      "Processing row group 189/338...\n",
      "Processing row group 189/338...\n",
      "Processing row group 190/338...\n",
      "Processing row group 190/338...\n",
      "Processing row group 191/338...\n",
      "Processing row group 191/338...\n",
      "Processing row group 192/338...\n",
      "Processing row group 192/338...\n",
      "Processing row group 193/338...\n",
      "Processing row group 193/338...\n",
      "Processing row group 194/338...\n",
      "Processing row group 194/338...\n",
      "Processing row group 195/338...\n",
      "Processing row group 195/338...\n",
      "Processing row group 196/338...\n",
      "Processing row group 196/338...\n",
      "Processing row group 197/338...\n",
      "Processing row group 197/338...\n",
      "Processing row group 198/338...\n",
      "Processing row group 198/338...\n",
      "Processing row group 199/338...\n",
      "Processing row group 199/338...\n",
      "Processing row group 200/338...\n",
      "Processing row group 200/338...\n",
      "Processing row group 201/338...\n",
      "Processing row group 201/338...\n",
      "Processing row group 202/338...\n",
      "Processing row group 202/338...\n",
      "Processing row group 203/338...\n",
      "Processing row group 203/338...\n",
      "Processing row group 204/338...\n",
      "Processing row group 205/338...\n",
      "Processing row group 204/338...\n",
      "Processing row group 205/338...\n",
      "Processing row group 206/338...\n",
      "Processing row group 207/338...\n",
      "Processing row group 206/338...\n",
      "Processing row group 207/338...\n",
      "Processing row group 208/338...\n",
      "Processing row group 208/338...\n",
      "Processing row group 209/338...\n",
      "Processing row group 209/338...\n",
      "Processing row group 210/338...\n",
      "Processing row group 210/338...\n",
      "Processing row group 211/338...\n",
      "Processing row group 211/338...\n",
      "Processing row group 212/338...\n",
      "Processing row group 212/338...\n",
      "Processing row group 213/338...\n",
      "Processing row group 213/338...\n",
      "Processing row group 214/338...\n",
      "Processing row group 214/338...\n",
      "Processing row group 215/338...\n",
      "Processing row group 215/338...\n",
      "Processing row group 216/338...\n",
      "Processing row group 216/338...\n",
      "Processing row group 217/338...\n",
      "Processing row group 217/338...\n",
      "Processing row group 218/338...\n",
      "Processing row group 218/338...\n",
      "Processing row group 219/338...\n",
      "Processing row group 219/338...\n",
      "Processing row group 220/338...\n",
      "Processing row group 220/338...\n",
      "Processing row group 221/338...\n",
      "Processing row group 221/338...\n",
      "Processing row group 222/338...\n",
      "Processing row group 222/338...\n",
      "Processing row group 223/338...\n",
      "Processing row group 223/338...\n",
      "Processing row group 224/338...\n",
      "Processing row group 224/338...\n",
      "Processing row group 225/338...\n",
      "Processing row group 225/338...\n",
      "Processing row group 226/338...\n",
      "Processing row group 226/338...\n",
      "Processing row group 227/338...\n",
      "Processing row group 227/338...\n",
      "Processing row group 228/338...\n",
      "Processing row group 228/338...\n",
      "Processing row group 229/338...\n",
      "Processing row group 229/338...\n",
      "Processing row group 230/338...\n",
      "Processing row group 230/338...\n",
      "Processing row group 231/338...\n",
      "Processing row group 231/338...\n",
      "Processing row group 232/338...\n",
      "Processing row group 232/338...\n",
      "Processing row group 233/338...\n",
      "Processing row group 233/338...\n",
      "Processing row group 234/338...\n",
      "Processing row group 234/338...\n",
      "Processing row group 235/338...\n",
      "Processing row group 235/338...\n",
      "Processing row group 236/338...\n",
      "Processing row group 236/338...\n",
      "Processing row group 237/338...\n",
      "Processing row group 237/338...\n",
      "Processing row group 238/338...\n",
      "Processing row group 238/338...\n",
      "Processing row group 239/338...\n",
      "Processing row group 239/338...\n",
      "Processing row group 240/338...\n",
      "Processing row group 240/338...\n",
      "Processing row group 241/338...\n",
      "Processing row group 241/338...\n",
      "Processing row group 242/338...\n",
      "Processing row group 242/338...\n",
      "Processing row group 243/338...\n",
      "Processing row group 243/338...\n",
      "Processing row group 244/338...\n",
      "Processing row group 244/338...\n",
      "Processing row group 245/338...\n",
      "Processing row group 245/338...\n",
      "Processing row group 246/338...\n",
      "Processing row group 246/338...\n",
      "Processing row group 247/338...\n",
      "Processing row group 247/338...\n",
      "Processing row group 248/338...\n",
      "Processing row group 248/338...\n",
      "Processing row group 249/338...\n",
      "Processing row group 249/338...\n",
      "Processing row group 250/338...\n",
      "Processing row group 250/338...\n",
      "Processing row group 251/338...\n",
      "Processing row group 251/338...\n",
      "Processing row group 252/338...\n",
      "Processing row group 252/338...\n",
      "Processing row group 253/338...\n",
      "Processing row group 253/338...\n",
      "Processing row group 254/338...\n",
      "Processing row group 254/338...\n",
      "Processing row group 255/338...\n",
      "Processing row group 255/338...\n",
      "Processing row group 256/338...\n",
      "Processing row group 256/338...\n",
      "Processing row group 257/338...\n",
      "Processing row group 257/338...\n",
      "Processing row group 258/338...\n",
      "Processing row group 258/338...\n",
      "Processing row group 259/338...\n",
      "Processing row group 259/338...\n",
      "Processing row group 260/338...\n",
      "Processing row group 260/338...\n",
      "Processing row group 261/338...\n",
      "Processing row group 261/338...\n",
      "Processing row group 262/338...\n",
      "Processing row group 262/338...\n",
      "Processing row group 263/338...\n",
      "Processing row group 263/338...\n",
      "Processing row group 264/338...\n",
      "Processing row group 264/338...\n",
      "Processing row group 265/338...\n",
      "Processing row group 265/338...\n",
      "Processing row group 266/338...\n",
      "Processing row group 266/338...\n",
      "Processing row group 267/338...\n",
      "Processing row group 267/338...\n",
      "Processing row group 268/338...\n",
      "Processing row group 268/338...\n",
      "Processing row group 269/338...\n",
      "Processing row group 269/338...\n",
      "Processing row group 270/338...\n",
      "Processing row group 270/338...\n",
      "Processing row group 271/338...\n",
      "Processing row group 271/338...\n",
      "Processing row group 272/338...\n",
      "Processing row group 272/338...\n",
      "Processing row group 273/338...\n",
      "Processing row group 273/338...\n",
      "Processing row group 274/338...\n",
      "Processing row group 274/338...\n",
      "Processing row group 275/338...\n",
      "Processing row group 275/338...\n",
      "Processing row group 276/338...\n",
      "Processing row group 276/338...\n",
      "Processing row group 277/338...\n",
      "Processing row group 277/338...\n",
      "Processing row group 278/338...\n",
      "Processing row group 278/338...\n",
      "Processing row group 279/338...\n",
      "Processing row group 279/338...\n",
      "Processing row group 280/338...\n",
      "Processing row group 280/338...\n",
      "Processing row group 281/338...\n",
      "Processing row group 281/338...\n",
      "Processing row group 282/338...\n",
      "Processing row group 282/338...\n",
      "Processing row group 283/338...\n",
      "Processing row group 283/338...\n",
      "Processing row group 284/338...\n",
      "Processing row group 284/338...\n",
      "Processing row group 285/338...\n",
      "Processing row group 285/338...\n",
      "Processing row group 286/338...\n",
      "Processing row group 286/338...\n",
      "Processing row group 287/338...\n",
      "Processing row group 287/338...\n",
      "Processing row group 288/338...\n",
      "Processing row group 288/338...\n",
      "Processing row group 289/338...\n",
      "Processing row group 289/338...\n",
      "Processing row group 290/338...\n",
      "Processing row group 290/338...\n",
      "Processing row group 291/338...\n",
      "Processing row group 291/338...\n",
      "Processing row group 292/338...\n",
      "Processing row group 292/338...\n",
      "Processing row group 293/338...\n",
      "Processing row group 293/338...\n",
      "Processing row group 294/338...\n",
      "Processing row group 294/338...\n",
      "Processing row group 295/338...\n",
      "Processing row group 295/338...\n",
      "Processing row group 296/338...\n",
      "Processing row group 296/338...\n",
      "Processing row group 297/338...\n",
      "Processing row group 297/338...\n",
      "Processing row group 298/338...\n",
      "Processing row group 298/338...\n",
      "Processing row group 299/338...\n",
      "Processing row group 299/338...\n",
      "Processing row group 300/338...\n",
      "Processing row group 300/338...\n",
      "Processing row group 301/338...\n",
      "Processing row group 301/338...\n",
      "Processing row group 302/338...\n",
      "Processing row group 302/338...\n",
      "Processing row group 303/338...\n",
      "Processing row group 303/338...\n",
      "Processing row group 304/338...\n",
      "Processing row group 304/338...\n",
      "Processing row group 305/338...\n",
      "Processing row group 305/338...\n",
      "Processing row group 306/338...\n",
      "Processing row group 306/338...\n",
      "Processing row group 307/338...\n",
      "Processing row group 307/338...\n",
      "Processing row group 308/338...\n",
      "Processing row group 308/338...\n",
      "Processing row group 309/338...\n",
      "Processing row group 309/338...\n",
      "Processing row group 310/338...\n",
      "Processing row group 310/338...\n",
      "Processing row group 311/338...\n",
      "Processing row group 311/338...\n",
      "Processing row group 312/338...\n",
      "Processing row group 312/338...\n",
      "Processing row group 313/338...\n",
      "Processing row group 313/338...\n",
      "Processing row group 314/338...\n",
      "Processing row group 314/338...\n",
      "Processing row group 315/338...\n",
      "Processing row group 315/338...\n",
      "Processing row group 316/338...\n",
      "Processing row group 316/338...\n",
      "Processing row group 317/338...\n",
      "Processing row group 317/338...\n",
      "Processing row group 318/338...\n",
      "Processing row group 318/338...\n",
      "Processing row group 319/338...\n",
      "Processing row group 319/338...\n",
      "Processing row group 320/338...\n",
      "Processing row group 320/338...\n",
      "Processing row group 321/338...\n",
      "Processing row group 321/338...\n",
      "Processing row group 322/338...\n",
      "Processing row group 322/338...\n",
      "Processing row group 323/338...\n",
      "Processing row group 323/338...\n",
      "Processing row group 324/338...\n",
      "Processing row group 324/338...\n",
      "Processing row group 325/338...\n",
      "Processing row group 325/338...\n",
      "Processing row group 326/338...\n",
      "Processing row group 326/338...\n",
      "Processing row group 327/338...\n",
      "Processing row group 327/338...\n",
      "Processing row group 328/338...\n",
      "Processing row group 328/338...\n",
      "Processing row group 329/338...\n",
      "Processing row group 329/338...\n",
      "Processing row group 330/338...\n",
      "Processing row group 330/338...\n",
      "Processing row group 331/338...\n",
      "Processing row group 331/338...\n",
      "Processing row group 332/338...\n",
      "Processing row group 332/338...\n",
      "Processing row group 333/338...\n",
      "Processing row group 333/338...\n",
      "Processing row group 334/338...\n",
      "Processing row group 334/338...\n",
      "Processing row group 335/338...\n",
      "Processing row group 335/338...\n",
      "Processing row group 336/338...\n",
      "Processing row group 336/338...\n",
      "Processing row group 337/338...\n",
      "Processing row group 337/338...\n",
      "Processing row group 338/338...\n",
      "Processing row group 338/338...\n",
      "Total Paris establishments collected: 1430615\n",
      "Total Paris establishments collected: 1430615\n",
      "Sirene: 1430615 establishments in Paris (2014-2024) saved\n",
      "Columns: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n",
      "Sirene: 1430615 establishments in Paris (2014-2024) saved\n",
      "Columns: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n"
     ]
    }
   ],
   "source": [
    "# Sirene Business Establishment Dataset\n",
    "print(\"Loading Sirene dataset (this may take a while, it's a large file)...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1Jh9vcCnblxJxbuMTrqxuyR1PPo1dkrBo'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'sirene.parquet'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "# This is a large parquet file - use pyarrow to read in batches\n",
    "print(\"Reading Sirene data in batches to handle large file size...\")\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "# Open the parquet file\n",
    "parquet_file = pq.ParquetFile(raw_file)\n",
    "\n",
    "# Get total number of row groups for progress tracking\n",
    "total_row_groups = parquet_file.num_row_groups\n",
    "print(f\"Parquet file has {total_row_groups} row groups\")\n",
    "\n",
    "# First, let's check what columns are available by reading just the first row group\n",
    "first_table = parquet_file.read_row_group(0, columns=None)\n",
    "first_df = first_table.to_pandas()\n",
    "print(f\"Available columns in Sirene: {list(first_df.columns)}\")\n",
    "\n",
    "sirene_chunks = []\n",
    "\n",
    "# Read each row group (batch) and process\n",
    "for i in range(total_row_groups):\n",
    "    print(f\"Processing row group {i+1}/{total_row_groups}...\")\n",
    "    \n",
    "    # Read this row group as a table\n",
    "    table = parquet_file.read_row_group(i, columns=None)\n",
    "    chunk = table.to_pandas()\n",
    "    \n",
    "    # Filter for Paris (département 75)\n",
    "    if 'depet' in chunk.columns:\n",
    "        chunk_paris = chunk[chunk['depet'] == '75'].copy()\n",
    "    elif 'departement' in chunk.columns:\n",
    "        chunk_paris = chunk[chunk['departement'] == '75'].copy()\n",
    "    elif 'codeCommuneEtablissement' in chunk.columns:\n",
    "        chunk_paris = chunk[chunk['codeCommuneEtablissement'].astype(str).str.startswith('75')].copy()\n",
    "    else:\n",
    "        # Find any column with commune or dep in name\n",
    "        dept_col = [col for col in chunk.columns if 'dep' in col.lower() or 'commune' in col.lower()]\n",
    "        if dept_col:\n",
    "            dept_col = dept_col[0]\n",
    "            chunk_paris = chunk[chunk[dept_col].astype(str).str.startswith('75')].copy()\n",
    "        else:\n",
    "            print(f\"Warning: No department column found in row group {i+1}, skipping...\")\n",
    "            continue\n",
    "    \n",
    "    # Filter for dates from 2014 to 2024\n",
    "    date_cols = [col for col in chunk_paris.columns if 'date' in col.lower() or 'creation' in col.lower()]\n",
    "    if date_cols and len(chunk_paris) > 0:\n",
    "        date_col = date_cols[0]\n",
    "        chunk_paris[date_col] = pd.to_datetime(chunk_paris[date_col], errors='coerce')\n",
    "        chunk_paris = chunk_paris[\n",
    "            (chunk_paris[date_col] >= '2014-01-01') & \n",
    "            (chunk_paris[date_col] <= '2024-12-31')\n",
    "        ].copy()\n",
    "    \n",
    "    # Add to our list if there are Paris records\n",
    "    if len(chunk_paris) > 0:\n",
    "        sirene_chunks.append(chunk_paris)\n",
    "\n",
    "# Concatenate all chunks\n",
    "if sirene_chunks:\n",
    "    sirene_paris = pd.concat(sirene_chunks, ignore_index=True)\n",
    "    print(f\"Total Paris establishments collected: {len(sirene_paris)}\")\n",
    "else:\n",
    "    print(\"No Paris establishments found!\")\n",
    "    sirene_paris = pd.DataFrame()\n",
    "\n",
    "# Save to datasets folder\n",
    "if len(sirene_paris) > 0:\n",
    "    sirene_paris.to_parquet(datasets_dir / 'sirene_2014_2024_paris.parquet', index=False)\n",
    "    print(f\"Sirene: {len(sirene_paris)} establishments in Paris (2014-2024) saved\")\n",
    "    print(f\"Columns: {list(sirene_paris.columns)}\")\n",
    "else:\n",
    "    print(\"No data to save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdhvk4jle5",
   "metadata": {},
   "source": [
    "## Summary of Loaded Datasets\n",
    "All datasets have been filtered for Paris intra-muros and saved to the `datasets/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ooxw0je35r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASETS LOADED - PARIS INTRA-MUROS ONLY\n",
      "================================================================================\n",
      "\n",
      "RAW DATASETS:\n",
      "----------------------------------------\n",
      "census_2013.xlsx: 67.43 MB\n",
      "census_2017.xlsx: 42.63 MB\n",
      "census_2021.xlsx: 47.39 MB\n",
      "dvf_mutations.gpkg: 341.20 MB\n",
      "filosofi_2013.xlsx: 4.81 MB\n",
      "filosofi_2017.xlsx: 2.63 MB\n",
      "filosofi_2021.xlsx: 2.69 MB\n",
      "geofabrik_idf.osm.pbf: 309.12 MB\n",
      "iris.geojson: 11.11 MB\n",
      "sirene.parquet: 2043.89 MB\n",
      "\n",
      "PROCESSED DATASETS:\n",
      "----------------------------------------\n",
      "census_2013_paris.parquet: 0.11 MB\n",
      "census_2017_paris.parquet: 0.11 MB\n",
      "census_2021_paris.parquet: 0.10 MB\n",
      "dvf_mutations_paris.parquet: 4.30 MB\n",
      "filosofi_2013_paris.parquet: 0.05 MB\n",
      "filosofi_2017_paris.parquet: 0.04 MB\n",
      "filosofi_2021_paris.parquet: 0.04 MB\n",
      "iris_paris.geojson: 0.03 MB\n",
      "sirene_2014_2024_paris.parquet: 72.79 MB\n",
      "\n",
      "================================================================================\n",
      "DATA LOADING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Datasets summary:\n",
      "- 3 FILOSOFI datasets (2013, 2017, 2021) - Income data\n",
      "- 3 CENSUS datasets (2013, 2017, 2021) - Population data\n",
      "- DVF Mutations - Real estate transactions\n",
      "- GEOFABRIK OSM - OpenStreetMap data for Île-de-France\n",
      "- IRIS GeoJSON - Geographic boundaries for Paris IRIS zones\n",
      "- Sirene (2014-2024) - Business establishments\n",
      "\n",
      "Raw data saved in 'raw_datasets/' folder\n",
      "Processed data saved in 'datasets/' folder - all filtered for Paris only.\n"
     ]
    }
   ],
   "source": [
    "# Summary of all loaded datasets\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASETS LOADED - PARIS INTRA-MUROS ONLY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nRAW DATASETS:\")\n",
    "print(\"-\" * 40)\n",
    "raw_files = sorted(os.listdir(raw_datasets_dir))\n",
    "for file in raw_files:\n",
    "    file_path = raw_datasets_dir / file\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"{file}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\nPROCESSED DATASETS:\")\n",
    "print(\"-\" * 40)\n",
    "datasets_files = sorted(os.listdir(datasets_dir))\n",
    "for file in datasets_files:\n",
    "    file_path = datasets_dir / file\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"{file}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA LOADING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDatasets summary:\")\n",
    "print(\"- 3 FILOSOFI datasets (2013, 2017, 2021) - Income data\")\n",
    "print(\"- 3 CENSUS datasets (2013, 2017, 2021) - Population data\")\n",
    "print(\"- DVF Mutations - Real estate transactions\")\n",
    "print(\"- GEOFABRIK OSM - OpenStreetMap data for Île-de-France\")\n",
    "print(\"- IRIS GeoJSON - Geographic boundaries for Paris IRIS zones\")\n",
    "print(\"- Sirene (2014-2024) - Business establishments\")\n",
    "print(f\"\\nRaw data saved in '{raw_datasets_dir}/' folder\")\n",
    "print(f\"Processed data saved in '{datasets_dir}/' folder - all filtered for Paris only.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
