{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "p3w9f1kbuoi",
   "metadata": {},
   "source": [
    "# Data Loading - Paris Gentrification Analysis\n",
    "\n",
    "**Purpose:** Download and load all raw data sources (FILOSOFI, EDUCATION, CENSUS, DVF, IRIS) for data preparation pipeline\n",
    "\n",
    "**Output:** Raw datasets stored in `raw_datasets/` folder, ready for cleaning and aggregation\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Load FILOSOFI** - Income data (2013, 2017, 2021)\n",
    "2. **Load EDUCATION** - Higher education statistics (2013, 2017, 2021)\n",
    "3. **Load CENSUS** - Demographic data (2013, 2017, 2021)\n",
    "4. **Load DVF** - Real estate transaction data (2014-2021)\n",
    "5. **Load IRIS** - Geographic boundaries and type classifications\n",
    "6. **Export & Quality Check** - Verify all files loaded with expected structure\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4d67e",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Load FILOSOFI Datasets (2013, 2017, 2021)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125181df",
   "metadata": {},
   "source": [
    "FILOSOFI datasets contain income and living standards data at IRIS level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Datasets directory ready at: ../datasets\n",
      "Raw datasets directory ready at: ../raw_datasets\n"
     ]
    }
   ],
   "source": [
    "# Setup: Create necessary directories\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import gdown\n",
    "import xlrd\n",
    "\n",
    "# Create datasets and raw_datasets folders if they don't exist\n",
    "datasets_dir = Path('..') / 'datasets'\n",
    "raw_datasets_dir = Path('..') / 'raw_datasets'\n",
    "datasets_dir.mkdir(exist_ok=True)\n",
    "raw_datasets_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Setup complete. Datasets directory ready at: {datasets_dir}\")\n",
    "print(f\"Raw datasets directory ready at: {raw_datasets_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bpra809573q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1fRbArcfw_DHrycI11NsjbosnXCp6Nh26\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2013.xlsx\n",
      "100%|██████████| 5.04M/5.04M [00:00<00:00, 29.3MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6013', 'DISP_Q113', 'DISP_MED13', 'DISP_Q313', 'DISP_EQ13', 'DISP_D113', 'DISP_D213', 'DISP_D313', 'DISP_D413', 'DISP_D613', 'DISP_D713', 'DISP_D813', 'DISP_D913', 'DISP_RD13', 'DISP_S80S2013', 'DISP_GI13', 'DISP_PTSAC13', 'DISP_PBEN13', 'DISP_PPEN13', 'DISP_PPAT13', 'DISP_PPSOC13', 'DISP_PPFAM13', 'DISP_PPMINI13', 'DISP_PPLOGT13', 'DISP_PIMPOT13']\n",
      "FILOSOFI 2013: 853 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc']\n",
      "FILOSOFI 2013: 853 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2013\n",
    "print(\"Loading FILOSOFI 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1fRbArcfw_DHrycI11NsjbosnXCp6Nh26'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2013.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED13': 'median_uc',}\n",
    "\n",
    "# Filter for Paris intra-muros (département 75)\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2013_paris = filosofi_2013[filosofi_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2013_paris.columns]\n",
    "filosofi_2013_paris = filosofi_2013_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2013_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2013_paris.to_parquet(datasets_dir / 'filosofi_2013_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2013: {len(filosofi_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ewz3ck2y91r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - FILOSOFI 2013\n",
      "============================================================\n",
      "Number of IRIS: 853\n",
      "Number of rows: 853\n",
      "Number of columns: 3\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010201', '751010202', '751010203', '751010204', '751010301', '751010401', '751020601', '751020701', '751020702', '751020703']\n",
      "\n",
      "Data types:\n",
      "code_iris        object\n",
      "libelle_iris     object\n",
      "median_uc       float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris       0\n",
      "libelle_iris    0\n",
      "median_uc       0\n",
      "dtype: int64\n",
      "============================================================\n",
      "Number of IRIS: 853\n",
      "Number of rows: 853\n",
      "Number of columns: 3\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010201', '751010202', '751010203', '751010204', '751010301', '751010401', '751020601', '751020701', '751020702', '751020703']\n",
      "\n",
      "Data types:\n",
      "code_iris        object\n",
      "libelle_iris     object\n",
      "median_uc       float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris       0\n",
      "libelle_iris    0\n",
      "median_uc       0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify FILOSOFI 2013 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - FILOSOFI 2013\")\n",
    "print(\"=\" * 60)\n",
    "loaded_filosofi_2013 = pd.read_parquet(datasets_dir / 'filosofi_2013_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_filosofi_2013)}\")\n",
    "print(f\"Number of rows: {len(loaded_filosofi_2013)}\")\n",
    "print(f\"Number of columns: {len(loaded_filosofi_2013.columns)}\")\n",
    "print(f\"Columns: {list(loaded_filosofi_2013.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_filosofi_2013['code_iris'].head(10).tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_filosofi_2013.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_filosofi_2013.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "w0huionnxs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1IhvzpWGInGlDj7Xpi4kHP87msylR7hiQ\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2017.xlsx\n",
      "100%|██████████| 2.76M/2.76M [00:00<00:00, 108MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6017', 'DISP_Q117', 'DISP_MED17', 'DISP_Q317', 'DISP_EQ17', 'DISP_D117', 'DISP_D217', 'DISP_D317', 'DISP_D417', 'DISP_D617', 'DISP_D717', 'DISP_D817', 'DISP_D917', 'DISP_RD17', 'DISP_S80S2017', 'DISP_GI17', 'DISP_PACT17', 'DISP_PTSA17', 'DISP_PCHO17', 'DISP_PBEN17', 'DISP_PPEN17', 'DISP_PPAT17', 'DISP_PPSOC17', 'DISP_PPFAM17', 'DISP_PPMINI17', 'DISP_PPLOGT17', 'DISP_PIMPOT17', 'DISP_NOTE17']\n",
      "FILOSOFI 2017: 871 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2017\n",
    "print(\"Loading FILOSOFI 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1IhvzpWGInGlDj7Xpi4kHP87msylR7hiQ'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2017.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED17': 'median_uc',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2017_paris = filosofi_2017[filosofi_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2017_paris.columns]\n",
    "filosofi_2017_paris = filosofi_2017_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2017_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2017_paris.to_parquet(datasets_dir / 'filosofi_2017_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2017: {len(filosofi_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sm4m8l2cpb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - FILOSOFI 2017\n",
      "============================================================\n",
      "Number of IRIS: 871\n",
      "Number of rows: 871\n",
      "Number of columns: 3\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010201', '751010202', '751010203', '751010204', '751010301', '751010401', '751010402', '751020601', '751020602', '751020701']\n",
      "\n",
      "Data types:\n",
      "code_iris        object\n",
      "libelle_iris     object\n",
      "median_uc       float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris       0\n",
      "libelle_iris    0\n",
      "median_uc       1\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify FILOSOFI 2017 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - FILOSOFI 2017\")\n",
    "print(\"=\" * 60)\n",
    "loaded_filosofi_2017 = pd.read_parquet(datasets_dir / 'filosofi_2017_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_filosofi_2017)}\")\n",
    "print(f\"Number of rows: {len(loaded_filosofi_2017)}\")\n",
    "print(f\"Number of columns: {len(loaded_filosofi_2017.columns)}\")\n",
    "print(f\"Columns: {list(loaded_filosofi_2017.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_filosofi_2017['code_iris'].head(10).tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_filosofi_2017.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_filosofi_2017.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hvqfjbnda9g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Har2wCg63dQZSTWYxmyXQ0DcQ0dHylX8\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2021.xlsx\n",
      "100%|██████████| 2.82M/2.82M [00:00<00:00, 111MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6021', 'DISP_INCERT21', 'DISP_Q121', 'DISP_MED21', 'DISP_Q321', 'DISP_EQ21', 'DISP_D121', 'DISP_D221', 'DISP_D321', 'DISP_D421', 'DISP_D621', 'DISP_D721', 'DISP_D821', 'DISP_D921', 'DISP_RD21', 'DISP_S80S2021', 'DISP_GI21', 'DISP_PACT21', 'DISP_PTSA21', 'DISP_PCHO21', 'DISP_PBEN21', 'DISP_PPEN21', 'DISP_PPAT21', 'DISP_PPSOC21', 'DISP_PPFAM21', 'DISP_PPMINI21', 'DISP_PPLOGT21', 'DISP_PIMPOT21', 'DISP_NOTE21']\n",
      "FILOSOFI 2021: 992 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2021\n",
    "print(\"Loading FILOSOFI 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1Har2wCg63dQZSTWYxmyXQ0DcQ0dHylX8'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2021.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED21': 'median_uc',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2021_paris = filosofi_2021[filosofi_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2021_paris.columns]\n",
    "filosofi_2021_paris = filosofi_2021_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2021_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2021_paris.to_parquet(datasets_dir / 'filosofi_2021_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2021: {len(filosofi_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1z05jym69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - FILOSOFI 2021\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 3\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Data types:\n",
      "code_iris       object\n",
      "libelle_iris    object\n",
      "median_uc       object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris       0\n",
      "libelle_iris    0\n",
      "median_uc       0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify FILOSOFI 2021 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - FILOSOFI 2021\")\n",
    "print(\"=\" * 60)\n",
    "loaded_filosofi_2021 = pd.read_parquet(datasets_dir / 'filosofi_2021_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_filosofi_2021)}\")\n",
    "print(f\"Number of rows: {len(loaded_filosofi_2021)}\")\n",
    "print(f\"Number of columns: {len(loaded_filosofi_2021.columns)}\")\n",
    "print(f\"Columns: {list(loaded_filosofi_2021.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_filosofi_2021['code_iris'].head(10).tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_filosofi_2021.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_filosofi_2021.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775ef48",
   "metadata": {},
   "source": [
    "## 2. Load EDUCATION Datasets (2013, 2017, 2021)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d67fdc",
   "metadata": {},
   "source": [
    "Education datasets contain higher education attainment data at IRIS level.\n",
    "\n",
    "**2013**: \n",
    "- `P13_NSCOL15P_SUP` → `pop_bac_sup` (all higher education, not subdivided)\n",
    "\n",
    "**2017/2021**: \n",
    "- `P17/P21_NSCOL15P_SUP2` → `pop_bac2` (Bac+2)\n",
    "- `P17/P21_NSCOL15P_SUP34` → `pop_bac34` (Bac+3/4)\n",
    "- `P17/P21_NSCOL15P_SUP5` → `pop_bac5_plus` (Bac+5+)\n",
    "- **Aggregated**: `pop_bac_sup` = sum of the 3 above (to match 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae487cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EDUCATION 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JmDo7waeztZukDAskj1PUGvzawussYWC\n",
      "To: /workspaces/thesis/raw_datasets/education_2013.xlsx\n",
      "100%|██████████| 37.1M/37.1M [00:01<00:00, 34.7MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION 2013: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'pop_bac_sup']\n"
     ]
    }
   ],
   "source": [
    "# EDUCATION 2013\n",
    "print(\"Loading EDUCATION 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1JmDo7waeztZukDAskj1PUGvzawussYWC'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'education_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "education_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in education_2013.columns if 'IRIS' in col.upper()][0]\n",
    "education_2013_paris = education_2013[education_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only total higher education (not subdivided in 2013)\n",
    "# P13_NSCOL15P_SUP = All higher education (Bac+2, Bac+3/4, Bac+5+ combined)\n",
    "education_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'P13_NSCOL15P_SUP': 'pop_bac_sup',  # All higher education (to match aggregated 2017/2021)\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in education_columns_mapping.keys() if col in education_2013_paris.columns]\n",
    "final_names = [education_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "education_2013_paris = education_2013_paris[cols_to_keep].copy()\n",
    "education_2013_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "education_2013_paris.to_parquet(datasets_dir / 'education_2013_paris.parquet', index=False)\n",
    "print(f\"EDUCATION 2013: {len(education_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(education_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b07498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - EDUCATION 2013\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 2\n",
      "Columns: ['code_iris', 'pop_bac_sup']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Education Statistics:\n",
      "  Total Higher Ed (all): 914,174\n",
      "  Avg Higher Ed (all):   921.5\n",
      "\n",
      "Note: 2013 data is not subdivided (includes all Bac+2, Bac+3/4, Bac+5+)\n",
      "\n",
      "Data types:\n",
      "code_iris       object\n",
      "pop_bac_sup    float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris      0\n",
      "pop_bac_sup    0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify EDUCATION 2013 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - EDUCATION 2013\")\n",
    "print(\"=\" * 60)\n",
    "loaded_education_2013 = pd.read_parquet(datasets_dir / 'education_2013_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_education_2013)}\")\n",
    "print(f\"Number of rows: {len(loaded_education_2013)}\")\n",
    "print(f\"Number of columns: {len(loaded_education_2013.columns)}\")\n",
    "print(f\"Columns: {list(loaded_education_2013.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_education_2013['code_iris'].head(10).tolist())\n",
    "print(f\"\\nEducation Statistics:\")\n",
    "print(f\"  Total Higher Ed (all): {loaded_education_2013['pop_bac_sup'].sum():,.0f}\")\n",
    "print(f\"  Avg Higher Ed (all):   {loaded_education_2013['pop_bac_sup'].mean():,.1f}\")\n",
    "print(f\"\\nNote: 2013 data is not subdivided (includes all Bac+2, Bac+3/4, Bac+5+)\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_education_2013.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_education_2013.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6588ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EDUCATION 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZyxFLSPaGfnVi29HjdxNoMlLh9XoeWye\n",
      "To: /workspaces/thesis/raw_datasets/education_2017.xlsx\n",
      "100%|██████████| 26.5M/26.5M [00:00<00:00, 106MB/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION 2017: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'pop_bac2', 'pop_bac34', 'pop_bac5_plus', 'pop_bac_sup']\n"
     ]
    }
   ],
   "source": [
    "# EDUCATION 2017\n",
    "print(\"Loading EDUCATION 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1ZyxFLSPaGfnVi29HjdxNoMlLh9XoeWye'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'education_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "education_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in education_2017.columns if 'IRIS' in col.upper()][0]\n",
    "education_2017_paris = education_2017[education_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep all 3 higher education categories - 2017 uses P17_ prefix\n",
    "education_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'P17_NSCOL15P_SUP2': 'pop_bac2',        # Bac+2\n",
    "    'P17_NSCOL15P_SUP34': 'pop_bac34',      # Bac+3/4\n",
    "    'P17_NSCOL15P_SUP5': 'pop_bac5_plus',   # Bac+5+\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in education_columns_mapping.keys() if col in education_2017_paris.columns]\n",
    "final_names = [education_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "education_2017_paris = education_2017_paris[cols_to_keep].copy()\n",
    "education_2017_paris.columns = final_names\n",
    "\n",
    "# Create aggregated column to match 2013 (all higher education)\n",
    "education_2017_paris['pop_bac_sup'] = (\n",
    "    education_2017_paris['pop_bac2'].fillna(0) + \n",
    "    education_2017_paris['pop_bac34'].fillna(0) + \n",
    "    education_2017_paris['pop_bac5_plus'].fillna(0)\n",
    ")\n",
    "\n",
    "# Save to datasets folder\n",
    "education_2017_paris.to_parquet(datasets_dir / 'education_2017_paris.parquet', index=False)\n",
    "print(f\"EDUCATION 2017: {len(education_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(education_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f70e946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - EDUCATION 2017\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 5\n",
      "Columns: ['code_iris', 'pop_bac2', 'pop_bac34', 'pop_bac5_plus', 'pop_bac_sup']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Education Statistics:\n",
      "  Total Bac+2:          133,482\n",
      "  Total Bac+3/4:        245,114\n",
      "  Total Bac+5+:         606,156\n",
      "  Total Higher Ed (all): 984,751\n",
      "\n",
      "Averages per IRIS:\n",
      "  Avg Bac+2:            134.6\n",
      "  Avg Bac+3/4:          247.1\n",
      "  Avg Bac+5+:           611.0\n",
      "  Avg Higher Ed (all):  992.7\n",
      "\n",
      "Data types:\n",
      "code_iris         object\n",
      "pop_bac2         float64\n",
      "pop_bac34        float64\n",
      "pop_bac5_plus    float64\n",
      "pop_bac_sup      float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris        0\n",
      "pop_bac2         0\n",
      "pop_bac34        0\n",
      "pop_bac5_plus    0\n",
      "pop_bac_sup      0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify EDUCATION 2017 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - EDUCATION 2017\")\n",
    "print(\"=\" * 60)\n",
    "loaded_education_2017 = pd.read_parquet(datasets_dir / 'education_2017_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_education_2017)}\")\n",
    "print(f\"Number of rows: {len(loaded_education_2017)}\")\n",
    "print(f\"Number of columns: {len(loaded_education_2017.columns)}\")\n",
    "print(f\"Columns: {list(loaded_education_2017.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_education_2017['code_iris'].head(10).tolist())\n",
    "print(f\"\\nEducation Statistics:\")\n",
    "print(f\"  Total Bac+2:          {loaded_education_2017['pop_bac2'].sum():,.0f}\")\n",
    "print(f\"  Total Bac+3/4:        {loaded_education_2017['pop_bac34'].sum():,.0f}\")\n",
    "print(f\"  Total Bac+5+:         {loaded_education_2017['pop_bac5_plus'].sum():,.0f}\")\n",
    "print(f\"  Total Higher Ed (all): {loaded_education_2017['pop_bac_sup'].sum():,.0f}\")\n",
    "print(f\"\\nAverages per IRIS:\")\n",
    "print(f\"  Avg Bac+2:            {loaded_education_2017['pop_bac2'].mean():,.1f}\")\n",
    "print(f\"  Avg Bac+3/4:          {loaded_education_2017['pop_bac34'].mean():,.1f}\")\n",
    "print(f\"  Avg Bac+5+:           {loaded_education_2017['pop_bac5_plus'].mean():,.1f}\")\n",
    "print(f\"  Avg Higher Ed (all):  {loaded_education_2017['pop_bac_sup'].mean():,.1f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_education_2017.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_education_2017.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08118c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EDUCATION 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1gP0FNOwIM3KPq8nVbL_oj9U_IPVJdHQW\n",
      "To: /workspaces/thesis/raw_datasets/education_2021.xlsx\n",
      "100%|██████████| 29.2M/29.2M [00:00<00:00, 54.4MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION 2021: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'pop_bac2', 'pop_bac34', 'pop_bac5_plus', 'pop_bac_sup']\n"
     ]
    }
   ],
   "source": [
    "# EDUCATION 2021\n",
    "print(\"Loading EDUCATION 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1gP0FNOwIM3KPq8nVbL_oj9U_IPVJdHQW'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'education_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "education_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in education_2021.columns if 'IRIS' in col.upper()][0]\n",
    "education_2021_paris = education_2021[education_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep all 3 higher education categories - 2021 uses P21_ prefix\n",
    "education_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'P21_NSCOL15P_SUP2': 'pop_bac2',        # Bac+2\n",
    "    'P21_NSCOL15P_SUP34': 'pop_bac34',      # Bac+3/4\n",
    "    'P21_NSCOL15P_SUP5': 'pop_bac5_plus',   # Bac+5+\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in education_columns_mapping.keys() if col in education_2021_paris.columns]\n",
    "final_names = [education_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "education_2021_paris = education_2021_paris[cols_to_keep].copy()\n",
    "education_2021_paris.columns = final_names\n",
    "\n",
    "# Create aggregated column to match 2013 (all higher education)\n",
    "education_2021_paris['pop_bac_sup'] = (\n",
    "    education_2021_paris['pop_bac2'].fillna(0) + \n",
    "    education_2021_paris['pop_bac34'].fillna(0) + \n",
    "    education_2021_paris['pop_bac5_plus'].fillna(0)\n",
    ")\n",
    "\n",
    "# Save to datasets folder\n",
    "education_2021_paris.to_parquet(datasets_dir / 'education_2021_paris.parquet', index=False)\n",
    "print(f\"EDUCATION 2021: {len(education_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(education_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d11bf545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - EDUCATION 2021\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 5\n",
      "Columns: ['code_iris', 'pop_bac2', 'pop_bac34', 'pop_bac5_plus', 'pop_bac_sup']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Education Statistics:\n",
      "  Total Bac+2:          123,521\n",
      "  Total Bac+3/4:        238,092\n",
      "  Total Bac+5+:         642,412\n",
      "  Total Higher Ed (all): 1,004,025\n",
      "\n",
      "Averages per IRIS:\n",
      "  Avg Bac+2:            124.5\n",
      "  Avg Bac+3/4:          240.0\n",
      "  Avg Bac+5+:           647.6\n",
      "  Avg Higher Ed (all):  1,012.1\n",
      "\n",
      "Data types:\n",
      "code_iris         object\n",
      "pop_bac2         float64\n",
      "pop_bac34        float64\n",
      "pop_bac5_plus    float64\n",
      "pop_bac_sup      float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris        0\n",
      "pop_bac2         0\n",
      "pop_bac34        0\n",
      "pop_bac5_plus    0\n",
      "pop_bac_sup      0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify EDUCATION 2021 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - EDUCATION 2021\")\n",
    "print(\"=\" * 60)\n",
    "loaded_education_2021 = pd.read_parquet(datasets_dir / 'education_2021_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_education_2021)}\")\n",
    "print(f\"Number of rows: {len(loaded_education_2021)}\")\n",
    "print(f\"Number of columns: {len(loaded_education_2021.columns)}\")\n",
    "print(f\"Columns: {list(loaded_education_2021.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_education_2021['code_iris'].head(10).tolist())\n",
    "print(f\"\\nEducation Statistics:\")\n",
    "print(f\"  Total Bac+2:          {loaded_education_2021['pop_bac2'].sum():,.0f}\")\n",
    "print(f\"  Total Bac+3/4:        {loaded_education_2021['pop_bac34'].sum():,.0f}\")\n",
    "print(f\"  Total Bac+5+:         {loaded_education_2021['pop_bac5_plus'].sum():,.0f}\")\n",
    "print(f\"  Total Higher Ed (all): {loaded_education_2021['pop_bac_sup'].sum():,.0f}\")\n",
    "print(f\"\\nAverages per IRIS:\")\n",
    "print(f\"  Avg Bac+2:            {loaded_education_2021['pop_bac2'].mean():,.1f}\")\n",
    "print(f\"  Avg Bac+3/4:          {loaded_education_2021['pop_bac34'].mean():,.1f}\")\n",
    "print(f\"  Avg Bac+5+:           {loaded_education_2021['pop_bac5_plus'].mean():,.1f}\")\n",
    "print(f\"  Avg Higher Ed (all):  {loaded_education_2021['pop_bac_sup'].mean():,.1f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_education_2021.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_education_2021.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e781af1",
   "metadata": {},
   "source": [
    "## 3. Load CENSUS Datasets (2013, 2017, 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb74ed8",
   "metadata": {},
   "source": [
    "CENSUS datasets contain demographic and occupational data at IRIS level.\n",
    "\n",
    "**Variables extracted (all years 2013, 2017, 2021):**\n",
    "- **Population totals**: `pop_total`, `pop_15plus`\n",
    "- **Age groups**: `pop_18_24`, `pop_25_39`, `pop_65plus`\n",
    "- **Occupations**: `pop_cadres` (executives), `pop_prof_inter` (intermediate professions), `pop_employes` (employees), `pop_ouvriers` (workers)\n",
    "- **Immigration**: `pop_immigres`, `pop_etrangers` (foreigners)\n",
    "- **IRIS type**: `typ_iris` (H=Habitat, D=Divers, A=Activité)\n",
    "\n",
    "**Year prefixes**: \n",
    "- 2013: `P13_` / `C13_`\n",
    "- 2017: `P17_` / `C17_`\n",
    "- 2021: `P21_` / `C21_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "w3y327puth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1b2LTSza0fRFkuVnvni60cKWKi51g3BQh\n",
      "To: /workspaces/thesis/raw_datasets/census_2013.xlsx\n",
      "100%|██████████| 70.7M/70.7M [00:00<00:00, 77.2MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2013: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2013\n",
    "print(\"Loading CENSUS 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1b2LTSza0fRFkuVnvni60cKWKi51g3BQh'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2013.columns if 'IRIS' in col.upper()][0]\n",
    "census_2013_paris = census_2013[census_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P13_POP': 'pop_total',\n",
    "    'C13_POP15P': 'pop_15plus',\n",
    "    'C13_POP15P_CS3': 'pop_cadres',\n",
    "    'C13_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C13_POP15P_CS5': 'pop_employes',\n",
    "    'C13_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P13_POP1824': 'pop_18_24',\n",
    "    'P13_POP2539': 'pop_25_39',\n",
    "    'P13_POP65P': 'pop_65plus',\n",
    "    'P13_POP_IMM': 'pop_immigres',\n",
    "    'P13_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2013_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2013_paris = census_2013_paris[cols_to_keep].copy()\n",
    "census_2013_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "census_2013_paris.to_parquet(datasets_dir / 'census_2013_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2013: {len(census_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wbhb53fyaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - CENSUS 2013\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 13\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Total population across all IRIS: 2,229,621\n",
      "\n",
      "Data types:\n",
      "code_iris          object\n",
      "typ_iris           object\n",
      "pop_total         float64\n",
      "pop_15plus        float64\n",
      "pop_cadres        float64\n",
      "pop_prof_inter    float64\n",
      "pop_employes      float64\n",
      "pop_ouvriers      float64\n",
      "pop_18_24         float64\n",
      "pop_25_39         float64\n",
      "pop_65plus        float64\n",
      "pop_immigres      float64\n",
      "pop_etrangers     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris         0\n",
      "typ_iris          0\n",
      "pop_total         0\n",
      "pop_15plus        0\n",
      "pop_cadres        0\n",
      "pop_prof_inter    0\n",
      "pop_employes      0\n",
      "pop_ouvriers      0\n",
      "pop_18_24         0\n",
      "pop_25_39         0\n",
      "pop_65plus        0\n",
      "pop_immigres      0\n",
      "pop_etrangers     0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CENSUS 2013 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - CENSUS 2013\")\n",
    "print(\"=\" * 60)\n",
    "loaded_census_2013 = pd.read_parquet(datasets_dir / 'census_2013_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_census_2013)}\")\n",
    "print(f\"Number of rows: {len(loaded_census_2013)}\")\n",
    "print(f\"Number of columns: {len(loaded_census_2013.columns)}\")\n",
    "print(f\"Columns: {list(loaded_census_2013.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_census_2013['code_iris'].head(10).tolist())\n",
    "print(f\"\\nTotal population across all IRIS: {loaded_census_2013['pop_total'].sum():,.0f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_census_2013.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_census_2013.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2jpiae70h58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1KHGwB0S8D-gj7f3d3LBCzRjqBWxaewzw\n",
      "To: /workspaces/thesis/raw_datasets/census_2017.xlsx\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 61.5MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2017: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2017\n",
    "print(\"Loading CENSUS 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1KHGwB0S8D-gj7f3d3LBCzRjqBWxaewzw'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2017.columns if 'IRIS' in col.upper()][0]\n",
    "census_2017_paris = census_2017[census_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables (2017 uses P17_ prefix)\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P17_POP': 'pop_total',\n",
    "    'C17_POP15P': 'pop_15plus',\n",
    "    'C17_POP15P_CS3': 'pop_cadres',\n",
    "    'C17_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C17_POP15P_CS5': 'pop_employes',\n",
    "    'C17_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P17_POP1824': 'pop_18_24',\n",
    "    'P17_POP2539': 'pop_25_39',\n",
    "    'P17_POP65P': 'pop_65plus',\n",
    "    'P17_POP_IMM': 'pop_immigres',\n",
    "    'P17_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2017_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2017_paris = census_2017_paris[cols_to_keep].copy()\n",
    "census_2017_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "census_2017_paris.to_parquet(datasets_dir / 'census_2017_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2017: {len(census_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6494ygacjh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - CENSUS 2017\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 13\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Total population across all IRIS: 2,187,526\n",
      "\n",
      "Data types:\n",
      "code_iris          object\n",
      "typ_iris           object\n",
      "pop_total         float64\n",
      "pop_15plus        float64\n",
      "pop_cadres        float64\n",
      "pop_prof_inter    float64\n",
      "pop_employes      float64\n",
      "pop_ouvriers      float64\n",
      "pop_18_24         float64\n",
      "pop_25_39         float64\n",
      "pop_65plus        float64\n",
      "pop_immigres      float64\n",
      "pop_etrangers     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris         0\n",
      "typ_iris          0\n",
      "pop_total         0\n",
      "pop_15plus        0\n",
      "pop_cadres        0\n",
      "pop_prof_inter    0\n",
      "pop_employes      0\n",
      "pop_ouvriers      0\n",
      "pop_18_24         0\n",
      "pop_25_39         0\n",
      "pop_65plus        0\n",
      "pop_immigres      0\n",
      "pop_etrangers     0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CENSUS 2017 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - CENSUS 2017\")\n",
    "print(\"=\" * 60)\n",
    "loaded_census_2017 = pd.read_parquet(datasets_dir / 'census_2017_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_census_2017)}\")\n",
    "print(f\"Number of rows: {len(loaded_census_2017)}\")\n",
    "print(f\"Number of columns: {len(loaded_census_2017.columns)}\")\n",
    "print(f\"Columns: {list(loaded_census_2017.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_census_2017['code_iris'].head(10).tolist())\n",
    "print(f\"\\nTotal population across all IRIS: {loaded_census_2017['pop_total'].sum():,.0f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_census_2017.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_census_2017.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adem7qp2of4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yfZ3EYbtnDaRhDWvP_u8ovC6HwQNuq9s\n",
      "To: /workspaces/thesis/raw_datasets/census_2021.xlsx\n",
      "100%|██████████| 49.7M/49.7M [00:00<00:00, 59.7MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2021: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2021\n",
    "print(\"Loading CENSUS 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1yfZ3EYbtnDaRhDWvP_u8ovC6HwQNuq9s'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2021.columns if 'IRIS' in col.upper()][0]\n",
    "census_2021_paris = census_2021[census_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables (2021 uses P21_ prefix)\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P21_POP': 'pop_total',\n",
    "    'C21_POP15P': 'pop_15plus',\n",
    "    'C21_POP15P_CS3': 'pop_cadres',\n",
    "    'C21_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C21_POP15P_CS5': 'pop_employes',\n",
    "    'C21_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P21_POP1824': 'pop_18_24',\n",
    "    'P21_POP2539': 'pop_25_39',\n",
    "    'P21_POP65P': 'pop_65plus',\n",
    "    'P21_POP_IMM': 'pop_immigres',\n",
    "    'P21_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2021_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2021_paris = census_2021_paris[cols_to_keep].copy()\n",
    "census_2021_paris.columns = final_names\n",
    "\n",
    "# Save to data folder\n",
    "census_2021_paris.to_parquet(datasets_dir / 'census_2021_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2021: {len(census_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "i91s2f90il9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - CENSUS 2021\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 13\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Total population across all IRIS: 2,133,111\n",
      "\n",
      "Data types:\n",
      "code_iris          object\n",
      "typ_iris           object\n",
      "pop_total         float64\n",
      "pop_15plus        float64\n",
      "pop_cadres        float64\n",
      "pop_prof_inter    float64\n",
      "pop_employes      float64\n",
      "pop_ouvriers      float64\n",
      "pop_18_24         float64\n",
      "pop_25_39         float64\n",
      "pop_65plus        float64\n",
      "pop_immigres      float64\n",
      "pop_etrangers     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris         0\n",
      "typ_iris          0\n",
      "pop_total         0\n",
      "pop_15plus        0\n",
      "pop_cadres        0\n",
      "pop_prof_inter    0\n",
      "pop_employes      0\n",
      "pop_ouvriers      0\n",
      "pop_18_24         0\n",
      "pop_25_39         0\n",
      "pop_65plus        0\n",
      "pop_immigres      0\n",
      "pop_etrangers     0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CENSUS 2021 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - CENSUS 2021\")\n",
    "print(\"=\" * 60)\n",
    "loaded_census_2021 = pd.read_parquet(datasets_dir / 'census_2021_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_census_2021)}\")\n",
    "print(f\"Number of rows: {len(loaded_census_2021)}\")\n",
    "print(f\"Number of columns: {len(loaded_census_2021.columns)}\")\n",
    "print(f\"Columns: {list(loaded_census_2021.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_census_2021['code_iris'].head(10).tolist())\n",
    "print(f\"\\nTotal population across all IRIS: {loaded_census_2021['pop_total'].sum():,.0f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_census_2021.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_census_2021.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u7o4zrdrvym",
   "metadata": {},
   "source": [
    "## 4. Load DVF Mutations Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a19ece",
   "metadata": {},
   "source": [
    "Real estate transaction data (Demandes de Valeurs Foncières)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59a7888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DVF Mutations dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN\n",
      "From (redirected): https://drive.google.com/uc?id=1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN&confirm=t&uuid=cbce9ace-6da0-494b-baac-104d7e240711\n",
      "To: /workspaces/thesis/raw_datasets/dvf_mutations.gpkg\n",
      "100%|██████████| 358M/358M [00:03<00:00, 102MB/s]  \n",
      "100%|██████████| 358M/358M [00:03<00:00, 102MB/s]\n",
      "/home/codespace/.local/lib/python3.12/site-packages/pyogrio/geopandas.py:275: UserWarning: More than one layer found in 'dvf_mutations.gpkg': 'mutation_geompar' (default), 'mutation_geomparmut', 'mutation_geomlocmut'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/pyogrio/geopandas.py:275: UserWarning: More than one layer found in 'dvf_mutations.gpkg': 'mutation_geompar' (default), 'mutation_geomparmut', 'mutation_geomlocmut'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVF Mutations: 457097 transactions in Paris saved\n",
      "Columns: ['datemut', 'anneemut', 'moismut', 'coddep', 'l_codinsee', 'valeurfonc', 'libtypbien', 'codtypbien', 'sbati', 'geometry']\n",
      "Geometry preserved: 456962 parcels with geometry (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# DVF Mutations - Download from Google Drive using gdown\n",
    "# File ID: 1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN\n",
    "print(\"Loading DVF Mutations dataset...\")\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# Download file\n",
    "file_id = '1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'dvf_mutations.gpkg'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "# Read and filter (keep as GeoDataFrame to preserve geometry)\n",
    "dvf_mutations = gpd.read_file(raw_file)\n",
    "dvf_mutations_paris = dvf_mutations[dvf_mutations['coddep'] == '75'].copy()\n",
    "\n",
    "# Keep only selected columns + geometry\n",
    "columns_to_keep = [\n",
    "    'datemut', 'anneemut', 'moismut',  # temporal\n",
    "    'coddep', 'l_codinsee',  # spatial\n",
    "    'valeurfonc',  # transaction value\n",
    "    'libtypbien', 'codtypbien',  # property type\n",
    "    'sbati',  # built surface\n",
    "    'geometry',  # geographic data (parcels)\n",
    "]\n",
    "\n",
    "# Only keep columns that exist\n",
    "existing_columns = [col for col in columns_to_keep if col in dvf_mutations_paris.columns]\n",
    "dvf_mutations_paris = dvf_mutations_paris[existing_columns].copy()\n",
    "\n",
    "# Save as GeoParquet to preserve geometry\n",
    "dvf_mutations_paris.to_parquet(datasets_dir / 'dvf_mutations_paris.parquet', index=False)\n",
    "print(f\"DVF Mutations: {len(dvf_mutations_paris)} transactions in Paris saved\")\n",
    "print(f\"Columns: {list(dvf_mutations_paris.columns)}\")\n",
    "print(f\"Geometry preserved: {dvf_mutations_paris.geometry.notna().sum()} parcels with geometry ({dvf_mutations_paris.geometry.notna().sum()/len(dvf_mutations_paris)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8vuei9lymvo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - DVF MUTATIONS\n",
      "============================================================\n",
      "Number of transactions: 457097\n",
      "Number of rows: 457097\n",
      "Number of columns: 10\n",
      "Columns: ['datemut', 'anneemut', 'moismut', 'coddep', 'l_codinsee', 'valeurfonc', 'libtypbien', 'codtypbien', 'sbati', 'geometry']\n",
      "\n",
      "Date range: 2014-01-02 to 2024-12-31\n",
      "Years covered: [np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "\n",
      "Total transaction value: 337,968,281,467 EUR\n",
      "Average transaction value: 739,820.02 EUR\n",
      "\n",
      "Property types:\n",
      "libtypbien\n",
      "UN APPARTEMENT                               330601\n",
      "UNE DEPENDANCE                                51776\n",
      "ACTIVITE                                      29326\n",
      "DEUX APPARTEMENTS                             16431\n",
      "BATI MIXTE - LOGEMENT/ACTIVITE                 7705\n",
      "DES DEPENDANCES                                7327\n",
      "APPARTEMENT INDETERMINE                        6346\n",
      "BATI - INDETERMINE : Vefa sans descriptif      4184\n",
      "UNE MAISON                                     1614\n",
      "BATI - INDETERMINE : Vente avec volume(s)      1267\n",
      "TERRAIN ARTIFICIALISE MIXTE                     250\n",
      "TERRAIN DE TYPE TAB                             101\n",
      "BATI MIXTE - LOGEMENTS                           89\n",
      "DES MAISONS                                      53\n",
      "TERRAIN DE TYPE RESEAU                           17\n",
      "TERRAIN D'AGREMENT                                9\n",
      "MAISON - INDETERMINEE                             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Geometry information:\n",
      "  Has geometry column: True\n",
      "  Non-null geometries: 456962\n",
      "Number of transactions: 457097\n",
      "Number of rows: 457097\n",
      "Number of columns: 10\n",
      "Columns: ['datemut', 'anneemut', 'moismut', 'coddep', 'l_codinsee', 'valeurfonc', 'libtypbien', 'codtypbien', 'sbati', 'geometry']\n",
      "\n",
      "Date range: 2014-01-02 to 2024-12-31\n",
      "Years covered: [np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "\n",
      "Total transaction value: 337,968,281,467 EUR\n",
      "Average transaction value: 739,820.02 EUR\n",
      "\n",
      "Property types:\n",
      "libtypbien\n",
      "UN APPARTEMENT                               330601\n",
      "UNE DEPENDANCE                                51776\n",
      "ACTIVITE                                      29326\n",
      "DEUX APPARTEMENTS                             16431\n",
      "BATI MIXTE - LOGEMENT/ACTIVITE                 7705\n",
      "DES DEPENDANCES                                7327\n",
      "APPARTEMENT INDETERMINE                        6346\n",
      "BATI - INDETERMINE : Vefa sans descriptif      4184\n",
      "UNE MAISON                                     1614\n",
      "BATI - INDETERMINE : Vente avec volume(s)      1267\n",
      "TERRAIN ARTIFICIALISE MIXTE                     250\n",
      "TERRAIN DE TYPE TAB                             101\n",
      "BATI MIXTE - LOGEMENTS                           89\n",
      "DES MAISONS                                      53\n",
      "TERRAIN DE TYPE RESEAU                           17\n",
      "TERRAIN D'AGREMENT                                9\n",
      "MAISON - INDETERMINEE                             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Geometry information:\n",
      "  Has geometry column: True\n",
      "  Non-null geometries: 456962\n",
      "  Geometry types: ['MultiPolygon']\n",
      "\n",
      "Data types:\n",
      "datemut         object\n",
      "anneemut         int64\n",
      "moismut          int64\n",
      "coddep          object\n",
      "l_codinsee      object\n",
      "valeurfonc     float64\n",
      "libtypbien      object\n",
      "codtypbien      object\n",
      "sbati          float64\n",
      "geometry      geometry\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "datemut         0\n",
      "anneemut        0\n",
      "moismut         0\n",
      "coddep          0\n",
      "l_codinsee      0\n",
      "valeurfonc    272\n",
      "libtypbien      0\n",
      "codtypbien      0\n",
      "sbati           0\n",
      "geometry      135\n",
      "dtype: int64\n",
      "============================================================\n",
      "  Geometry types: ['MultiPolygon']\n",
      "\n",
      "Data types:\n",
      "datemut         object\n",
      "anneemut         int64\n",
      "moismut          int64\n",
      "coddep          object\n",
      "l_codinsee      object\n",
      "valeurfonc     float64\n",
      "libtypbien      object\n",
      "codtypbien      object\n",
      "sbati          float64\n",
      "geometry      geometry\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "datemut         0\n",
      "anneemut        0\n",
      "moismut         0\n",
      "coddep          0\n",
      "l_codinsee      0\n",
      "valeurfonc    272\n",
      "libtypbien      0\n",
      "codtypbien      0\n",
      "sbati           0\n",
      "geometry      135\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify DVF Mutations data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - DVF MUTATIONS\")\n",
    "print(\"=\" * 60)\n",
    "loaded_dvf = gpd.read_parquet(datasets_dir / 'dvf_mutations_paris.parquet')\n",
    "print(f\"Number of transactions: {len(loaded_dvf)}\")\n",
    "print(f\"Number of rows: {len(loaded_dvf)}\")\n",
    "print(f\"Number of columns: {len(loaded_dvf.columns)}\")\n",
    "print(f\"Columns: {list(loaded_dvf.columns)}\")\n",
    "print(f\"\\nDate range: {loaded_dvf['datemut'].min()} to {loaded_dvf['datemut'].max()}\")\n",
    "print(f\"Years covered: {sorted(loaded_dvf['anneemut'].unique())}\")\n",
    "print(f\"\\nTotal transaction value: {loaded_dvf['valeurfonc'].sum():,.0f} EUR\")\n",
    "print(f\"Average transaction value: {loaded_dvf['valeurfonc'].mean():,.2f} EUR\")\n",
    "print(f\"\\nProperty types:\")\n",
    "print(loaded_dvf['libtypbien'].value_counts())\n",
    "print(f\"\\nGeometry information:\")\n",
    "print(f\"  Has geometry column: {'geometry' in loaded_dvf.columns}\")\n",
    "if 'geometry' in loaded_dvf.columns:\n",
    "    print(f\"  Non-null geometries: {loaded_dvf.geometry.notna().sum()}\")\n",
    "    print(f\"  Geometry types: {loaded_dvf[loaded_dvf.geometry.notna()].geometry.geom_type.unique()}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_dvf.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_dvf.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s7uqc2xy30p",
   "metadata": {},
   "source": [
    "## 5. Load IRIS GeoJSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b2bbc",
   "metadata": {},
   "source": [
    "Geographic boundaries for IRIS zones in France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "qu2zsga8psj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IRIS GeoJSON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yWwsp5LcykD5UtvVPj_S695ALSKsCskP\n",
      "To: /workspaces/thesis/raw_datasets/iris.geojson\n",
      "100%|██████████| 11.6M/11.6M [00:00<00:00, 52.2MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS GeoJSON: 992 IRIS zones in Paris saved\n",
      "Columns: ['dep', 'insee_com', 'nom_com', 'iris', 'code_iris', 'nom_iris', 'typ_iris', 'geo_point_2d', 'id', 'geometry']\n"
     ]
    }
   ],
   "source": [
    "# IRIS GeoJSON - Geographic boundaries\n",
    "print(\"Loading IRIS GeoJSON...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1yWwsp5LcykD5UtvVPj_S695ALSKsCskP'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'iris.geojson'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "iris_geo = gpd.read_file(raw_file)\n",
    "\n",
    "# Filter for Paris intra-muros using the code_iris column (full 9-digit code)\n",
    "iris_geo_paris = iris_geo[iris_geo['code_iris'].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Save to datasets folder\n",
    "iris_geo_paris.to_file(datasets_dir / 'iris_paris.geojson', driver='GeoJSON')\n",
    "print(f\"IRIS GeoJSON: {len(iris_geo_paris)} IRIS zones in Paris saved\")\n",
    "print(f\"Columns: {list(iris_geo_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4xgrequ31u",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - IRIS GEOJSON\n",
      "============================================================\n",
      "Number of IRIS zones: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 10\n",
      "Columns: ['dep', 'insee_com', 'nom_com', 'iris', 'code_iris', 'nom_iris', 'typ_iris', 'geo_point_2d', 'id', 'geometry']\n",
      "\n",
      "CRS (Coordinate Reference System): EPSG:4326\n",
      "Geometry type: ['Polygon' 'MultiPolygon']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751072601', '751072603', '751093605', '751114108', '751114404', '751186903', '751208022', '751156099', '751072705', '751072804']\n",
      "\n",
      "IRIS type distribution:\n",
      "typ_iris\n",
      "H    861\n",
      "A     88\n",
      "D     43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "dep               object\n",
      "insee_com          int32\n",
      "nom_com           object\n",
      "iris              object\n",
      "code_iris         object\n",
      "nom_iris          object\n",
      "typ_iris          object\n",
      "geo_point_2d      object\n",
      "id                object\n",
      "geometry        geometry\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "dep             0\n",
      "insee_com       0\n",
      "nom_com         0\n",
      "iris            0\n",
      "code_iris       0\n",
      "nom_iris        0\n",
      "typ_iris        0\n",
      "geo_point_2d    0\n",
      "id              0\n",
      "geometry        0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify IRIS GeoJSON data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - IRIS GEOJSON\")\n",
    "print(\"=\" * 60)\n",
    "loaded_iris_geo = gpd.read_file(datasets_dir / 'iris_paris.geojson')\n",
    "print(f\"Number of IRIS zones: {len(loaded_iris_geo)}\")\n",
    "print(f\"Number of rows: {len(loaded_iris_geo)}\")\n",
    "print(f\"Number of columns: {len(loaded_iris_geo.columns)}\")\n",
    "print(f\"Columns: {list(loaded_iris_geo.columns)}\")\n",
    "print(f\"\\nCRS (Coordinate Reference System): {loaded_iris_geo.crs}\")\n",
    "print(f\"Geometry type: {loaded_iris_geo.geometry.geom_type.unique()}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_iris_geo['code_iris'].head(10).tolist())\n",
    "print(f\"\\nIRIS type distribution:\")\n",
    "print(loaded_iris_geo['typ_iris'].value_counts())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_iris_geo.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_iris_geo.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdhvk4jle5",
   "metadata": {},
   "source": [
    "## 6. Export & Quality Check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a6000",
   "metadata": {},
   "source": [
    "All datasets have been filtered for Paris intra-muros and saved to the `datasets/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ooxw0je35r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASETS LOADED - PARIS INTRA-MUROS ONLY\n",
      "================================================================================\n",
      "\n",
      "RAW DATASETS:\n",
      "----------------------------------------\n",
      "census_2013.xlsx: 67.43 MB\n",
      "census_2017.xlsx: 42.63 MB\n",
      "census_2021.xlsx: 47.39 MB\n",
      "dvf_mutations.gpkg: 341.20 MB\n",
      "education_2013.xlsx: 35.34 MB\n",
      "education_2017.xlsx: 25.23 MB\n",
      "education_2021.xlsx: 27.81 MB\n",
      "filosofi_2013.xlsx: 4.81 MB\n",
      "filosofi_2017.xlsx: 2.63 MB\n",
      "filosofi_2021.xlsx: 2.69 MB\n",
      "iris.geojson: 11.11 MB\n",
      "\n",
      "PROCESSED DATASETS:\n",
      "----------------------------------------\n",
      "census_2013_paris.parquet: 0.11 MB\n",
      "census_2013_paris_clean.parquet: 0.12 MB\n",
      "census_2017_paris.parquet: 0.11 MB\n",
      "census_2017_paris_clean.parquet: 0.12 MB\n",
      "census_2021_paris.parquet: 0.11 MB\n",
      "census_2021_paris_clean.parquet: 0.12 MB\n",
      "dvf_mutations_paris.parquet: 109.86 MB\n",
      "dvf_mutations_paris_clean.parquet: 3.46 MB\n",
      "education_2013_paris.parquet: 0.02 MB\n",
      "education_2013_paris_clean.parquet: 0.02 MB\n",
      "education_2017_paris.parquet: 0.04 MB\n",
      "education_2017_paris_clean.parquet: 0.04 MB\n",
      "education_2021_paris.parquet: 0.04 MB\n",
      "education_2021_paris_clean.parquet: 0.04 MB\n",
      "filosofi_2013_paris.parquet: 0.02 MB\n",
      "filosofi_2013_paris_clean.parquet: 0.02 MB\n",
      "filosofi_2017_paris.parquet: 0.02 MB\n",
      "filosofi_2017_paris_clean.parquet: 0.02 MB\n",
      "filosofi_2021_paris.parquet: 0.02 MB\n",
      "filosofi_2021_paris_clean.parquet: 0.02 MB\n",
      "iris_paris.geojson: 0.88 MB\n",
      "iris_paris_clean.geojson: 0.88 MB\n",
      "paris_merged_2013.parquet: 0.03 MB\n",
      "paris_merged_2017.parquet: 0.03 MB\n",
      "paris_merged_2021.parquet: 0.03 MB\n",
      "paris_merged_all_years.parquet: 0.05 MB\n",
      "\n",
      "================================================================================\n",
      "DATA LOADING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Datasets summary:\n",
      "- 3 FILOSOFI datasets (2013, 2017, 2021) - Income data\n",
      "- 3 EDUCATION datasets (2013, 2017, 2021) - Higher education (Bac+3/4)\n",
      "- 3 CENSUS datasets (2013, 2017, 2021) - Population data\n",
      "- DVF Mutations - Real estate transactions\n",
      "- IRIS GeoJSON - Geographic boundaries for Paris IRIS zones\n",
      "\n",
      "Raw data saved in '../raw_datasets/' folder\n",
      "Processed data saved in '../datasets/' folder - all filtered for Paris only.\n",
      "census_2013.xlsx: 67.43 MB\n",
      "census_2017.xlsx: 42.63 MB\n",
      "census_2021.xlsx: 47.39 MB\n",
      "dvf_mutations.gpkg: 341.20 MB\n",
      "education_2013.xlsx: 35.34 MB\n",
      "education_2017.xlsx: 25.23 MB\n",
      "education_2021.xlsx: 27.81 MB\n",
      "filosofi_2013.xlsx: 4.81 MB\n",
      "filosofi_2017.xlsx: 2.63 MB\n",
      "filosofi_2021.xlsx: 2.69 MB\n",
      "iris.geojson: 11.11 MB\n",
      "\n",
      "PROCESSED DATASETS:\n",
      "----------------------------------------\n",
      "census_2013_paris.parquet: 0.11 MB\n",
      "census_2013_paris_clean.parquet: 0.12 MB\n",
      "census_2017_paris.parquet: 0.11 MB\n",
      "census_2017_paris_clean.parquet: 0.12 MB\n",
      "census_2021_paris.parquet: 0.11 MB\n",
      "census_2021_paris_clean.parquet: 0.12 MB\n",
      "dvf_mutations_paris.parquet: 109.86 MB\n",
      "dvf_mutations_paris_clean.parquet: 3.46 MB\n",
      "education_2013_paris.parquet: 0.02 MB\n",
      "education_2013_paris_clean.parquet: 0.02 MB\n",
      "education_2017_paris.parquet: 0.04 MB\n",
      "education_2017_paris_clean.parquet: 0.04 MB\n",
      "education_2021_paris.parquet: 0.04 MB\n",
      "education_2021_paris_clean.parquet: 0.04 MB\n",
      "filosofi_2013_paris.parquet: 0.02 MB\n",
      "filosofi_2013_paris_clean.parquet: 0.02 MB\n",
      "filosofi_2017_paris.parquet: 0.02 MB\n",
      "filosofi_2017_paris_clean.parquet: 0.02 MB\n",
      "filosofi_2021_paris.parquet: 0.02 MB\n",
      "filosofi_2021_paris_clean.parquet: 0.02 MB\n",
      "iris_paris.geojson: 0.88 MB\n",
      "iris_paris_clean.geojson: 0.88 MB\n",
      "paris_merged_2013.parquet: 0.03 MB\n",
      "paris_merged_2017.parquet: 0.03 MB\n",
      "paris_merged_2021.parquet: 0.03 MB\n",
      "paris_merged_all_years.parquet: 0.05 MB\n",
      "\n",
      "================================================================================\n",
      "DATA LOADING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Datasets summary:\n",
      "- 3 FILOSOFI datasets (2013, 2017, 2021) - Income data\n",
      "- 3 EDUCATION datasets (2013, 2017, 2021) - Higher education (Bac+3/4)\n",
      "- 3 CENSUS datasets (2013, 2017, 2021) - Population data\n",
      "- DVF Mutations - Real estate transactions\n",
      "- IRIS GeoJSON - Geographic boundaries for Paris IRIS zones\n",
      "\n",
      "Raw data saved in '../raw_datasets/' folder\n",
      "Processed data saved in '../datasets/' folder - all filtered for Paris only.\n"
     ]
    }
   ],
   "source": [
    "# Summary of all loaded datasets\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASETS LOADED - PARIS INTRA-MUROS ONLY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nRAW DATASETS:\")\n",
    "print(\"-\" * 40)\n",
    "raw_files = sorted(os.listdir(raw_datasets_dir))\n",
    "for file in raw_files:\n",
    "    file_path = raw_datasets_dir / file\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"{file}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\nPROCESSED DATASETS:\")\n",
    "print(\"-\" * 40)\n",
    "datasets_files = sorted(os.listdir(datasets_dir))\n",
    "for file in datasets_files:\n",
    "    file_path = datasets_dir / file\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"{file}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA LOADING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDatasets summary:\")\n",
    "print(\"- 3 FILOSOFI datasets (2013, 2017, 2021) - Income data\")\n",
    "print(\"- 3 EDUCATION datasets (2013, 2017, 2021) - Higher education (Bac+3/4)\")\n",
    "print(\"- 3 CENSUS datasets (2013, 2017, 2021) - Population data\")\n",
    "print(\"- DVF Mutations - Real estate transactions\")\n",
    "print(\"- IRIS GeoJSON - Geographic boundaries for Paris IRIS zones\")\n",
    "print(f\"\\nRaw data saved in '{raw_datasets_dir}/' folder\")\n",
    "print(f\"Processed data saved in '{datasets_dir}/' folder - all filtered for Paris only.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
