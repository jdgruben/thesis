{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47c3ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Datasets directory ready at: ../datasets\n",
      "Raw datasets directory ready at: ../raw_datasets\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import gdown\n",
    "\n",
    "# Create datasets and raw_datasets folders if they don't exist\n",
    "datasets_dir = Path('..') / 'datasets'\n",
    "raw_datasets_dir = Path('..') / 'raw_datasets'\n",
    "datasets_dir.mkdir(exist_ok=True)\n",
    "raw_datasets_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Setup complete. Datasets directory ready at: {datasets_dir}\")\n",
    "print(f\"Raw datasets directory ready at: {raw_datasets_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p3w9f1kbuoi",
   "metadata": {},
   "source": [
    "## 1. Load FILOSOFI Datasets (2013, 2017, 2021)\n",
    "FILOSOFI datasets contain income and living standards data at IRIS level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bpra809573q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1fRbArcfw_DHrycI11NsjbosnXCp6Nh26\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2013.xlsx\n",
      "100%|██████████| 5.04M/5.04M [00:00<00:00, 102MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6013', 'DISP_Q113', 'DISP_MED13', 'DISP_Q313', 'DISP_EQ13', 'DISP_D113', 'DISP_D213', 'DISP_D313', 'DISP_D413', 'DISP_D613', 'DISP_D713', 'DISP_D813', 'DISP_D913', 'DISP_RD13', 'DISP_S80S2013', 'DISP_GI13', 'DISP_PTSAC13', 'DISP_PBEN13', 'DISP_PPEN13', 'DISP_PPAT13', 'DISP_PPSOC13', 'DISP_PPFAM13', 'DISP_PPMINI13', 'DISP_PPLOGT13', 'DISP_PIMPOT13']\n",
      "FILOSOFI 2013: 853 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc', 'q1_uc', 'q3_uc', 'd9d1_ratio', 'gini', 'share_activity_income', 'share_pensions', 'share_social_benefits']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2013\n",
    "print(\"Loading FILOSOFI 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1fRbArcfw_DHrycI11NsjbosnXCp6Nh26'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2013.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED13': 'median_uc',\n",
    "    'DISP_Q113': 'q1_uc',\n",
    "    'DISP_Q313': 'q3_uc',\n",
    "    'DISP_RD13': 'd9d1_ratio',\n",
    "    'DISP_GI13': 'gini',\n",
    "    'DISP_PTSAC13': 'share_activity_income',\n",
    "    'DISP_PPEN13': 'share_pensions',\n",
    "    'DISP_PPSOC13': 'share_social_benefits',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros (département 75)\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2013_paris = filosofi_2013[filosofi_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2013_paris.columns]\n",
    "filosofi_2013_paris = filosofi_2013_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2013_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2013_paris.to_parquet(datasets_dir / 'filosofi_2013_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2013: {len(filosofi_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ewz3ck2y91r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - FILOSOFI 2013\n",
      "============================================================\n",
      "Number of IRIS: 853\n",
      "Number of rows: 853\n",
      "Number of columns: 10\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc', 'q1_uc', 'q3_uc', 'd9d1_ratio', 'gini', 'share_activity_income', 'share_pensions', 'share_social_benefits']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010201', '751010202', '751010203', '751010204', '751010301', '751010401', '751020601', '751020701', '751020702', '751020703']\n",
      "\n",
      "Data types:\n",
      "code_iris                 object\n",
      "libelle_iris              object\n",
      "median_uc                float64\n",
      "q1_uc                    float64\n",
      "q3_uc                    float64\n",
      "d9d1_ratio               float64\n",
      "gini                     float64\n",
      "share_activity_income    float64\n",
      "share_pensions           float64\n",
      "share_social_benefits    float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris                0\n",
      "libelle_iris             0\n",
      "median_uc                0\n",
      "q1_uc                    0\n",
      "q3_uc                    0\n",
      "d9d1_ratio               0\n",
      "gini                     0\n",
      "share_activity_income    0\n",
      "share_pensions           0\n",
      "share_social_benefits    0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify FILOSOFI 2013 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - FILOSOFI 2013\")\n",
    "print(\"=\" * 60)\n",
    "loaded_filosofi_2013 = pd.read_parquet(datasets_dir / 'filosofi_2013_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_filosofi_2013)}\")\n",
    "print(f\"Number of rows: {len(loaded_filosofi_2013)}\")\n",
    "print(f\"Number of columns: {len(loaded_filosofi_2013.columns)}\")\n",
    "print(f\"Columns: {list(loaded_filosofi_2013.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_filosofi_2013['code_iris'].head(10).tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_filosofi_2013.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_filosofi_2013.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "w0huionnxs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1IhvzpWGInGlDj7Xpi4kHP87msylR7hiQ\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2017.xlsx\n",
      "100%|██████████| 2.76M/2.76M [00:00<00:00, 79.5MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6017', 'DISP_Q117', 'DISP_MED17', 'DISP_Q317', 'DISP_EQ17', 'DISP_D117', 'DISP_D217', 'DISP_D317', 'DISP_D417', 'DISP_D617', 'DISP_D717', 'DISP_D817', 'DISP_D917', 'DISP_RD17', 'DISP_S80S2017', 'DISP_GI17', 'DISP_PACT17', 'DISP_PTSA17', 'DISP_PCHO17', 'DISP_PBEN17', 'DISP_PPEN17', 'DISP_PPAT17', 'DISP_PPSOC17', 'DISP_PPFAM17', 'DISP_PPMINI17', 'DISP_PPLOGT17', 'DISP_PIMPOT17', 'DISP_NOTE17']\n",
      "FILOSOFI 2017: 871 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc', 'q1_uc', 'q3_uc', 'd9d1_ratio', 'gini', 'share_activity_income', 'share_pensions', 'share_social_benefits']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2017\n",
    "print(\"Loading FILOSOFI 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1IhvzpWGInGlDj7Xpi4kHP87msylR7hiQ'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2017.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED17': 'median_uc',\n",
    "    'DISP_Q117': 'q1_uc',\n",
    "    'DISP_Q317': 'q3_uc',\n",
    "    'DISP_RD17': 'd9d1_ratio',\n",
    "    'DISP_GI17': 'gini',\n",
    "    'DISP_PACT17': 'share_activity_income',\n",
    "    'DISP_PPEN17': 'share_pensions',\n",
    "    'DISP_PPSOC17': 'share_social_benefits',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2017_paris = filosofi_2017[filosofi_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2017_paris.columns]\n",
    "filosofi_2017_paris = filosofi_2017_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2017_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2017_paris.to_parquet(datasets_dir / 'filosofi_2017_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2017: {len(filosofi_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "sm4m8l2cpb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - FILOSOFI 2017\n",
      "============================================================\n",
      "Number of IRIS: 871\n",
      "Number of rows: 871\n",
      "Number of columns: 10\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc', 'q1_uc', 'q3_uc', 'd9d1_ratio', 'gini', 'share_activity_income', 'share_pensions', 'share_social_benefits']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010201', '751010202', '751010203', '751010204', '751010301', '751010401', '751010402', '751020601', '751020602', '751020701']\n",
      "\n",
      "Data types:\n",
      "code_iris                 object\n",
      "libelle_iris              object\n",
      "median_uc                float64\n",
      "q1_uc                    float64\n",
      "q3_uc                    float64\n",
      "d9d1_ratio               float64\n",
      "gini                     float64\n",
      "share_activity_income    float64\n",
      "share_pensions           float64\n",
      "share_social_benefits    float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris                0\n",
      "libelle_iris             0\n",
      "median_uc                1\n",
      "q1_uc                    1\n",
      "q3_uc                    1\n",
      "d9d1_ratio               1\n",
      "gini                     1\n",
      "share_activity_income    1\n",
      "share_pensions           1\n",
      "share_social_benefits    1\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify FILOSOFI 2017 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - FILOSOFI 2017\")\n",
    "print(\"=\" * 60)\n",
    "loaded_filosofi_2017 = pd.read_parquet(datasets_dir / 'filosofi_2017_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_filosofi_2017)}\")\n",
    "print(f\"Number of rows: {len(loaded_filosofi_2017)}\")\n",
    "print(f\"Number of columns: {len(loaded_filosofi_2017.columns)}\")\n",
    "print(f\"Columns: {list(loaded_filosofi_2017.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_filosofi_2017['code_iris'].head(10).tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_filosofi_2017.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_filosofi_2017.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "hvqfjbnda9g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Har2wCg63dQZSTWYxmyXQ0DcQ0dHylX8\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2021.xlsx\n",
      "100%|██████████| 2.82M/2.82M [00:00<00:00, 138MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6021', 'DISP_INCERT21', 'DISP_Q121', 'DISP_MED21', 'DISP_Q321', 'DISP_EQ21', 'DISP_D121', 'DISP_D221', 'DISP_D321', 'DISP_D421', 'DISP_D621', 'DISP_D721', 'DISP_D821', 'DISP_D921', 'DISP_RD21', 'DISP_S80S2021', 'DISP_GI21', 'DISP_PACT21', 'DISP_PTSA21', 'DISP_PCHO21', 'DISP_PBEN21', 'DISP_PPEN21', 'DISP_PPAT21', 'DISP_PPSOC21', 'DISP_PPFAM21', 'DISP_PPMINI21', 'DISP_PPLOGT21', 'DISP_PIMPOT21', 'DISP_NOTE21']\n",
      "FILOSOFI 2021: 992 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc', 'q1_uc', 'q3_uc', 'd9d1_ratio', 'gini', 'share_activity_income', 'share_pensions', 'share_social_benefits']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2021\n",
    "print(\"Loading FILOSOFI 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1Har2wCg63dQZSTWYxmyXQ0DcQ0dHylX8'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2021.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED21': 'median_uc',\n",
    "    'DISP_Q121': 'q1_uc',\n",
    "    'DISP_Q321': 'q3_uc',\n",
    "    'DISP_RD21': 'd9d1_ratio',\n",
    "    'DISP_GI21': 'gini',\n",
    "    'DISP_PACT21': 'share_activity_income',\n",
    "    'DISP_PPEN21': 'share_pensions',\n",
    "    'DISP_PPSOC21': 'share_social_benefits',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2021_paris = filosofi_2021[filosofi_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2021_paris.columns]\n",
    "filosofi_2021_paris = filosofi_2021_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2021_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2021_paris.to_parquet(datasets_dir / 'filosofi_2021_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2021: {len(filosofi_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c1z05jym69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - FILOSOFI 2021\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 10\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc', 'q1_uc', 'q3_uc', 'd9d1_ratio', 'gini', 'share_activity_income', 'share_pensions', 'share_social_benefits']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Data types:\n",
      "code_iris                object\n",
      "libelle_iris             object\n",
      "median_uc                object\n",
      "q1_uc                    object\n",
      "q3_uc                    object\n",
      "d9d1_ratio               object\n",
      "gini                     object\n",
      "share_activity_income    object\n",
      "share_pensions           object\n",
      "share_social_benefits    object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris                0\n",
      "libelle_iris             0\n",
      "median_uc                0\n",
      "q1_uc                    0\n",
      "q3_uc                    0\n",
      "d9d1_ratio               0\n",
      "gini                     0\n",
      "share_activity_income    0\n",
      "share_pensions           0\n",
      "share_social_benefits    0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify FILOSOFI 2021 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - FILOSOFI 2021\")\n",
    "print(\"=\" * 60)\n",
    "loaded_filosofi_2021 = pd.read_parquet(datasets_dir / 'filosofi_2021_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_filosofi_2021)}\")\n",
    "print(f\"Number of rows: {len(loaded_filosofi_2021)}\")\n",
    "print(f\"Number of columns: {len(loaded_filosofi_2021.columns)}\")\n",
    "print(f\"Columns: {list(loaded_filosofi_2021.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_filosofi_2021['code_iris'].head(10).tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_filosofi_2021.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_filosofi_2021.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ukcqdhd3j",
   "metadata": {},
   "source": [
    "## 2. Load CENSUS Datasets (2013, 2017, 2021)\n",
    "Census datasets contain population structure and evolution data at IRIS level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "w3y327puth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1b2LTSza0fRFkuVnvni60cKWKi51g3BQh\n",
      "To: /workspaces/thesis/raw_datasets/census_2013.xlsx\n",
      "100%|██████████| 70.7M/70.7M [00:00<00:00, 127MB/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2013: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2013\n",
    "print(\"Loading CENSUS 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1b2LTSza0fRFkuVnvni60cKWKi51g3BQh'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2013.columns if 'IRIS' in col.upper()][0]\n",
    "census_2013_paris = census_2013[census_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P13_POP': 'pop_total',\n",
    "    'C13_POP15P': 'pop_15plus',\n",
    "    'C13_POP15P_CS3': 'pop_cadres',\n",
    "    'C13_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C13_POP15P_CS5': 'pop_employes',\n",
    "    'C13_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P13_POP1824': 'pop_18_24',\n",
    "    'P13_POP2539': 'pop_25_39',\n",
    "    'P13_POP65P': 'pop_65plus',\n",
    "    'P13_POP_IMM': 'pop_immigres',\n",
    "    'P13_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2013_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2013_paris = census_2013_paris[cols_to_keep].copy()\n",
    "census_2013_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "census_2013_paris.to_parquet(datasets_dir / 'census_2013_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2013: {len(census_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "wbhb53fyaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - CENSUS 2013\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 13\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Total population across all IRIS: 2,229,621\n",
      "\n",
      "Data types:\n",
      "code_iris          object\n",
      "typ_iris           object\n",
      "pop_total         float64\n",
      "pop_15plus        float64\n",
      "pop_cadres        float64\n",
      "pop_prof_inter    float64\n",
      "pop_employes      float64\n",
      "pop_ouvriers      float64\n",
      "pop_18_24         float64\n",
      "pop_25_39         float64\n",
      "pop_65plus        float64\n",
      "pop_immigres      float64\n",
      "pop_etrangers     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris         0\n",
      "typ_iris          0\n",
      "pop_total         0\n",
      "pop_15plus        0\n",
      "pop_cadres        0\n",
      "pop_prof_inter    0\n",
      "pop_employes      0\n",
      "pop_ouvriers      0\n",
      "pop_18_24         0\n",
      "pop_25_39         0\n",
      "pop_65plus        0\n",
      "pop_immigres      0\n",
      "pop_etrangers     0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CENSUS 2013 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - CENSUS 2013\")\n",
    "print(\"=\" * 60)\n",
    "loaded_census_2013 = pd.read_parquet(datasets_dir / 'census_2013_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_census_2013)}\")\n",
    "print(f\"Number of rows: {len(loaded_census_2013)}\")\n",
    "print(f\"Number of columns: {len(loaded_census_2013.columns)}\")\n",
    "print(f\"Columns: {list(loaded_census_2013.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_census_2013['code_iris'].head(10).tolist())\n",
    "print(f\"\\nTotal population across all IRIS: {loaded_census_2013['pop_total'].sum():,.0f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_census_2013.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_census_2013.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2jpiae70h58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1KHGwB0S8D-gj7f3d3LBCzRjqBWxaewzw\n",
      "To: /workspaces/thesis/raw_datasets/census_2017.xlsx\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 95.2MB/s]\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 95.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2017: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2017\n",
    "print(\"Loading CENSUS 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1KHGwB0S8D-gj7f3d3LBCzRjqBWxaewzw'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2017.columns if 'IRIS' in col.upper()][0]\n",
    "census_2017_paris = census_2017[census_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables (2017 uses P17_ prefix)\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P17_POP': 'pop_total',\n",
    "    'C17_POP15P': 'pop_15plus',\n",
    "    'C17_POP15P_CS3': 'pop_cadres',\n",
    "    'C17_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C17_POP15P_CS5': 'pop_employes',\n",
    "    'C17_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P17_POP1824': 'pop_18_24',\n",
    "    'P17_POP2539': 'pop_25_39',\n",
    "    'P17_POP65P': 'pop_65plus',\n",
    "    'P17_POP_IMM': 'pop_immigres',\n",
    "    'P17_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2017_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2017_paris = census_2017_paris[cols_to_keep].copy()\n",
    "census_2017_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "census_2017_paris.to_parquet(datasets_dir / 'census_2017_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2017: {len(census_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6494ygacjh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - CENSUS 2017\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 13\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Total population across all IRIS: 2,187,526\n",
      "\n",
      "Data types:\n",
      "code_iris          object\n",
      "typ_iris           object\n",
      "pop_total         float64\n",
      "pop_15plus        float64\n",
      "pop_cadres        float64\n",
      "pop_prof_inter    float64\n",
      "pop_employes      float64\n",
      "pop_ouvriers      float64\n",
      "pop_18_24         float64\n",
      "pop_25_39         float64\n",
      "pop_65plus        float64\n",
      "pop_immigres      float64\n",
      "pop_etrangers     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris         0\n",
      "typ_iris          0\n",
      "pop_total         0\n",
      "pop_15plus        0\n",
      "pop_cadres        0\n",
      "pop_prof_inter    0\n",
      "pop_employes      0\n",
      "pop_ouvriers      0\n",
      "pop_18_24         0\n",
      "pop_25_39         0\n",
      "pop_65plus        0\n",
      "pop_immigres      0\n",
      "pop_etrangers     0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CENSUS 2017 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - CENSUS 2017\")\n",
    "print(\"=\" * 60)\n",
    "loaded_census_2017 = pd.read_parquet(datasets_dir / 'census_2017_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_census_2017)}\")\n",
    "print(f\"Number of rows: {len(loaded_census_2017)}\")\n",
    "print(f\"Number of columns: {len(loaded_census_2017.columns)}\")\n",
    "print(f\"Columns: {list(loaded_census_2017.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_census_2017['code_iris'].head(10).tolist())\n",
    "print(f\"\\nTotal population across all IRIS: {loaded_census_2017['pop_total'].sum():,.0f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_census_2017.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_census_2017.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adem7qp2of4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yfZ3EYbtnDaRhDWvP_u8ovC6HwQNuq9s\n",
      "To: /workspaces/thesis/raw_datasets/census_2021.xlsx\n",
      "100%|██████████| 49.7M/49.7M [00:00<00:00, 76.2MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2021: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2021\n",
    "print(\"Loading CENSUS 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1yfZ3EYbtnDaRhDWvP_u8ovC6HwQNuq9s'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2021.columns if 'IRIS' in col.upper()][0]\n",
    "census_2021_paris = census_2021[census_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables (2021 uses P21_ prefix)\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P21_POP': 'pop_total',\n",
    "    'C21_POP15P': 'pop_15plus',\n",
    "    'C21_POP15P_CS3': 'pop_cadres',\n",
    "    'C21_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C21_POP15P_CS5': 'pop_employes',\n",
    "    'C21_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P21_POP1824': 'pop_18_24',\n",
    "    'P21_POP2539': 'pop_25_39',\n",
    "    'P21_POP65P': 'pop_65plus',\n",
    "    'P21_POP_IMM': 'pop_immigres',\n",
    "    'P21_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2021_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2021_paris = census_2021_paris[cols_to_keep].copy()\n",
    "census_2021_paris.columns = final_names\n",
    "\n",
    "# Save to data folder\n",
    "census_2021_paris.to_parquet(datasets_dir / 'census_2021_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2021: {len(census_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "i91s2f90il9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - CENSUS 2021\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 13\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Total population across all IRIS: 2,133,111\n",
      "\n",
      "Data types:\n",
      "code_iris          object\n",
      "typ_iris           object\n",
      "pop_total         float64\n",
      "pop_15plus        float64\n",
      "pop_cadres        float64\n",
      "pop_prof_inter    float64\n",
      "pop_employes      float64\n",
      "pop_ouvriers      float64\n",
      "pop_18_24         float64\n",
      "pop_25_39         float64\n",
      "pop_65plus        float64\n",
      "pop_immigres      float64\n",
      "pop_etrangers     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris         0\n",
      "typ_iris          0\n",
      "pop_total         0\n",
      "pop_15plus        0\n",
      "pop_cadres        0\n",
      "pop_prof_inter    0\n",
      "pop_employes      0\n",
      "pop_ouvriers      0\n",
      "pop_18_24         0\n",
      "pop_25_39         0\n",
      "pop_65plus        0\n",
      "pop_immigres      0\n",
      "pop_etrangers     0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CENSUS 2021 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - CENSUS 2021\")\n",
    "print(\"=\" * 60)\n",
    "loaded_census_2021 = pd.read_parquet(datasets_dir / 'census_2021_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_census_2021)}\")\n",
    "print(f\"Number of rows: {len(loaded_census_2021)}\")\n",
    "print(f\"Number of columns: {len(loaded_census_2021.columns)}\")\n",
    "print(f\"Columns: {list(loaded_census_2021.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_census_2021['code_iris'].head(10).tolist())\n",
    "print(f\"\\nTotal population across all IRIS: {loaded_census_2021['pop_total'].sum():,.0f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_census_2021.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_census_2021.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u7o4zrdrvym",
   "metadata": {},
   "source": [
    "## 3. Load DVF Mutations Dataset\n",
    "Real estate transaction data (Demandes de Valeurs Foncières)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59a7888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DVF Mutations dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN\n",
      "From (redirected): https://drive.google.com/uc?id=1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN&confirm=t&uuid=397a107a-1f24-4c94-a9e0-a1de93c56c7c\n",
      "To: /workspaces/thesis/raw_datasets/dvf_mutations.gpkg\n",
      "100%|██████████| 358M/358M [00:04<00:00, 86.4MB/s] \n",
      "100%|██████████| 358M/358M [00:04<00:00, 86.4MB/s]\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pyogrio/geopandas.py:275: UserWarning: More than one layer found in 'dvf_mutations.gpkg': 'mutation_geompar' (default), 'mutation_geomparmut', 'mutation_geomlocmut'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pyogrio/geopandas.py:275: UserWarning: More than one layer found in 'dvf_mutations.gpkg': 'mutation_geompar' (default), 'mutation_geomparmut', 'mutation_geomlocmut'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVF Mutations: 457097 transactions in Paris saved\n",
      "Columns: ['datemut', 'anneemut', 'moismut', 'coddep', 'l_codinsee', 'valeurfonc', 'libtypbien', 'codtypbien', 'sbati', 'nblot', 'nbapt1pp', 'nbapt2pp', 'nbapt3pp', 'nbapt4pp', 'nbapt5pp', 'nbmai1pp', 'nbmai2pp', 'nbmai3pp', 'nbmai4pp', 'nbmai5pp']\n"
     ]
    }
   ],
   "source": [
    "# DVF Mutations - Download from Google Drive using gdown\n",
    "# File ID: 1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN\n",
    "print(\"Loading DVF Mutations dataset...\")\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# Download file\n",
    "file_id = '1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'dvf_mutations.gpkg'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "# Read and filter\n",
    "dvf_mutations = gpd.read_file(raw_file)\n",
    "dvf_mutations_paris = dvf_mutations[dvf_mutations['coddep'] == '75'].copy()\n",
    "\n",
    "# Keep only selected columns\n",
    "columns_to_keep = [\n",
    "    'datemut', 'anneemut', 'moismut',  # temporal\n",
    "    'coddep', 'l_codinsee',  # spatial\n",
    "    'valeurfonc',  # transaction value\n",
    "    'libtypbien', 'codtypbien',  # property type\n",
    "    'sbati',  # built surface\n",
    "    'nblot',  # lot characteristics\n",
    "    'nbapt1pp', 'nbapt2pp', 'nbapt3pp', 'nbapt4pp', 'nbapt5pp',  # apartments\n",
    "    'nbmai1pp', 'nbmai2pp', 'nbmai3pp', 'nbmai4pp', 'nbmai5pp'   # houses\n",
    "]\n",
    "\n",
    "# Only keep columns that exist\n",
    "existing_columns = [col for col in columns_to_keep if col in dvf_mutations_paris.columns]\n",
    "dvf_mutations_paris = dvf_mutations_paris[existing_columns].copy()\n",
    "\n",
    "# Save to parquet\n",
    "dvf_mutations_paris.to_parquet(datasets_dir / 'dvf_mutations_paris.parquet', index=False)\n",
    "print(f\"DVF Mutations: {len(dvf_mutations_paris)} transactions in Paris saved\")\n",
    "print(f\"Columns: {list(dvf_mutations_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8vuei9lymvo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - DVF MUTATIONS\n",
      "============================================================\n",
      "Number of transactions: 457097\n",
      "Number of rows: 457097\n",
      "Number of columns: 20\n",
      "Columns: ['datemut', 'anneemut', 'moismut', 'coddep', 'l_codinsee', 'valeurfonc', 'libtypbien', 'codtypbien', 'sbati', 'nblot', 'nbapt1pp', 'nbapt2pp', 'nbapt3pp', 'nbapt4pp', 'nbapt5pp', 'nbmai1pp', 'nbmai2pp', 'nbmai3pp', 'nbmai4pp', 'nbmai5pp']\n",
      "\n",
      "Date range: 2014-01-02 to 2024-12-31\n",
      "Years covered: [np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "\n",
      "Total transaction value: 337,968,281,467 EUR\n",
      "Average transaction value: 739,820.02 EUR\n",
      "\n",
      "Property types:\n",
      "libtypbien\n",
      "UN APPARTEMENT                               330601\n",
      "UNE DEPENDANCE                                51776\n",
      "ACTIVITE                                      29326\n",
      "DEUX APPARTEMENTS                             16431\n",
      "BATI MIXTE - LOGEMENT/ACTIVITE                 7705\n",
      "DES DEPENDANCES                                7327\n",
      "APPARTEMENT INDETERMINE                        6346\n",
      "BATI - INDETERMINE : Vefa sans descriptif      4184\n",
      "UNE MAISON                                     1614\n",
      "BATI - INDETERMINE : Vente avec volume(s)      1267\n",
      "TERRAIN ARTIFICIALISE MIXTE                     250\n",
      "TERRAIN DE TYPE TAB                             101\n",
      "BATI MIXTE - LOGEMENTS                           89\n",
      "DES MAISONS                                      53\n",
      "TERRAIN DE TYPE RESEAU                           17\n",
      "TERRAIN D'AGREMENT                                9\n",
      "MAISON - INDETERMINEE                             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "datemut        object\n",
      "anneemut        int64\n",
      "moismut         int64\n",
      "coddep         object\n",
      "l_codinsee     object\n",
      "valeurfonc    float64\n",
      "libtypbien     object\n",
      "codtypbien     object\n",
      "sbati         float64\n",
      "nblot           int64\n",
      "nbapt1pp        int64\n",
      "nbapt2pp        int64\n",
      "nbapt3pp        int64\n",
      "nbapt4pp        int64\n",
      "nbapt5pp        int64\n",
      "nbmai1pp        int64\n",
      "nbmai2pp        int64\n",
      "nbmai3pp        int64\n",
      "nbmai4pp        int64\n",
      "nbmai5pp        int64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "datemut         0\n",
      "anneemut        0\n",
      "moismut         0\n",
      "coddep          0\n",
      "l_codinsee      0\n",
      "valeurfonc    272\n",
      "libtypbien      0\n",
      "codtypbien      0\n",
      "sbati           0\n",
      "nblot           0\n",
      "nbapt1pp        0\n",
      "nbapt2pp        0\n",
      "nbapt3pp        0\n",
      "nbapt4pp        0\n",
      "nbapt5pp        0\n",
      "nbmai1pp        0\n",
      "nbmai2pp        0\n",
      "nbmai3pp        0\n",
      "nbmai4pp        0\n",
      "nbmai5pp        0\n",
      "dtype: int64\n",
      "============================================================\n",
      "datemut         0\n",
      "anneemut        0\n",
      "moismut         0\n",
      "coddep          0\n",
      "l_codinsee      0\n",
      "valeurfonc    272\n",
      "libtypbien      0\n",
      "codtypbien      0\n",
      "sbati           0\n",
      "nblot           0\n",
      "nbapt1pp        0\n",
      "nbapt2pp        0\n",
      "nbapt3pp        0\n",
      "nbapt4pp        0\n",
      "nbapt5pp        0\n",
      "nbmai1pp        0\n",
      "nbmai2pp        0\n",
      "nbmai3pp        0\n",
      "nbmai4pp        0\n",
      "nbmai5pp        0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify DVF Mutations data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - DVF MUTATIONS\")\n",
    "print(\"=\" * 60)\n",
    "loaded_dvf = pd.read_parquet(datasets_dir / 'dvf_mutations_paris.parquet')\n",
    "print(f\"Number of transactions: {len(loaded_dvf)}\")\n",
    "print(f\"Number of rows: {len(loaded_dvf)}\")\n",
    "print(f\"Number of columns: {len(loaded_dvf.columns)}\")\n",
    "print(f\"Columns: {list(loaded_dvf.columns)}\")\n",
    "print(f\"\\nDate range: {loaded_dvf['datemut'].min()} to {loaded_dvf['datemut'].max()}\")\n",
    "print(f\"Years covered: {sorted(loaded_dvf['anneemut'].unique())}\")\n",
    "print(f\"\\nTotal transaction value: {loaded_dvf['valeurfonc'].sum():,.0f} EUR\")\n",
    "print(f\"Average transaction value: {loaded_dvf['valeurfonc'].mean():,.2f} EUR\")\n",
    "print(f\"\\nProperty types:\")\n",
    "print(loaded_dvf['libtypbien'].value_counts())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_dvf.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_dvf.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aydqi2eol3",
   "metadata": {},
   "source": [
    "## 4. Load GEOFABRIK OSM Data\n",
    "OpenStreetMap data for Île-de-France region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "zl82496vf3o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GEOFABRIK OSM data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=10tnwqygnWErQRLZ__J6u2ez4Ct7qx_qo\n",
      "From (redirected): https://drive.google.com/uc?id=10tnwqygnWErQRLZ__J6u2ez4Ct7qx_qo&confirm=t&uuid=a2e9fd03-429f-40f7-8ef0-8ff4ffdf041d\n",
      "To: /workspaces/thesis/raw_datasets/geofabrik_idf.osm.pbf\n",
      "100%|██████████| 324M/324M [00:02<00:00, 160MB/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOFABRIK OSM data downloaded to ../raw_datasets/geofabrik_idf.osm.pbf\n",
      "Note: This OSM file covers Île-de-France and includes Paris. Use osmium or other tools to process.\n"
     ]
    }
   ],
   "source": [
    "# GEOFABRIK Île-de-France OSM data\n",
    "print(\"Loading GEOFABRIK OSM data...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '10tnwqygnWErQRLZ__J6u2ez4Ct7qx_qo'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'geofabrik_idf.osm.pbf'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "print(f\"GEOFABRIK OSM data downloaded to {raw_file}\")\n",
    "print(\"Note: This OSM file covers Île-de-France and includes Paris. Use osmium or other tools to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s7uqc2xy30p",
   "metadata": {},
   "source": [
    "## 5. Load IRIS GeoJSON\n",
    "Geographic boundaries for IRIS zones in France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "qu2zsga8psj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IRIS GeoJSON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yWwsp5LcykD5UtvVPj_S695ALSKsCskP\n",
      "To: /workspaces/thesis/raw_datasets/iris.geojson\n",
      "100%|██████████| 11.6M/11.6M [00:00<00:00, 97.1MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS GeoJSON: 992 IRIS zones in Paris saved\n",
      "Columns: ['dep', 'insee_com', 'nom_com', 'iris', 'code_iris', 'nom_iris', 'typ_iris', 'geo_point_2d', 'id', 'geometry']\n"
     ]
    }
   ],
   "source": [
    "# IRIS GeoJSON - Geographic boundaries\n",
    "print(\"Loading IRIS GeoJSON...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1yWwsp5LcykD5UtvVPj_S695ALSKsCskP'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'iris.geojson'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "iris_geo = gpd.read_file(raw_file)\n",
    "\n",
    "# Filter for Paris intra-muros using the code_iris column (full 9-digit code)\n",
    "iris_geo_paris = iris_geo[iris_geo['code_iris'].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Save to datasets folder\n",
    "iris_geo_paris.to_file(datasets_dir / 'iris_paris.geojson', driver='GeoJSON')\n",
    "print(f\"IRIS GeoJSON: {len(iris_geo_paris)} IRIS zones in Paris saved\")\n",
    "print(f\"Columns: {list(iris_geo_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4xgrequ31u",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - IRIS GEOJSON\n",
      "============================================================\n",
      "Number of IRIS zones: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 10\n",
      "Columns: ['dep', 'insee_com', 'nom_com', 'iris', 'code_iris', 'nom_iris', 'typ_iris', 'geo_point_2d', 'id', 'geometry']\n",
      "\n",
      "CRS (Coordinate Reference System): EPSG:4326\n",
      "Geometry type: ['Polygon' 'MultiPolygon']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751072601', '751072603', '751093605', '751114108', '751114404', '751186903', '751208022', '751156099', '751072705', '751072804']\n",
      "\n",
      "IRIS type distribution:\n",
      "typ_iris\n",
      "H    861\n",
      "A     88\n",
      "D     43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "dep               object\n",
      "insee_com          int32\n",
      "nom_com           object\n",
      "iris              object\n",
      "code_iris         object\n",
      "nom_iris          object\n",
      "typ_iris          object\n",
      "geo_point_2d      object\n",
      "id                object\n",
      "geometry        geometry\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "dep             0\n",
      "insee_com       0\n",
      "nom_com         0\n",
      "iris            0\n",
      "code_iris       0\n",
      "nom_iris        0\n",
      "typ_iris        0\n",
      "geo_point_2d    0\n",
      "id              0\n",
      "geometry        0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify IRIS GeoJSON data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - IRIS GEOJSON\")\n",
    "print(\"=\" * 60)\n",
    "loaded_iris_geo = gpd.read_file(datasets_dir / 'iris_paris.geojson')\n",
    "print(f\"Number of IRIS zones: {len(loaded_iris_geo)}\")\n",
    "print(f\"Number of rows: {len(loaded_iris_geo)}\")\n",
    "print(f\"Number of columns: {len(loaded_iris_geo.columns)}\")\n",
    "print(f\"Columns: {list(loaded_iris_geo.columns)}\")\n",
    "print(f\"\\nCRS (Coordinate Reference System): {loaded_iris_geo.crs}\")\n",
    "print(f\"Geometry type: {loaded_iris_geo.geometry.geom_type.unique()}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_iris_geo['code_iris'].head(10).tolist())\n",
    "print(f\"\\nIRIS type distribution:\")\n",
    "print(loaded_iris_geo['typ_iris'].value_counts())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_iris_geo.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_iris_geo.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l2iykkxhu5h",
   "metadata": {},
   "source": [
    "## 6. Load Sirene Business Establishment Dataset\n",
    "Business establishment data from 2014 to 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7v0v9uhu27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sirene dataset (this may take a while, it's a large file)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Jh9vcCnblxJxbuMTrqxuyR1PPo1dkrBo\n",
      "From (redirected): https://drive.google.com/uc?id=1Jh9vcCnblxJxbuMTrqxuyR1PPo1dkrBo&confirm=t&uuid=bc9a2258-3982-4a08-8053-1aff0ab31c4b\n",
      "To: /workspaces/thesis/raw_datasets/sirene.parquet\n",
      "100%|██████████| 2.14G/2.14G [00:29<00:00, 72.0MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Sirene data in batches to handle large file size...\n",
      "Parquet file has 338 row groups\n",
      "Available columns in Sirene: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n",
      "Processing row group 1/338...\n",
      "Available columns in Sirene: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n",
      "Processing row group 1/338...\n",
      "Processing row group 2/338...\n",
      "Processing row group 2/338...\n",
      "Processing row group 3/338...\n",
      "Processing row group 3/338...\n",
      "Processing row group 4/338...\n",
      "Processing row group 4/338...\n",
      "Processing row group 5/338...\n",
      "Processing row group 5/338...\n",
      "Processing row group 6/338...\n",
      "Processing row group 6/338...\n",
      "Processing row group 7/338...\n",
      "Processing row group 7/338...\n",
      "Processing row group 8/338...\n",
      "Processing row group 8/338...\n",
      "Processing row group 9/338...\n",
      "Processing row group 9/338...\n",
      "Processing row group 10/338...\n",
      "Processing row group 10/338...\n",
      "Processing row group 11/338...\n",
      "Processing row group 11/338...\n",
      "Processing row group 12/338...\n",
      "Processing row group 12/338...\n",
      "Processing row group 13/338...\n",
      "Processing row group 13/338...\n",
      "Processing row group 14/338...\n",
      "Processing row group 14/338...\n",
      "Processing row group 15/338...\n",
      "Processing row group 15/338...\n",
      "Processing row group 16/338...\n",
      "Processing row group 16/338...\n",
      "Processing row group 17/338...\n",
      "Processing row group 17/338...\n",
      "Processing row group 18/338...\n",
      "Processing row group 18/338...\n",
      "Processing row group 19/338...\n",
      "Processing row group 19/338...\n",
      "Processing row group 20/338...\n",
      "Processing row group 20/338...\n",
      "Processing row group 21/338...\n",
      "Processing row group 21/338...\n",
      "Processing row group 22/338...\n",
      "Processing row group 22/338...\n",
      "Processing row group 23/338...\n",
      "Processing row group 23/338...\n",
      "Processing row group 24/338...\n",
      "Processing row group 24/338...\n",
      "Processing row group 25/338...\n",
      "Processing row group 25/338...\n",
      "Processing row group 26/338...\n",
      "Processing row group 26/338...\n",
      "Processing row group 27/338...\n",
      "Processing row group 27/338...\n",
      "Processing row group 28/338...\n",
      "Processing row group 28/338...\n",
      "Processing row group 29/338...\n",
      "Processing row group 29/338...\n",
      "Processing row group 30/338...\n",
      "Processing row group 30/338...\n",
      "Processing row group 31/338...\n",
      "Processing row group 31/338...\n",
      "Processing row group 32/338...\n",
      "Processing row group 32/338...\n",
      "Processing row group 33/338...\n",
      "Processing row group 33/338...\n",
      "Processing row group 34/338...\n",
      "Processing row group 34/338...\n",
      "Processing row group 35/338...\n",
      "Processing row group 35/338...\n",
      "Processing row group 36/338...\n",
      "Processing row group 36/338...\n",
      "Processing row group 37/338...\n",
      "Processing row group 37/338...\n",
      "Processing row group 38/338...\n",
      "Processing row group 38/338...\n",
      "Processing row group 39/338...\n",
      "Processing row group 39/338...\n",
      "Processing row group 40/338...\n",
      "Processing row group 40/338...\n",
      "Processing row group 41/338...\n",
      "Processing row group 41/338...\n",
      "Processing row group 42/338...\n",
      "Processing row group 42/338...\n",
      "Processing row group 43/338...\n",
      "Processing row group 43/338...\n",
      "Processing row group 44/338...\n",
      "Processing row group 44/338...\n",
      "Processing row group 45/338...\n",
      "Processing row group 45/338...\n",
      "Processing row group 46/338...\n",
      "Processing row group 46/338...\n",
      "Processing row group 47/338...\n",
      "Processing row group 47/338...\n",
      "Processing row group 48/338...\n",
      "Processing row group 48/338...\n",
      "Processing row group 49/338...\n",
      "Processing row group 49/338...\n",
      "Processing row group 50/338...\n",
      "Processing row group 50/338...\n",
      "Processing row group 51/338...\n",
      "Processing row group 51/338...\n",
      "Processing row group 52/338...\n",
      "Processing row group 52/338...\n",
      "Processing row group 53/338...\n",
      "Processing row group 53/338...\n",
      "Processing row group 54/338...\n",
      "Processing row group 54/338...\n",
      "Processing row group 55/338...\n",
      "Processing row group 55/338...\n",
      "Processing row group 56/338...\n",
      "Processing row group 56/338...\n",
      "Processing row group 57/338...\n",
      "Processing row group 57/338...\n",
      "Processing row group 58/338...\n",
      "Processing row group 58/338...\n",
      "Processing row group 59/338...\n",
      "Processing row group 59/338...\n",
      "Processing row group 60/338...\n",
      "Processing row group 60/338...\n",
      "Processing row group 61/338...\n",
      "Processing row group 61/338...\n",
      "Processing row group 62/338...\n",
      "Processing row group 62/338...\n",
      "Processing row group 63/338...\n",
      "Processing row group 63/338...\n",
      "Processing row group 64/338...\n",
      "Processing row group 64/338...\n",
      "Processing row group 65/338...\n",
      "Processing row group 65/338...\n",
      "Processing row group 66/338...\n",
      "Processing row group 66/338...\n",
      "Processing row group 67/338...\n",
      "Processing row group 67/338...\n",
      "Processing row group 68/338...\n",
      "Processing row group 68/338...\n",
      "Processing row group 69/338...\n",
      "Processing row group 69/338...\n",
      "Processing row group 70/338...\n",
      "Processing row group 70/338...\n",
      "Processing row group 71/338...\n",
      "Processing row group 71/338...\n",
      "Processing row group 72/338...\n",
      "Processing row group 72/338...\n",
      "Processing row group 73/338...\n",
      "Processing row group 73/338...\n",
      "Processing row group 74/338...\n",
      "Processing row group 74/338...\n",
      "Processing row group 75/338...\n",
      "Processing row group 75/338...\n",
      "Processing row group 76/338...\n",
      "Processing row group 76/338...\n",
      "Processing row group 77/338...\n",
      "Processing row group 77/338...\n",
      "Processing row group 78/338...\n",
      "Processing row group 78/338...\n",
      "Processing row group 79/338...\n",
      "Processing row group 79/338...\n",
      "Processing row group 80/338...\n",
      "Processing row group 80/338...\n",
      "Processing row group 81/338...\n",
      "Processing row group 81/338...\n",
      "Processing row group 82/338...\n",
      "Processing row group 82/338...\n",
      "Processing row group 83/338...\n",
      "Processing row group 83/338...\n",
      "Processing row group 84/338...\n",
      "Processing row group 84/338...\n",
      "Processing row group 85/338...\n",
      "Processing row group 85/338...\n",
      "Processing row group 86/338...\n",
      "Processing row group 86/338...\n",
      "Processing row group 87/338...\n",
      "Processing row group 87/338...\n",
      "Processing row group 88/338...\n",
      "Processing row group 88/338...\n",
      "Processing row group 89/338...\n",
      "Processing row group 89/338...\n",
      "Processing row group 90/338...\n",
      "Processing row group 90/338...\n",
      "Processing row group 91/338...\n",
      "Processing row group 91/338...\n",
      "Processing row group 92/338...\n",
      "Processing row group 92/338...\n",
      "Processing row group 93/338...\n",
      "Processing row group 93/338...\n",
      "Processing row group 94/338...\n",
      "Processing row group 94/338...\n",
      "Processing row group 95/338...\n",
      "Processing row group 95/338...\n",
      "Processing row group 96/338...\n",
      "Processing row group 96/338...\n",
      "Processing row group 97/338...\n",
      "Processing row group 97/338...\n",
      "Processing row group 98/338...\n",
      "Processing row group 98/338...\n",
      "Processing row group 99/338...\n",
      "Processing row group 99/338...\n",
      "Processing row group 100/338...\n",
      "Processing row group 100/338...\n",
      "Processing row group 101/338...\n",
      "Processing row group 101/338...\n",
      "Processing row group 102/338...\n",
      "Processing row group 102/338...\n",
      "Processing row group 103/338...\n",
      "Processing row group 103/338...\n",
      "Processing row group 104/338...\n",
      "Processing row group 104/338...\n",
      "Processing row group 105/338...\n",
      "Processing row group 105/338...\n",
      "Processing row group 106/338...\n",
      "Processing row group 106/338...\n",
      "Processing row group 107/338...\n",
      "Processing row group 107/338...\n",
      "Processing row group 108/338...\n",
      "Processing row group 108/338...\n",
      "Processing row group 109/338...\n",
      "Processing row group 109/338...\n",
      "Processing row group 110/338...\n",
      "Processing row group 110/338...\n",
      "Processing row group 111/338...\n",
      "Processing row group 111/338...\n",
      "Processing row group 112/338...\n",
      "Processing row group 112/338...\n",
      "Processing row group 113/338...\n",
      "Processing row group 113/338...\n",
      "Processing row group 114/338...\n",
      "Processing row group 114/338...\n",
      "Processing row group 115/338...\n",
      "Processing row group 115/338...\n",
      "Processing row group 116/338...\n",
      "Processing row group 116/338...\n",
      "Processing row group 117/338...\n",
      "Processing row group 117/338...\n",
      "Processing row group 118/338...\n",
      "Processing row group 118/338...\n",
      "Processing row group 119/338...\n",
      "Processing row group 119/338...\n",
      "Processing row group 120/338...\n",
      "Processing row group 120/338...\n",
      "Processing row group 121/338...\n",
      "Processing row group 121/338...\n",
      "Processing row group 122/338...\n",
      "Processing row group 122/338...\n",
      "Processing row group 123/338...\n",
      "Processing row group 123/338...\n",
      "Processing row group 124/338...\n",
      "Processing row group 124/338...\n",
      "Processing row group 125/338...\n",
      "Processing row group 125/338...\n",
      "Processing row group 126/338...\n",
      "Processing row group 126/338...\n",
      "Processing row group 127/338...\n",
      "Processing row group 127/338...\n",
      "Processing row group 128/338...\n",
      "Processing row group 128/338...\n",
      "Processing row group 129/338...\n",
      "Processing row group 129/338...\n",
      "Processing row group 130/338...\n",
      "Processing row group 130/338...\n",
      "Processing row group 131/338...\n",
      "Processing row group 131/338...\n",
      "Processing row group 132/338...\n",
      "Processing row group 132/338...\n",
      "Processing row group 133/338...\n",
      "Processing row group 133/338...\n",
      "Processing row group 134/338...\n",
      "Processing row group 134/338...\n",
      "Processing row group 135/338...\n",
      "Processing row group 135/338...\n",
      "Processing row group 136/338...\n",
      "Processing row group 136/338...\n",
      "Processing row group 137/338...\n",
      "Processing row group 137/338...\n",
      "Processing row group 138/338...\n",
      "Processing row group 138/338...\n",
      "Processing row group 139/338...\n",
      "Processing row group 139/338...\n",
      "Processing row group 140/338...\n",
      "Processing row group 140/338...\n",
      "Processing row group 141/338...\n",
      "Processing row group 141/338...\n",
      "Processing row group 142/338...\n",
      "Processing row group 142/338...\n",
      "Processing row group 143/338...\n",
      "Processing row group 143/338...\n",
      "Processing row group 144/338...\n",
      "Processing row group 144/338...\n",
      "Processing row group 145/338...\n",
      "Processing row group 145/338...\n",
      "Processing row group 146/338...\n",
      "Processing row group 146/338...\n",
      "Processing row group 147/338...\n",
      "Processing row group 147/338...\n",
      "Processing row group 148/338...\n",
      "Processing row group 148/338...\n",
      "Processing row group 149/338...\n",
      "Processing row group 149/338...\n",
      "Processing row group 150/338...\n",
      "Processing row group 150/338...\n",
      "Processing row group 151/338...\n",
      "Processing row group 151/338...\n",
      "Processing row group 152/338...\n",
      "Processing row group 152/338...\n",
      "Processing row group 153/338...\n",
      "Processing row group 153/338...\n",
      "Processing row group 154/338...\n",
      "Processing row group 154/338...\n",
      "Processing row group 155/338...\n",
      "Processing row group 155/338...\n",
      "Processing row group 156/338...\n",
      "Processing row group 156/338...\n",
      "Processing row group 157/338...\n",
      "Processing row group 157/338...\n",
      "Processing row group 158/338...\n",
      "Processing row group 158/338...\n",
      "Processing row group 159/338...\n",
      "Processing row group 159/338...\n",
      "Processing row group 160/338...\n",
      "Processing row group 160/338...\n",
      "Processing row group 161/338...\n",
      "Processing row group 161/338...\n",
      "Processing row group 162/338...\n",
      "Processing row group 162/338...\n",
      "Processing row group 163/338...\n",
      "Processing row group 163/338...\n",
      "Processing row group 164/338...\n",
      "Processing row group 164/338...\n",
      "Processing row group 165/338...\n",
      "Processing row group 165/338...\n",
      "Processing row group 166/338...\n",
      "Processing row group 166/338...\n",
      "Processing row group 167/338...\n",
      "Processing row group 167/338...\n",
      "Processing row group 168/338...\n",
      "Processing row group 168/338...\n",
      "Processing row group 169/338...\n",
      "Processing row group 169/338...\n",
      "Processing row group 170/338...\n",
      "Processing row group 170/338...\n",
      "Processing row group 171/338...\n",
      "Processing row group 171/338...\n",
      "Processing row group 172/338...\n",
      "Processing row group 172/338...\n",
      "Processing row group 173/338...\n",
      "Processing row group 173/338...\n",
      "Processing row group 174/338...\n",
      "Processing row group 174/338...\n",
      "Processing row group 175/338...\n",
      "Processing row group 175/338...\n",
      "Processing row group 176/338...\n",
      "Processing row group 176/338...\n",
      "Processing row group 177/338...\n",
      "Processing row group 177/338...\n",
      "Processing row group 178/338...\n",
      "Processing row group 178/338...\n",
      "Processing row group 179/338...\n",
      "Processing row group 179/338...\n",
      "Processing row group 180/338...\n",
      "Processing row group 180/338...\n",
      "Processing row group 181/338...\n",
      "Processing row group 181/338...\n",
      "Processing row group 182/338...\n",
      "Processing row group 182/338...\n",
      "Processing row group 183/338...\n",
      "Processing row group 183/338...\n",
      "Processing row group 184/338...\n",
      "Processing row group 184/338...\n",
      "Processing row group 185/338...\n",
      "Processing row group 185/338...\n",
      "Processing row group 186/338...\n",
      "Processing row group 186/338...\n",
      "Processing row group 187/338...\n",
      "Processing row group 187/338...\n",
      "Processing row group 188/338...\n",
      "Processing row group 188/338...\n",
      "Processing row group 189/338...\n",
      "Processing row group 189/338...\n",
      "Processing row group 190/338...\n",
      "Processing row group 190/338...\n",
      "Processing row group 191/338...\n",
      "Processing row group 191/338...\n",
      "Processing row group 192/338...\n",
      "Processing row group 192/338...\n",
      "Processing row group 193/338...\n",
      "Processing row group 193/338...\n",
      "Processing row group 194/338...\n",
      "Processing row group 194/338...\n",
      "Processing row group 195/338...\n",
      "Processing row group 195/338...\n",
      "Processing row group 196/338...\n",
      "Processing row group 196/338...\n",
      "Processing row group 197/338...\n",
      "Processing row group 197/338...\n",
      "Processing row group 198/338...\n",
      "Processing row group 198/338...\n",
      "Processing row group 199/338...\n",
      "Processing row group 199/338...\n",
      "Processing row group 200/338...\n",
      "Processing row group 200/338...\n",
      "Processing row group 201/338...\n",
      "Processing row group 201/338...\n",
      "Processing row group 202/338...\n",
      "Processing row group 202/338...\n",
      "Processing row group 203/338...\n",
      "Processing row group 203/338...\n",
      "Processing row group 204/338...\n",
      "Processing row group 204/338...\n",
      "Processing row group 205/338...\n",
      "Processing row group 206/338...\n",
      "Processing row group 205/338...\n",
      "Processing row group 206/338...\n",
      "Processing row group 207/338...\n",
      "Processing row group 207/338...\n",
      "Processing row group 208/338...\n",
      "Processing row group 208/338...\n",
      "Processing row group 209/338...\n",
      "Processing row group 209/338...\n",
      "Processing row group 210/338...\n",
      "Processing row group 210/338...\n",
      "Processing row group 211/338...\n",
      "Processing row group 211/338...\n",
      "Processing row group 212/338...\n",
      "Processing row group 212/338...\n",
      "Processing row group 213/338...\n",
      "Processing row group 213/338...\n",
      "Processing row group 214/338...\n",
      "Processing row group 214/338...\n",
      "Processing row group 215/338...\n",
      "Processing row group 215/338...\n",
      "Processing row group 216/338...\n",
      "Processing row group 216/338...\n",
      "Processing row group 217/338...\n",
      "Processing row group 217/338...\n",
      "Processing row group 218/338...\n",
      "Processing row group 218/338...\n",
      "Processing row group 219/338...\n",
      "Processing row group 219/338...\n",
      "Processing row group 220/338...\n",
      "Processing row group 220/338...\n",
      "Processing row group 221/338...\n",
      "Processing row group 221/338...\n",
      "Processing row group 222/338...\n",
      "Processing row group 222/338...\n",
      "Processing row group 223/338...\n",
      "Processing row group 223/338...\n",
      "Processing row group 224/338...\n",
      "Processing row group 224/338...\n",
      "Processing row group 225/338...\n",
      "Processing row group 225/338...\n",
      "Processing row group 226/338...\n",
      "Processing row group 226/338...\n",
      "Processing row group 227/338...\n",
      "Processing row group 227/338...\n",
      "Processing row group 228/338...\n",
      "Processing row group 228/338...\n",
      "Processing row group 229/338...\n",
      "Processing row group 229/338...\n",
      "Processing row group 230/338...\n",
      "Processing row group 230/338...\n",
      "Processing row group 231/338...\n",
      "Processing row group 231/338...\n",
      "Processing row group 232/338...\n",
      "Processing row group 232/338...\n",
      "Processing row group 233/338...\n",
      "Processing row group 233/338...\n",
      "Processing row group 234/338...\n",
      "Processing row group 234/338...\n",
      "Processing row group 235/338...\n",
      "Processing row group 235/338...\n",
      "Processing row group 236/338...\n",
      "Processing row group 236/338...\n",
      "Processing row group 237/338...\n",
      "Processing row group 237/338...\n",
      "Processing row group 238/338...\n",
      "Processing row group 238/338...\n",
      "Processing row group 239/338...\n",
      "Processing row group 239/338...\n",
      "Processing row group 240/338...\n",
      "Processing row group 240/338...\n",
      "Processing row group 241/338...\n",
      "Processing row group 241/338...\n",
      "Processing row group 242/338...\n",
      "Processing row group 242/338...\n",
      "Processing row group 243/338...\n",
      "Processing row group 243/338...\n",
      "Processing row group 244/338...\n",
      "Processing row group 244/338...\n",
      "Processing row group 245/338...\n",
      "Processing row group 245/338...\n",
      "Processing row group 246/338...\n",
      "Processing row group 246/338...\n",
      "Processing row group 247/338...\n",
      "Processing row group 247/338...\n",
      "Processing row group 248/338...\n",
      "Processing row group 248/338...\n",
      "Processing row group 249/338...\n",
      "Processing row group 249/338...\n",
      "Processing row group 250/338...\n",
      "Processing row group 250/338...\n",
      "Processing row group 251/338...\n",
      "Processing row group 251/338...\n",
      "Processing row group 252/338...\n",
      "Processing row group 252/338...\n",
      "Processing row group 253/338...\n",
      "Processing row group 253/338...\n",
      "Processing row group 254/338...\n",
      "Processing row group 254/338...\n",
      "Processing row group 255/338...\n",
      "Processing row group 255/338...\n",
      "Processing row group 256/338...\n",
      "Processing row group 256/338...\n",
      "Processing row group 257/338...\n",
      "Processing row group 257/338...\n",
      "Processing row group 258/338...\n",
      "Processing row group 258/338...\n",
      "Processing row group 259/338...\n",
      "Processing row group 259/338...\n",
      "Processing row group 260/338...\n",
      "Processing row group 260/338...\n",
      "Processing row group 261/338...\n",
      "Processing row group 261/338...\n",
      "Processing row group 262/338...\n",
      "Processing row group 262/338...\n",
      "Processing row group 263/338...\n",
      "Processing row group 263/338...\n",
      "Processing row group 264/338...\n",
      "Processing row group 264/338...\n",
      "Processing row group 265/338...\n",
      "Processing row group 265/338...\n",
      "Processing row group 266/338...\n",
      "Processing row group 266/338...\n",
      "Processing row group 267/338...\n",
      "Processing row group 267/338...\n",
      "Processing row group 268/338...\n",
      "Processing row group 268/338...\n",
      "Processing row group 269/338...\n",
      "Processing row group 269/338...\n",
      "Processing row group 270/338...\n",
      "Processing row group 270/338...\n",
      "Processing row group 271/338...\n",
      "Processing row group 271/338...\n",
      "Processing row group 272/338...\n",
      "Processing row group 272/338...\n",
      "Processing row group 273/338...\n",
      "Processing row group 273/338...\n",
      "Processing row group 274/338...\n",
      "Processing row group 274/338...\n",
      "Processing row group 275/338...\n",
      "Processing row group 275/338...\n",
      "Processing row group 276/338...\n",
      "Processing row group 276/338...\n",
      "Processing row group 277/338...\n",
      "Processing row group 277/338...\n",
      "Processing row group 278/338...\n",
      "Processing row group 278/338...\n",
      "Processing row group 279/338...\n",
      "Processing row group 279/338...\n",
      "Processing row group 280/338...\n",
      "Processing row group 280/338...\n",
      "Processing row group 281/338...\n",
      "Processing row group 281/338...\n",
      "Processing row group 282/338...\n",
      "Processing row group 282/338...\n",
      "Processing row group 283/338...\n",
      "Processing row group 283/338...\n",
      "Processing row group 284/338...\n",
      "Processing row group 284/338...\n",
      "Processing row group 285/338...\n",
      "Processing row group 285/338...\n",
      "Processing row group 286/338...\n",
      "Processing row group 286/338...\n",
      "Processing row group 287/338...\n",
      "Processing row group 287/338...\n",
      "Processing row group 288/338...\n",
      "Processing row group 288/338...\n",
      "Processing row group 289/338...\n",
      "Processing row group 289/338...\n",
      "Processing row group 290/338...\n",
      "Processing row group 290/338...\n",
      "Processing row group 291/338...\n",
      "Processing row group 291/338...\n",
      "Processing row group 292/338...\n",
      "Processing row group 292/338...\n",
      "Processing row group 293/338...\n",
      "Processing row group 293/338...\n",
      "Processing row group 294/338...\n",
      "Processing row group 294/338...\n",
      "Processing row group 295/338...\n",
      "Processing row group 295/338...\n",
      "Processing row group 296/338...\n",
      "Processing row group 296/338...\n",
      "Processing row group 297/338...\n",
      "Processing row group 297/338...\n",
      "Processing row group 298/338...\n",
      "Processing row group 298/338...\n",
      "Processing row group 299/338...\n",
      "Processing row group 299/338...\n",
      "Processing row group 300/338...\n",
      "Processing row group 300/338...\n",
      "Processing row group 301/338...\n",
      "Processing row group 301/338...\n",
      "Processing row group 302/338...\n",
      "Processing row group 302/338...\n",
      "Processing row group 303/338...\n",
      "Processing row group 303/338...\n",
      "Processing row group 304/338...\n",
      "Processing row group 304/338...\n",
      "Processing row group 305/338...\n",
      "Processing row group 305/338...\n",
      "Processing row group 306/338...\n",
      "Processing row group 306/338...\n",
      "Processing row group 307/338...\n",
      "Processing row group 307/338...\n",
      "Processing row group 308/338...\n",
      "Processing row group 308/338...\n",
      "Processing row group 309/338...\n",
      "Processing row group 309/338...\n",
      "Processing row group 310/338...\n",
      "Processing row group 310/338...\n",
      "Processing row group 311/338...\n",
      "Processing row group 311/338...\n",
      "Processing row group 312/338...\n",
      "Processing row group 312/338...\n",
      "Processing row group 313/338...\n",
      "Processing row group 313/338...\n",
      "Processing row group 314/338...\n",
      "Processing row group 314/338...\n",
      "Processing row group 315/338...\n",
      "Processing row group 315/338...\n",
      "Processing row group 316/338...\n",
      "Processing row group 316/338...\n",
      "Processing row group 317/338...\n",
      "Processing row group 317/338...\n",
      "Processing row group 318/338...\n",
      "Processing row group 318/338...\n",
      "Processing row group 319/338...\n",
      "Processing row group 319/338...\n",
      "Processing row group 320/338...\n",
      "Processing row group 320/338...\n",
      "Processing row group 321/338...\n",
      "Processing row group 321/338...\n",
      "Processing row group 322/338...\n",
      "Processing row group 322/338...\n",
      "Processing row group 323/338...\n",
      "Processing row group 323/338...\n",
      "Processing row group 324/338...\n",
      "Processing row group 324/338...\n",
      "Processing row group 325/338...\n",
      "Processing row group 325/338...\n",
      "Processing row group 326/338...\n",
      "Processing row group 326/338...\n",
      "Processing row group 327/338...\n",
      "Processing row group 327/338...\n",
      "Processing row group 328/338...\n",
      "Processing row group 328/338...\n",
      "Processing row group 329/338...\n",
      "Processing row group 329/338...\n",
      "Processing row group 330/338...\n",
      "Processing row group 330/338...\n",
      "Processing row group 331/338...\n",
      "Processing row group 331/338...\n",
      "Processing row group 332/338...\n",
      "Processing row group 332/338...\n",
      "Processing row group 333/338...\n",
      "Processing row group 333/338...\n",
      "Processing row group 334/338...\n",
      "Processing row group 334/338...\n",
      "Processing row group 335/338...\n",
      "Processing row group 335/338...\n",
      "Processing row group 336/338...\n",
      "Processing row group 336/338...\n",
      "Processing row group 337/338...\n",
      "Processing row group 337/338...\n",
      "Processing row group 338/338...\n",
      "Processing row group 338/338...\n",
      "Total Paris establishments collected: 1194896\n",
      "Total Paris establishments collected: 1194896\n",
      "Sirene: 1194896 establishments in Paris (2014-2024) saved\n",
      "Columns: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n",
      "Sirene: 1194896 establishments in Paris (2014-2024) saved\n",
      "Columns: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n"
     ]
    }
   ],
   "source": [
    "# Sirene Business Establishment Dataset\n",
    "print(\"Loading Sirene dataset (this may take a while, it's a large file)...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1Jh9vcCnblxJxbuMTrqxuyR1PPo1dkrBo'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'sirene.parquet'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "# This is a large parquet file - use pyarrow to read in batches\n",
    "print(\"Reading Sirene data in batches to handle large file size...\")\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "# Open the parquet file\n",
    "parquet_file = pq.ParquetFile(raw_file)\n",
    "\n",
    "# Get total number of row groups for progress tracking\n",
    "total_row_groups = parquet_file.num_row_groups\n",
    "print(f\"Parquet file has {total_row_groups} row groups\")\n",
    "\n",
    "# First, let's check what columns are available by reading just the first row group\n",
    "first_table = parquet_file.read_row_group(0, columns=None)\n",
    "first_df = first_table.to_pandas()\n",
    "print(f\"Available columns in Sirene: {list(first_df.columns)}\")\n",
    "\n",
    "sirene_chunks = []\n",
    "\n",
    "# Read each row group (batch) and process\n",
    "for i in range(total_row_groups):\n",
    "    print(f\"Processing row group {i+1}/{total_row_groups}...\")\n",
    "    \n",
    "    # Read this row group as a table\n",
    "    table = parquet_file.read_row_group(i, columns=None)\n",
    "    chunk = table.to_pandas()\n",
    "    \n",
    "    # Filter for Paris using postal code (starts with '75')\n",
    "    if 'codePostalEtablissement' in chunk.columns:\n",
    "        chunk_paris = chunk[chunk['codePostalEtablissement'].astype(str).str.startswith('75')].copy()\n",
    "    else:\n",
    "        print(f\"Warning: codePostalEtablissement column not found in row group {i+1}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Filter for dates from 2014 to 2024\n",
    "    date_cols = [col for col in chunk_paris.columns if 'date' in col.lower() or 'creation' in col.lower()]\n",
    "    if date_cols and len(chunk_paris) > 0:\n",
    "        date_col = date_cols[0]\n",
    "        chunk_paris[date_col] = pd.to_datetime(chunk_paris[date_col], errors='coerce')\n",
    "        chunk_paris = chunk_paris[\n",
    "            (chunk_paris[date_col] >= '2014-01-01') & \n",
    "            (chunk_paris[date_col] <= '2024-12-31')\n",
    "        ].copy()\n",
    "    \n",
    "    # Add to our list if there are Paris records\n",
    "    if len(chunk_paris) > 0:\n",
    "        sirene_chunks.append(chunk_paris)\n",
    "\n",
    "# Concatenate all chunks\n",
    "if sirene_chunks:\n",
    "    sirene_paris = pd.concat(sirene_chunks, ignore_index=True)\n",
    "    print(f\"Total Paris establishments collected: {len(sirene_paris)}\")\n",
    "else:\n",
    "    print(\"No Paris establishments found!\")\n",
    "    sirene_paris = pd.DataFrame()\n",
    "\n",
    "# Save to datasets folder\n",
    "if len(sirene_paris) > 0:\n",
    "    sirene_paris.to_parquet(datasets_dir / 'sirene_2014_2024_paris.parquet', index=False)\n",
    "    print(f\"Sirene: {len(sirene_paris)} establishments in Paris (2014-2024) saved\")\n",
    "    print(f\"Columns: {list(sirene_paris.columns)}\")\n",
    "else:\n",
    "    print(\"No data to save!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "l9kdfejmv2o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - SIRENE\n",
      "============================================================\n",
      "Number of establishments: 1194896\n",
      "Number of rows: 1194896\n",
      "Number of columns: 53\n",
      "Columns: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n",
      "\n",
      "Date range: 2014-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "Years covered: [np.int32(2014), np.int32(2015), np.int32(2016), np.int32(2017), np.int32(2018), np.int32(2019), np.int32(2020), np.int32(2021), np.int32(2022), np.int32(2023), np.int32(2024)]\n",
      "\n",
      "Top 10 activity sectors:\n",
      "activitePrincipaleEtablissement\n",
      "70.22Z    112808\n",
      "68.20B     85802\n",
      "68.20A     66795\n",
      "69.10Z     57589\n",
      "53.20Z     46253\n",
      "64.20Z     27361\n",
      "62.01Z     25126\n",
      "70.21Z     24341\n",
      "70.10Z     23792\n",
      "74.10Z     22779\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Establishment status distribution:\n",
      "etatAdministratifEtablissement\n",
      "A    674506\n",
      "F    520390\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Headquarters distribution:\n",
      "etablissementSiege\n",
      "True     864426\n",
      "False    330470\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "siren                                                     object\n",
      "nic                                                        int64\n",
      "siret                                                     object\n",
      "statutDiffusionEtablissement                              object\n",
      "dateCreationEtablissement                         datetime64[ns]\n",
      "trancheEffectifsEtablissement                             object\n",
      "anneeEffectifsEtablissement                              float64\n",
      "activitePrincipaleRegistreMetiersEtablissement            object\n",
      "dateDernierTraitementEtablissement                datetime64[us]\n",
      "etablissementSiege                                          bool\n",
      "nombrePeriodesEtablissement                                int64\n",
      "complementAdresseEtablissement                            object\n",
      "numeroVoieEtablissement                                   object\n",
      "indiceRepetitionEtablissement                             object\n",
      "dernierNumeroVoieEtablissement                            object\n",
      "indiceRepetitionDernierNumeroVoieEtablissement            object\n",
      "typeVoieEtablissement                                     object\n",
      "libelleVoieEtablissement                                  object\n",
      "codePostalEtablissement                                   object\n",
      "libelleCommuneEtablissement                               object\n",
      "libelleCommuneEtrangerEtablissement                       object\n",
      "distributionSpecialeEtablissement                         object\n",
      "codeCommuneEtablissement                                  object\n",
      "codeCedexEtablissement                                    object\n",
      "libelleCedexEtablissement                                 object\n",
      "codePaysEtrangerEtablissement                             object\n",
      "libellePaysEtrangerEtablissement                          object\n",
      "identifiantAdresseEtablissement                           object\n",
      "coordonneeLambertAbscisseEtablissement                    object\n",
      "coordonneeLambertOrdonneeEtablissement                    object\n",
      "complementAdresse2Etablissement                           object\n",
      "numeroVoie2Etablissement                                  object\n",
      "indiceRepetition2Etablissement                            object\n",
      "typeVoie2Etablissement                                    object\n",
      "libelleVoie2Etablissement                                 object\n",
      "codePostal2Etablissement                                  object\n",
      "libelleCommune2Etablissement                              object\n",
      "libelleCommuneEtranger2Etablissement                      object\n",
      "distributionSpeciale2Etablissement                        object\n",
      "codeCommune2Etablissement                                 object\n",
      "codeCedex2Etablissement                                   object\n",
      "libelleCedex2Etablissement                                object\n",
      "codePaysEtranger2Etablissement                            object\n",
      "libellePaysEtranger2Etablissement                         object\n",
      "dateDebut                                                 object\n",
      "etatAdministratifEtablissement                            object\n",
      "enseigne1Etablissement                                    object\n",
      "enseigne2Etablissement                                    object\n",
      "enseigne3Etablissement                                    object\n",
      "denominationUsuelleEtablissement                          object\n",
      "activitePrincipaleEtablissement                           object\n",
      "nomenclatureActivitePrincipaleEtablissement               object\n",
      "caractereEmployeurEtablissement                           object\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      "Number of establishments: 1194896\n",
      "Number of rows: 1194896\n",
      "Number of columns: 53\n",
      "Columns: ['siren', 'nic', 'siret', 'statutDiffusionEtablissement', 'dateCreationEtablissement', 'trancheEffectifsEtablissement', 'anneeEffectifsEtablissement', 'activitePrincipaleRegistreMetiersEtablissement', 'dateDernierTraitementEtablissement', 'etablissementSiege', 'nombrePeriodesEtablissement', 'complementAdresseEtablissement', 'numeroVoieEtablissement', 'indiceRepetitionEtablissement', 'dernierNumeroVoieEtablissement', 'indiceRepetitionDernierNumeroVoieEtablissement', 'typeVoieEtablissement', 'libelleVoieEtablissement', 'codePostalEtablissement', 'libelleCommuneEtablissement', 'libelleCommuneEtrangerEtablissement', 'distributionSpecialeEtablissement', 'codeCommuneEtablissement', 'codeCedexEtablissement', 'libelleCedexEtablissement', 'codePaysEtrangerEtablissement', 'libellePaysEtrangerEtablissement', 'identifiantAdresseEtablissement', 'coordonneeLambertAbscisseEtablissement', 'coordonneeLambertOrdonneeEtablissement', 'complementAdresse2Etablissement', 'numeroVoie2Etablissement', 'indiceRepetition2Etablissement', 'typeVoie2Etablissement', 'libelleVoie2Etablissement', 'codePostal2Etablissement', 'libelleCommune2Etablissement', 'libelleCommuneEtranger2Etablissement', 'distributionSpeciale2Etablissement', 'codeCommune2Etablissement', 'codeCedex2Etablissement', 'libelleCedex2Etablissement', 'codePaysEtranger2Etablissement', 'libellePaysEtranger2Etablissement', 'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement', 'enseigne2Etablissement', 'enseigne3Etablissement', 'denominationUsuelleEtablissement', 'activitePrincipaleEtablissement', 'nomenclatureActivitePrincipaleEtablissement', 'caractereEmployeurEtablissement']\n",
      "\n",
      "Date range: 2014-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "Years covered: [np.int32(2014), np.int32(2015), np.int32(2016), np.int32(2017), np.int32(2018), np.int32(2019), np.int32(2020), np.int32(2021), np.int32(2022), np.int32(2023), np.int32(2024)]\n",
      "\n",
      "Top 10 activity sectors:\n",
      "activitePrincipaleEtablissement\n",
      "70.22Z    112808\n",
      "68.20B     85802\n",
      "68.20A     66795\n",
      "69.10Z     57589\n",
      "53.20Z     46253\n",
      "64.20Z     27361\n",
      "62.01Z     25126\n",
      "70.21Z     24341\n",
      "70.10Z     23792\n",
      "74.10Z     22779\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Establishment status distribution:\n",
      "etatAdministratifEtablissement\n",
      "A    674506\n",
      "F    520390\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Headquarters distribution:\n",
      "etablissementSiege\n",
      "True     864426\n",
      "False    330470\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "siren                                                     object\n",
      "nic                                                        int64\n",
      "siret                                                     object\n",
      "statutDiffusionEtablissement                              object\n",
      "dateCreationEtablissement                         datetime64[ns]\n",
      "trancheEffectifsEtablissement                             object\n",
      "anneeEffectifsEtablissement                              float64\n",
      "activitePrincipaleRegistreMetiersEtablissement            object\n",
      "dateDernierTraitementEtablissement                datetime64[us]\n",
      "etablissementSiege                                          bool\n",
      "nombrePeriodesEtablissement                                int64\n",
      "complementAdresseEtablissement                            object\n",
      "numeroVoieEtablissement                                   object\n",
      "indiceRepetitionEtablissement                             object\n",
      "dernierNumeroVoieEtablissement                            object\n",
      "indiceRepetitionDernierNumeroVoieEtablissement            object\n",
      "typeVoieEtablissement                                     object\n",
      "libelleVoieEtablissement                                  object\n",
      "codePostalEtablissement                                   object\n",
      "libelleCommuneEtablissement                               object\n",
      "libelleCommuneEtrangerEtablissement                       object\n",
      "distributionSpecialeEtablissement                         object\n",
      "codeCommuneEtablissement                                  object\n",
      "codeCedexEtablissement                                    object\n",
      "libelleCedexEtablissement                                 object\n",
      "codePaysEtrangerEtablissement                             object\n",
      "libellePaysEtrangerEtablissement                          object\n",
      "identifiantAdresseEtablissement                           object\n",
      "coordonneeLambertAbscisseEtablissement                    object\n",
      "coordonneeLambertOrdonneeEtablissement                    object\n",
      "complementAdresse2Etablissement                           object\n",
      "numeroVoie2Etablissement                                  object\n",
      "indiceRepetition2Etablissement                            object\n",
      "typeVoie2Etablissement                                    object\n",
      "libelleVoie2Etablissement                                 object\n",
      "codePostal2Etablissement                                  object\n",
      "libelleCommune2Etablissement                              object\n",
      "libelleCommuneEtranger2Etablissement                      object\n",
      "distributionSpeciale2Etablissement                        object\n",
      "codeCommune2Etablissement                                 object\n",
      "codeCedex2Etablissement                                   object\n",
      "libelleCedex2Etablissement                                object\n",
      "codePaysEtranger2Etablissement                            object\n",
      "libellePaysEtranger2Etablissement                         object\n",
      "dateDebut                                                 object\n",
      "etatAdministratifEtablissement                            object\n",
      "enseigne1Etablissement                                    object\n",
      "enseigne2Etablissement                                    object\n",
      "enseigne3Etablissement                                    object\n",
      "denominationUsuelleEtablissement                          object\n",
      "activitePrincipaleEtablissement                           object\n",
      "nomenclatureActivitePrincipaleEtablissement               object\n",
      "caractereEmployeurEtablissement                           object\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      "siren                                                   0\n",
      "nic                                                     0\n",
      "siret                                                   0\n",
      "statutDiffusionEtablissement                            0\n",
      "dateCreationEtablissement                               0\n",
      "trancheEffectifsEtablissement                     1083888\n",
      "anneeEffectifsEtablissement                       1083888\n",
      "activitePrincipaleRegistreMetiersEtablissement    1127167\n",
      "dateDernierTraitementEtablissement                      0\n",
      "etablissementSiege                                      0\n",
      "nombrePeriodesEtablissement                             0\n",
      "complementAdresseEtablissement                    1042825\n",
      "numeroVoieEtablissement                              6068\n",
      "indiceRepetitionEtablissement                     1148988\n",
      "dernierNumeroVoieEtablissement                    1193294\n",
      "indiceRepetitionDernierNumeroVoieEtablissement    1194896\n",
      "typeVoieEtablissement                                1128\n",
      "libelleVoieEtablissement                                2\n",
      "codePostalEtablissement                                 0\n",
      "libelleCommuneEtablissement                            63\n",
      "libelleCommuneEtrangerEtablissement               1194833\n",
      "distributionSpecialeEtablissement                 1194896\n",
      "codeCommuneEtablissement                               63\n",
      "codeCedexEtablissement                            1194896\n",
      "libelleCedexEtablissement                         1194896\n",
      "codePaysEtrangerEtablissement                     1194833\n",
      "libellePaysEtrangerEtablissement                  1194833\n",
      "identifiantAdresseEtablissement                     89210\n",
      "coordonneeLambertAbscisseEtablissement              96655\n",
      "coordonneeLambertOrdonneeEtablissement              96655\n",
      "complementAdresse2Etablissement                   1194896\n",
      "numeroVoie2Etablissement                          1194896\n",
      "indiceRepetition2Etablissement                    1194896\n",
      "typeVoie2Etablissement                            1194896\n",
      "libelleVoie2Etablissement                         1194896\n",
      "codePostal2Etablissement                          1194896\n",
      "libelleCommune2Etablissement                      1194896\n",
      "libelleCommuneEtranger2Etablissement              1194896\n",
      "distributionSpeciale2Etablissement                1194896\n",
      "codeCommune2Etablissement                         1194896\n",
      "codeCedex2Etablissement                           1194896\n",
      "libelleCedex2Etablissement                        1194896\n",
      "codePaysEtranger2Etablissement                    1194896\n",
      "libellePaysEtranger2Etablissement                 1194896\n",
      "dateDebut                                               0\n",
      "etatAdministratifEtablissement                          0\n",
      "enseigne1Etablissement                            1133548\n",
      "enseigne2Etablissement                            1194730\n",
      "enseigne3Etablissement                            1194851\n",
      "denominationUsuelleEtablissement                  1018586\n",
      "activitePrincipaleEtablissement                         0\n",
      "nomenclatureActivitePrincipaleEtablissement             0\n",
      "caractereEmployeurEtablissement                      1542\n",
      "dtype: int64\n",
      "============================================================\n",
      "siren                                                   0\n",
      "nic                                                     0\n",
      "siret                                                   0\n",
      "statutDiffusionEtablissement                            0\n",
      "dateCreationEtablissement                               0\n",
      "trancheEffectifsEtablissement                     1083888\n",
      "anneeEffectifsEtablissement                       1083888\n",
      "activitePrincipaleRegistreMetiersEtablissement    1127167\n",
      "dateDernierTraitementEtablissement                      0\n",
      "etablissementSiege                                      0\n",
      "nombrePeriodesEtablissement                             0\n",
      "complementAdresseEtablissement                    1042825\n",
      "numeroVoieEtablissement                              6068\n",
      "indiceRepetitionEtablissement                     1148988\n",
      "dernierNumeroVoieEtablissement                    1193294\n",
      "indiceRepetitionDernierNumeroVoieEtablissement    1194896\n",
      "typeVoieEtablissement                                1128\n",
      "libelleVoieEtablissement                                2\n",
      "codePostalEtablissement                                 0\n",
      "libelleCommuneEtablissement                            63\n",
      "libelleCommuneEtrangerEtablissement               1194833\n",
      "distributionSpecialeEtablissement                 1194896\n",
      "codeCommuneEtablissement                               63\n",
      "codeCedexEtablissement                            1194896\n",
      "libelleCedexEtablissement                         1194896\n",
      "codePaysEtrangerEtablissement                     1194833\n",
      "libellePaysEtrangerEtablissement                  1194833\n",
      "identifiantAdresseEtablissement                     89210\n",
      "coordonneeLambertAbscisseEtablissement              96655\n",
      "coordonneeLambertOrdonneeEtablissement              96655\n",
      "complementAdresse2Etablissement                   1194896\n",
      "numeroVoie2Etablissement                          1194896\n",
      "indiceRepetition2Etablissement                    1194896\n",
      "typeVoie2Etablissement                            1194896\n",
      "libelleVoie2Etablissement                         1194896\n",
      "codePostal2Etablissement                          1194896\n",
      "libelleCommune2Etablissement                      1194896\n",
      "libelleCommuneEtranger2Etablissement              1194896\n",
      "distributionSpeciale2Etablissement                1194896\n",
      "codeCommune2Etablissement                         1194896\n",
      "codeCedex2Etablissement                           1194896\n",
      "libelleCedex2Etablissement                        1194896\n",
      "codePaysEtranger2Etablissement                    1194896\n",
      "libellePaysEtranger2Etablissement                 1194896\n",
      "dateDebut                                               0\n",
      "etatAdministratifEtablissement                          0\n",
      "enseigne1Etablissement                            1133548\n",
      "enseigne2Etablissement                            1194730\n",
      "enseigne3Etablissement                            1194851\n",
      "denominationUsuelleEtablissement                  1018586\n",
      "activitePrincipaleEtablissement                         0\n",
      "nomenclatureActivitePrincipaleEtablissement             0\n",
      "caractereEmployeurEtablissement                      1542\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify Sirene data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - SIRENE\")\n",
    "print(\"=\" * 60)\n",
    "loaded_sirene = pd.read_parquet(datasets_dir / 'sirene_2014_2024_paris.parquet')\n",
    "print(f\"Number of establishments: {len(loaded_sirene)}\")\n",
    "print(f\"Number of rows: {len(loaded_sirene)}\")\n",
    "print(f\"Number of columns: {len(loaded_sirene.columns)}\")\n",
    "print(f\"Columns: {list(loaded_sirene.columns)}\")\n",
    "\n",
    "# Check date range\n",
    "if 'dateCreationEtablissement' in loaded_sirene.columns:\n",
    "    loaded_sirene['dateCreationEtablissement'] = pd.to_datetime(loaded_sirene['dateCreationEtablissement'], errors='coerce')\n",
    "    print(f\"\\nDate range: {loaded_sirene['dateCreationEtablissement'].min()} to {loaded_sirene['dateCreationEtablissement'].max()}\")\n",
    "    print(f\"Years covered: {sorted(loaded_sirene['dateCreationEtablissement'].dt.year.dropna().unique())}\")\n",
    "\n",
    "# Check top activity sectors\n",
    "if 'activitePrincipaleEtablissement' in loaded_sirene.columns:\n",
    "    print(f\"\\nTop 10 activity sectors:\")\n",
    "    print(loaded_sirene['activitePrincipaleEtablissement'].value_counts().head(10))\n",
    "\n",
    "# Check establishment status\n",
    "if 'etatAdministratifEtablissement' in loaded_sirene.columns:\n",
    "    print(f\"\\nEstablishment status distribution:\")\n",
    "    print(loaded_sirene['etatAdministratifEtablissement'].value_counts())\n",
    "\n",
    "# Check if it's a headquarters\n",
    "if 'etablissementSiege' in loaded_sirene.columns:\n",
    "    print(f\"\\nHeadquarters distribution:\")\n",
    "    print(loaded_sirene['etablissementSiege'].value_counts())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_sirene.dtypes)\n",
    "print(f\"\\nMissing values per column:\")\n",
    "print(loaded_sirene.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdhvk4jle5",
   "metadata": {},
   "source": [
    "## Summary of Loaded Datasets\n",
    "All datasets have been filtered for Paris intra-muros and saved to the `datasets/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ooxw0je35r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASETS LOADED - PARIS INTRA-MUROS ONLY\n",
      "================================================================================\n",
      "\n",
      "RAW DATASETS:\n",
      "----------------------------------------\n",
      "census_2013.xlsx: 67.43 MB\n",
      "census_2017.xlsx: 42.63 MB\n",
      "census_2021.xlsx: 47.39 MB\n",
      "dvf_mutations.gpkg: 341.20 MB\n",
      "filosofi_2013.xlsx: 4.81 MB\n",
      "filosofi_2017.xlsx: 2.63 MB\n",
      "filosofi_2021.xlsx: 2.69 MB\n",
      "geofabrik_idf.osm.pbf: 309.12 MB\n",
      "iris.geojson: 11.11 MB\n",
      "sirene.parquet: 2043.89 MB\n",
      "\n",
      "PROCESSED DATASETS:\n",
      "----------------------------------------\n",
      "census_2013_paris.parquet: 0.11 MB\n",
      "census_2017_paris.parquet: 0.11 MB\n",
      "census_2021_paris.parquet: 0.10 MB\n",
      "dvf_mutations_paris.parquet: 4.30 MB\n",
      "filosofi_2013_paris.parquet: 0.05 MB\n",
      "filosofi_2017_paris.parquet: 0.04 MB\n",
      "filosofi_2021_paris.parquet: 0.04 MB\n",
      "iris_paris.geojson: 0.88 MB\n",
      "sirene_2014_2024_paris.parquet: 62.53 MB\n",
      "\n",
      "================================================================================\n",
      "DATA LOADING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Datasets summary:\n",
      "- 3 FILOSOFI datasets (2013, 2017, 2021) - Income data\n",
      "- 3 CENSUS datasets (2013, 2017, 2021) - Population data\n",
      "- DVF Mutations - Real estate transactions\n",
      "- GEOFABRIK OSM - OpenStreetMap data for Île-de-France\n",
      "- IRIS GeoJSON - Geographic boundaries for Paris IRIS zones\n",
      "- Sirene (2014-2024) - Business establishments\n",
      "\n",
      "Raw data saved in '../raw_datasets/' folder\n",
      "Processed data saved in '../datasets/' folder - all filtered for Paris only.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Summary of all loaded datasets\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASETS LOADED - PARIS INTRA-MUROS ONLY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nRAW DATASETS:\")\n",
    "print(\"-\" * 40)\n",
    "raw_files = sorted(os.listdir(raw_datasets_dir))\n",
    "for file in raw_files:\n",
    "    file_path = raw_datasets_dir / file\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"{file}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\nPROCESSED DATASETS:\")\n",
    "print(\"-\" * 40)\n",
    "datasets_files = sorted(os.listdir(datasets_dir))\n",
    "for file in datasets_files:\n",
    "    file_path = datasets_dir / file\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"{file}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA LOADING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDatasets summary:\")\n",
    "print(\"- 3 FILOSOFI datasets (2013, 2017, 2021) - Income data\")\n",
    "print(\"- 3 CENSUS datasets (2013, 2017, 2021) - Population data\")\n",
    "print(\"- DVF Mutations - Real estate transactions\")\n",
    "print(\"- GEOFABRIK OSM - OpenStreetMap data for Île-de-France\")\n",
    "print(\"- IRIS GeoJSON - Geographic boundaries for Paris IRIS zones\")\n",
    "print(\"- Sirene (2014-2024) - Business establishments\")\n",
    "print(f\"\\nRaw data saved in '{raw_datasets_dir}/' folder\")\n",
    "print(f\"Processed data saved in '{datasets_dir}/' folder - all filtered for Paris only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face8147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
