{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "p3w9f1kbuoi",
   "metadata": {},
   "source": [
    "# Data Loading - Paris Gentrification Analysis\n",
    "\n",
    "**Purpose:** Download and load all raw data sources (FILOSOFI, EDUCATION, CENSUS, DVF, IRIS) for data preparation pipeline\n",
    "\n",
    "**Output:** Raw datasets stored in `raw_datasets/` folder, ready for cleaning and aggregation\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow Overview\n",
    "0. **Install Requirements**\n",
    "1. **Load FILOSOFI** - Income data (2013, 2017, 2021)\n",
    "2. **Load EDUCATION** - Higher education statistics (2013, 2017, 2021)\n",
    "3. **Load CENSUS** - Demographic data (2013, 2017, 2021)\n",
    "4. **Load DVF** - Real estate transaction data (2014-2021)\n",
    "5. **Load IRIS** - Geographic boundaries and type classifications\n",
    "6. **Export & Quality Check** - Verify all files loaded with expected structure\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a4f4f",
   "metadata": {},
   "source": [
    "## 0. Install Requirements\n",
    "\n",
    "First, let's install all the required packages from the requirements.txt file. Load libraries and set up the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e979ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages from requirements.txt...\n",
      "✅ All packages installed successfully!\n",
      "Requirement already satisfied: pandas>=1.5.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 3)) (2.3.4)\n",
      "Requirement already satisfied: geopandas>=0.12.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 7)) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 10)) (3.10.7)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 11)) (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.9.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 14)) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 15)) (1.7.2)\n",
      "Requirement already satisfied: libpysal>=4.6.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 18)) (4.13.0)\n",
      "Requirement already satisfied: esda>=2.4.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 19)) (2.8.0)\n",
      "Requirement already satisfied: splot>=1.1.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 20)) (1.1.7)\n",
      "Requirement already satisfied: xlrd>=2.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 23)) (2.0.2)\n",
      "Requirement already satisfied: openpyxl>=3.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 24)) (3.1.5)\n",
      "Requirement already satisfied: gdown>=4.6.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 25)) (5.2.0)\n",
      "Requirement already satisfied: jupyter>=1.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 28)) (1.1.1)\n",
      "Requirement already satisfied: ipykernel>=6.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 29)) (7.1.0)\n",
      "Requirement already satisfied: pyproj>=3.4.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 32)) (3.7.2)\n",
      "Requirement already satisfied: fiona>=1.8.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 33)) (1.10.1)\n",
      "Requirement already satisfied: rtree>=1.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 34)) (1.4.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 37)) (22.0.0)\n",
      "Requirement already satisfied: black>=22.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 40)) (25.9.0)\n",
      "Requirement already satisfied: flake8>=5.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 41)) (7.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from pandas>=1.5.0->-r ../requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from pandas>=1.5.0->-r ../requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from pandas>=1.5.0->-r ../requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from geopandas>=0.12.0->-r ../requirements.txt (line 6)) (0.11.1)\n",
      "Requirement already satisfied: packaging in /workspaces/thesis/.venv/lib/python3.12/site-packages (from geopandas>=0.12.0->-r ../requirements.txt (line 6)) (25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0->-r ../requirements.txt (line 10)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0->-r ../requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0->-r ../requirements.txt (line 10)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0->-r ../requirements.txt (line 10)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0->-r ../requirements.txt (line 10)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0->-r ../requirements.txt (line 10)) (3.2.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from scikit-learn>=1.1.0->-r ../requirements.txt (line 15)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from scikit-learn>=1.1.0->-r ../requirements.txt (line 15)) (3.6.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.10 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from libpysal>=4.6.0->-r ../requirements.txt (line 18)) (4.14.2)\n",
      "Requirement already satisfied: platformdirs>=2.0.2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from libpysal>=4.6.0->-r ../requirements.txt (line 18)) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.27 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from libpysal>=4.6.0->-r ../requirements.txt (line 18)) (2.32.5)\n",
      "Requirement already satisfied: giddy in /workspaces/thesis/.venv/lib/python3.12/site-packages (from splot>=1.1.0->-r ../requirements.txt (line 20)) (2.3.6)\n",
      "Requirement already satisfied: mapclassify in /workspaces/thesis/.venv/lib/python3.12/site-packages (from splot>=1.1.0->-r ../requirements.txt (line 20)) (2.10.0)\n",
      "Requirement already satisfied: spreg in /workspaces/thesis/.venv/lib/python3.12/site-packages (from splot>=1.1.0->-r ../requirements.txt (line 20)) (1.8.3)\n",
      "Requirement already satisfied: et-xmlfile in /workspaces/thesis/.venv/lib/python3.12/site-packages (from openpyxl>=3.0.0->-r ../requirements.txt (line 24)) (2.0.0)\n",
      "Requirement already satisfied: filelock in /workspaces/thesis/.venv/lib/python3.12/site-packages (from gdown>=4.6.0->-r ../requirements.txt (line 25)) (3.20.0)\n",
      "Requirement already satisfied: tqdm in /workspaces/thesis/.venv/lib/python3.12/site-packages (from gdown>=4.6.0->-r ../requirements.txt (line 25)) (4.67.1)\n",
      "Requirement already satisfied: notebook in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter>=1.0.0->-r ../requirements.txt (line 28)) (7.4.7)\n",
      "Requirement already satisfied: jupyter-console in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter>=1.0.0->-r ../requirements.txt (line 28)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter>=1.0.0->-r ../requirements.txt (line 28)) (7.16.6)\n",
      "Requirement already satisfied: ipywidgets in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter>=1.0.0->-r ../requirements.txt (line 28)) (8.1.7)\n",
      "Requirement already satisfied: jupyterlab in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter>=1.0.0->-r ../requirements.txt (line 28)) (4.4.10)\n",
      "Requirement already satisfied: comm>=0.1.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (9.6.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (7.1.2)\n",
      "Requirement already satisfied: pyzmq>=25 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (5.14.3)\n",
      "Requirement already satisfied: certifi in /workspaces/thesis/.venv/lib/python3.12/site-packages (from pyproj>=3.4.0->-r ../requirements.txt (line 32)) (2025.10.5)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from fiona>=1.8.0->-r ../requirements.txt (line 33)) (25.4.0)\n",
      "Requirement already satisfied: click~=8.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from fiona>=1.8.0->-r ../requirements.txt (line 33)) (8.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from fiona>=1.8.0->-r ../requirements.txt (line 33)) (1.1.1.2)\n",
      "Requirement already satisfied: cligj>=0.5 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from fiona>=1.8.0->-r ../requirements.txt (line 33)) (0.7.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from black>=22.0.0->-r ../requirements.txt (line 40)) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from black>=22.0.0->-r ../requirements.txt (line 40)) (0.12.1)\n",
      "Requirement already satisfied: pytokens>=0.1.10 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from black>=22.0.0->-r ../requirements.txt (line 40)) (0.2.0)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from flake8>=5.0.0->-r ../requirements.txt (line 41)) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.15.0,>=2.14.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from flake8>=5.0.0->-r ../requirements.txt (line 41)) (2.14.0)\n",
      "Requirement already satisfied: pyflakes<3.5.0,>=3.4.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from flake8>=5.0.0->-r ../requirements.txt (line 41)) (3.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from beautifulsoup4>=4.10->libpysal>=4.6.0->-r ../requirements.txt (line 18)) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from beautifulsoup4>=4.10->libpysal>=4.6.0->-r ../requirements.txt (line 18)) (4.15.0)\n",
      "Requirement already satisfied: decorator in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /workspaces/thesis/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->-r ../requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from requests>=2.27->libpysal>=4.6.0->-r ../requirements.txt (line 18)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from requests>=2.27->libpysal>=4.6.0->-r ../requirements.txt (line 18)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from requests>=2.27->libpysal>=4.6.0->-r ../requirements.txt (line 18)) (2.5.0)\n",
      "Requirement already satisfied: quantecon>=0.7 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from giddy->splot>=1.1.0->-r ../requirements.txt (line 20)) (0.10.1)\n",
      "Requirement already satisfied: networkx>=3.2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from mapclassify->splot>=1.1.0->-r ../requirements.txt (line 20)) (3.5)\n",
      "Requirement already satisfied: numba>=0.49.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from quantecon>=0.7->giddy->splot>=1.1.0->-r ../requirements.txt (line 20)) (0.62.1)\n",
      "Requirement already satisfied: sympy in /workspaces/thesis/.venv/lib/python3.12/site-packages (from quantecon>=0.7->giddy->splot>=1.1.0->-r ../requirements.txt (line 20)) (1.14.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from numba>=0.49.0->quantecon>=0.7->giddy->splot>=1.1.0->-r ../requirements.txt (line 20)) (0.45.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipywidgets->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from ipywidgets->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (3.0.15)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (80.9.0)\n",
      "Requirement already satisfied: anyio in /workspaces/thesis/.venv/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /workspaces/thesis/.venv/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.23.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (4.25.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /workspaces/thesis/.venv/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (25.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.28.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (24.11.1)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in /workspaces/thesis/.venv/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /workspaces/thesis/.venv/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from nbconvert->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /workspaces/thesis/.venv/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (2.21.2)\n",
      "Requirement already satisfied: lark>=1.2.2 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /workspaces/thesis/.venv/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (2.23)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r ../requirements.txt (line 28)) (1.4.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from requests[socks]->gdown>=4.6.0->-r ../requirements.txt (line 25)) (1.7.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /workspaces/thesis/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.0.0->-r ../requirements.txt (line 29)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspaces/thesis/.venv/lib/python3.12/site-packages (from sympy->quantecon>=0.7->giddy->splot>=1.1.0->-r ../requirements.txt (line 20)) (1.3.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install all required packages from requirements.txt\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Install packages from requirements.txt file\"\"\"\n",
    "    try:\n",
    "        requirements_path = \"../requirements.txt\"\n",
    "        \n",
    "        print(\"Installing packages from requirements.txt...\")\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_path\n",
    "        ], capture_output=True, text=True, check=True)\n",
    "        \n",
    "        print(\"✅ All packages installed successfully!\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"❌ Error installing packages:\")\n",
    "        print(e.stderr)\n",
    "        raise\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ requirements.txt file not found at ../requirements.txt\")\n",
    "        print(\"Please make sure the requirements.txt file exists in the parent directory.\")\n",
    "        raise\n",
    "\n",
    "# Run the installation\n",
    "install_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee9f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Datasets directory ready at: ../datasets\n",
      "Raw datasets directory ready at: ../raw_datasets\n"
     ]
    }
   ],
   "source": [
    "# Setup: Create necessary directories\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import gdown\n",
    "import xlrd\n",
    "\n",
    "# Create datasets and raw_datasets folders if they don't exist\n",
    "datasets_dir = Path('..') / 'datasets'\n",
    "raw_datasets_dir = Path('..') / 'raw_datasets'\n",
    "datasets_dir.mkdir(exist_ok=True)\n",
    "raw_datasets_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Setup complete. Datasets directory ready at: {datasets_dir}\")\n",
    "print(f\"Raw datasets directory ready at: {raw_datasets_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4d67e",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Load FILOSOFI Datasets (2013, 2017, 2021)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125181df",
   "metadata": {},
   "source": [
    "FILOSOFI datasets contain income and living standards data at IRIS level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bpra809573q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1fRbArcfw_DHrycI11NsjbosnXCp6Nh26\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2013.xlsx\n",
      "100%|██████████| 5.04M/5.04M [00:00<00:00, 125MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6013', 'DISP_Q113', 'DISP_MED13', 'DISP_Q313', 'DISP_EQ13', 'DISP_D113', 'DISP_D213', 'DISP_D313', 'DISP_D413', 'DISP_D613', 'DISP_D713', 'DISP_D813', 'DISP_D913', 'DISP_RD13', 'DISP_S80S2013', 'DISP_GI13', 'DISP_PTSAC13', 'DISP_PBEN13', 'DISP_PPEN13', 'DISP_PPAT13', 'DISP_PPSOC13', 'DISP_PPFAM13', 'DISP_PPMINI13', 'DISP_PPLOGT13', 'DISP_PIMPOT13']\n",
      "FILOSOFI 2013: 853 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2013\n",
    "print(\"Loading FILOSOFI 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1fRbArcfw_DHrycI11NsjbosnXCp6Nh26'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2013.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED13': 'median_uc',}\n",
    "\n",
    "# Filter for Paris intra-muros (département 75)\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2013_paris = filosofi_2013[filosofi_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2013_paris.columns]\n",
    "filosofi_2013_paris = filosofi_2013_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2013_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2013_paris.to_parquet(datasets_dir / 'filosofi_2013_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2013: {len(filosofi_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ewz3ck2y91r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - FILOSOFI 2013\n",
      "============================================================\n",
      "Number of IRIS: 853\n",
      "Number of rows: 853\n",
      "Number of columns: 3\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010201', '751010202', '751010203', '751010204', '751010301', '751010401', '751020601', '751020701', '751020702', '751020703']\n",
      "\n",
      "Data types:\n",
      "code_iris        object\n",
      "libelle_iris     object\n",
      "median_uc       float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris       0\n",
      "libelle_iris    0\n",
      "median_uc       0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify FILOSOFI 2013 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - FILOSOFI 2013\")\n",
    "print(\"=\" * 60)\n",
    "loaded_filosofi_2013 = pd.read_parquet(datasets_dir / 'filosofi_2013_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_filosofi_2013)}\")\n",
    "print(f\"Number of rows: {len(loaded_filosofi_2013)}\")\n",
    "print(f\"Number of columns: {len(loaded_filosofi_2013.columns)}\")\n",
    "print(f\"Columns: {list(loaded_filosofi_2013.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_filosofi_2013['code_iris'].head(10).tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_filosofi_2013.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_filosofi_2013.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "w0huionnxs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1IhvzpWGInGlDj7Xpi4kHP87msylR7hiQ\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2017.xlsx\n",
      "100%|██████████| 2.76M/2.76M [00:00<00:00, 74.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6017', 'DISP_Q117', 'DISP_MED17', 'DISP_Q317', 'DISP_EQ17', 'DISP_D117', 'DISP_D217', 'DISP_D317', 'DISP_D417', 'DISP_D617', 'DISP_D717', 'DISP_D817', 'DISP_D917', 'DISP_RD17', 'DISP_S80S2017', 'DISP_GI17', 'DISP_PACT17', 'DISP_PTSA17', 'DISP_PCHO17', 'DISP_PBEN17', 'DISP_PPEN17', 'DISP_PPAT17', 'DISP_PPSOC17', 'DISP_PPFAM17', 'DISP_PPMINI17', 'DISP_PPLOGT17', 'DISP_PIMPOT17', 'DISP_NOTE17']\n",
      "FILOSOFI 2017: 871 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2017\n",
    "print(\"Loading FILOSOFI 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1IhvzpWGInGlDj7Xpi4kHP87msylR7hiQ'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2017.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED17': 'median_uc',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2017_paris = filosofi_2017[filosofi_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2017_paris.columns]\n",
    "filosofi_2017_paris = filosofi_2017_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2017_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2017_paris.to_parquet(datasets_dir / 'filosofi_2017_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2017: {len(filosofi_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sm4m8l2cpb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - FILOSOFI 2017\n",
      "============================================================\n",
      "Number of IRIS: 871\n",
      "Number of rows: 871\n",
      "Number of columns: 3\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010201', '751010202', '751010203', '751010204', '751010301', '751010401', '751010402', '751020601', '751020602', '751020701']\n",
      "\n",
      "Data types:\n",
      "code_iris        object\n",
      "libelle_iris     object\n",
      "median_uc       float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris       0\n",
      "libelle_iris    0\n",
      "median_uc       1\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify FILOSOFI 2017 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - FILOSOFI 2017\")\n",
    "print(\"=\" * 60)\n",
    "loaded_filosofi_2017 = pd.read_parquet(datasets_dir / 'filosofi_2017_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_filosofi_2017)}\")\n",
    "print(f\"Number of rows: {len(loaded_filosofi_2017)}\")\n",
    "print(f\"Number of columns: {len(loaded_filosofi_2017.columns)}\")\n",
    "print(f\"Columns: {list(loaded_filosofi_2017.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_filosofi_2017['code_iris'].head(10).tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_filosofi_2017.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_filosofi_2017.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hvqfjbnda9g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FILOSOFI 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Har2wCg63dQZSTWYxmyXQ0DcQ0dHylX8\n",
      "To: /workspaces/thesis/raw_datasets/filosofi_2021.xlsx\n",
      "100%|██████████| 2.82M/2.82M [00:00<00:00, 69.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['IRIS', 'LIBIRIS', 'COM', 'LIBCOM', 'DISP_TP6021', 'DISP_INCERT21', 'DISP_Q121', 'DISP_MED21', 'DISP_Q321', 'DISP_EQ21', 'DISP_D121', 'DISP_D221', 'DISP_D321', 'DISP_D421', 'DISP_D621', 'DISP_D721', 'DISP_D821', 'DISP_D921', 'DISP_RD21', 'DISP_S80S2021', 'DISP_GI21', 'DISP_PACT21', 'DISP_PTSA21', 'DISP_PCHO21', 'DISP_PBEN21', 'DISP_PPEN21', 'DISP_PPAT21', 'DISP_PPSOC21', 'DISP_PPFAM21', 'DISP_PPMINI21', 'DISP_PPLOGT21', 'DISP_PIMPOT21', 'DISP_NOTE21']\n",
      "FILOSOFI 2021: 992 IRIS in Paris saved\n",
      "Final columns: ['code_iris', 'libelle_iris', 'median_uc']\n"
     ]
    }
   ],
   "source": [
    "# FILOSOFI 2021\n",
    "print(\"Loading FILOSOFI 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1Har2wCg63dQZSTWYxmyXQ0DcQ0dHylX8'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'filosofi_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "filosofi_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "print(f\"Available columns: {list(filosofi_2021.columns)}\")\n",
    "\n",
    "# Define columns to keep with their new names\n",
    "filosofi_columns_to_keep = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'LIBIRIS': 'libelle_iris',\n",
    "    'DISP_MED21': 'median_uc',\n",
    "}\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = 'IRIS'\n",
    "filosofi_2021_paris = filosofi_2021[filosofi_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Select only columns that exist in the dataframe\n",
    "cols_to_keep = [col for col in filosofi_columns_to_keep.keys() if col in filosofi_2021_paris.columns]\n",
    "filosofi_2021_paris = filosofi_2021_paris[cols_to_keep].copy()\n",
    "\n",
    "# Rename columns\n",
    "rename_mapping = {col: filosofi_columns_to_keep[col] for col in cols_to_keep}\n",
    "filosofi_2021_paris.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save to datasets folder\n",
    "filosofi_2021_paris.to_parquet(datasets_dir / 'filosofi_2021_paris.parquet', index=False)\n",
    "print(f\"FILOSOFI 2021: {len(filosofi_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Final columns: {list(filosofi_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c1z05jym69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - FILOSOFI 2021\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 3\n",
      "Columns: ['code_iris', 'libelle_iris', 'median_uc']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Data types:\n",
      "code_iris       object\n",
      "libelle_iris    object\n",
      "median_uc       object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris       0\n",
      "libelle_iris    0\n",
      "median_uc       0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify FILOSOFI 2021 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - FILOSOFI 2021\")\n",
    "print(\"=\" * 60)\n",
    "loaded_filosofi_2021 = pd.read_parquet(datasets_dir / 'filosofi_2021_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_filosofi_2021)}\")\n",
    "print(f\"Number of rows: {len(loaded_filosofi_2021)}\")\n",
    "print(f\"Number of columns: {len(loaded_filosofi_2021.columns)}\")\n",
    "print(f\"Columns: {list(loaded_filosofi_2021.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_filosofi_2021['code_iris'].head(10).tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_filosofi_2021.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_filosofi_2021.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775ef48",
   "metadata": {},
   "source": [
    "## 2. Load EDUCATION Datasets (2013, 2017, 2021)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d67fdc",
   "metadata": {},
   "source": [
    "Education datasets contain higher education attainment data at IRIS level.\n",
    "\n",
    "**2013**: \n",
    "- `P13_NSCOL15P_SUP` → `pop_bac_sup` (all higher education, not subdivided)\n",
    "\n",
    "**2017/2021**: \n",
    "- `P17/P21_NSCOL15P_SUP2` → `pop_bac2` (Bac+2)\n",
    "- `P17/P21_NSCOL15P_SUP34` → `pop_bac34` (Bac+3/4)\n",
    "- `P17/P21_NSCOL15P_SUP5` → `pop_bac5_plus` (Bac+5+)\n",
    "- **Aggregated**: `pop_bac_sup` = sum of the 3 above (to match 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ae487cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EDUCATION 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JmDo7waeztZukDAskj1PUGvzawussYWC\n",
      "To: /workspaces/thesis/raw_datasets/education_2013.xlsx\n",
      "100%|██████████| 37.1M/37.1M [00:00<00:00, 168MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION 2013: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'pop_bac_sup']\n"
     ]
    }
   ],
   "source": [
    "# EDUCATION 2013\n",
    "print(\"Loading EDUCATION 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1JmDo7waeztZukDAskj1PUGvzawussYWC'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'education_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "education_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in education_2013.columns if 'IRIS' in col.upper()][0]\n",
    "education_2013_paris = education_2013[education_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# P13_NSCOL15P_SUP = All higher education (Bac+2, Bac+3/4, Bac+5+ combined)\n",
    "education_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'P13_NSCOL15P_SUP': 'pop_bac_sup',  # All higher education (to match aggregated 2017/2021)\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in education_columns_mapping.keys() if col in education_2013_paris.columns]\n",
    "final_names = [education_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "education_2013_paris = education_2013_paris[cols_to_keep].copy()\n",
    "education_2013_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "education_2013_paris.to_parquet(datasets_dir / 'education_2013_paris.parquet', index=False)\n",
    "print(f\"EDUCATION 2013: {len(education_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(education_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b07498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - EDUCATION 2013\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 2\n",
      "Columns: ['code_iris', 'pop_bac_sup']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Education Statistics:\n",
      "  Total Higher Ed (all): 914,174\n",
      "  Avg Higher Ed (all):   921.5\n",
      "\n",
      "Note: 2013 data is not subdivided (includes all Bac+2, Bac+3/4, Bac+5+)\n",
      "\n",
      "Data types:\n",
      "code_iris       object\n",
      "pop_bac_sup    float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris      0\n",
      "pop_bac_sup    0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify EDUCATION 2013 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - EDUCATION 2013\")\n",
    "print(\"=\" * 60)\n",
    "loaded_education_2013 = pd.read_parquet(datasets_dir / 'education_2013_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_education_2013)}\")\n",
    "print(f\"Number of rows: {len(loaded_education_2013)}\")\n",
    "print(f\"Number of columns: {len(loaded_education_2013.columns)}\")\n",
    "print(f\"Columns: {list(loaded_education_2013.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_education_2013['code_iris'].head(10).tolist())\n",
    "print(f\"\\nEducation Statistics:\")\n",
    "print(f\"  Total Higher Ed (all): {loaded_education_2013['pop_bac_sup'].sum():,.0f}\")\n",
    "print(f\"  Avg Higher Ed (all):   {loaded_education_2013['pop_bac_sup'].mean():,.1f}\")\n",
    "print(f\"\\nNote: 2013 data is not subdivided (includes all Bac+2, Bac+3/4, Bac+5+)\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_education_2013.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_education_2013.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6588ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EDUCATION 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZyxFLSPaGfnVi29HjdxNoMlLh9XoeWye\n",
      "To: /workspaces/thesis/raw_datasets/education_2017.xlsx\n",
      "100%|██████████| 26.5M/26.5M [00:00<00:00, 88.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION 2017: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'pop_bac2', 'pop_bac34', 'pop_bac5_plus', 'pop_bac_sup']\n"
     ]
    }
   ],
   "source": [
    "# EDUCATION 2017\n",
    "print(\"Loading EDUCATION 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1ZyxFLSPaGfnVi29HjdxNoMlLh9XoeWye'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'education_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "education_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in education_2017.columns if 'IRIS' in col.upper()][0]\n",
    "education_2017_paris = education_2017[education_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "education_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'P17_NSCOL15P_SUP2': 'pop_bac2',        # Bac+2\n",
    "    'P17_NSCOL15P_SUP34': 'pop_bac34',      # Bac+3/4\n",
    "    'P17_NSCOL15P_SUP5': 'pop_bac5_plus',   # Bac+5+\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in education_columns_mapping.keys() if col in education_2017_paris.columns]\n",
    "final_names = [education_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "education_2017_paris = education_2017_paris[cols_to_keep].copy()\n",
    "education_2017_paris.columns = final_names\n",
    "\n",
    "# Create aggregated column to match 2013 (all higher education)\n",
    "education_2017_paris['pop_bac_sup'] = (\n",
    "    education_2017_paris['pop_bac2'] + \n",
    "    education_2017_paris['pop_bac34'] + \n",
    "    education_2017_paris['pop_bac5_plus']\n",
    ")\n",
    "\n",
    "# Save to datasets folder\n",
    "education_2017_paris.to_parquet(datasets_dir / 'education_2017_paris.parquet', index=False)\n",
    "print(f\"EDUCATION 2017: {len(education_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(education_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f70e946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - EDUCATION 2017\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 5\n",
      "Columns: ['code_iris', 'pop_bac2', 'pop_bac34', 'pop_bac5_plus', 'pop_bac_sup']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Education Statistics:\n",
      "  Total Bac+2:          133,482\n",
      "  Total Bac+3/4:        245,114\n",
      "  Total Bac+5+:         606,156\n",
      "  Total Higher Ed (all): 984,751\n",
      "\n",
      "Averages per IRIS:\n",
      "  Avg Bac+2:            134.6\n",
      "  Avg Bac+3/4:          247.1\n",
      "  Avg Bac+5+:           611.0\n",
      "  Avg Higher Ed (all):  992.7\n",
      "\n",
      "Data types:\n",
      "code_iris         object\n",
      "pop_bac2         float64\n",
      "pop_bac34        float64\n",
      "pop_bac5_plus    float64\n",
      "pop_bac_sup      float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris        0\n",
      "pop_bac2         0\n",
      "pop_bac34        0\n",
      "pop_bac5_plus    0\n",
      "pop_bac_sup      0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify EDUCATION 2017 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - EDUCATION 2017\")\n",
    "print(\"=\" * 60)\n",
    "loaded_education_2017 = pd.read_parquet(datasets_dir / 'education_2017_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_education_2017)}\")\n",
    "print(f\"Number of rows: {len(loaded_education_2017)}\")\n",
    "print(f\"Number of columns: {len(loaded_education_2017.columns)}\")\n",
    "print(f\"Columns: {list(loaded_education_2017.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_education_2017['code_iris'].head(10).tolist())\n",
    "print(f\"\\nEducation Statistics:\")\n",
    "print(f\"  Total Bac+2:          {loaded_education_2017['pop_bac2'].sum():,.0f}\")\n",
    "print(f\"  Total Bac+3/4:        {loaded_education_2017['pop_bac34'].sum():,.0f}\")\n",
    "print(f\"  Total Bac+5+:         {loaded_education_2017['pop_bac5_plus'].sum():,.0f}\")\n",
    "print(f\"  Total Higher Ed (all): {loaded_education_2017['pop_bac_sup'].sum():,.0f}\")\n",
    "print(f\"\\nAverages per IRIS:\")\n",
    "print(f\"  Avg Bac+2:            {loaded_education_2017['pop_bac2'].mean():,.1f}\")\n",
    "print(f\"  Avg Bac+3/4:          {loaded_education_2017['pop_bac34'].mean():,.1f}\")\n",
    "print(f\"  Avg Bac+5+:           {loaded_education_2017['pop_bac5_plus'].mean():,.1f}\")\n",
    "print(f\"  Avg Higher Ed (all):  {loaded_education_2017['pop_bac_sup'].mean():,.1f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_education_2017.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_education_2017.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08118c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EDUCATION 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1gP0FNOwIM3KPq8nVbL_oj9U_IPVJdHQW\n",
      "To: /workspaces/thesis/raw_datasets/education_2021.xlsx\n",
      "100%|██████████| 29.2M/29.2M [00:00<00:00, 152MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION 2021: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'pop_bac2', 'pop_bac34', 'pop_bac5_plus', 'pop_bac_sup']\n"
     ]
    }
   ],
   "source": [
    "# EDUCATION 2021\n",
    "print(\"Loading EDUCATION 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1gP0FNOwIM3KPq8nVbL_oj9U_IPVJdHQW'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'education_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "education_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in education_2021.columns if 'IRIS' in col.upper()][0]\n",
    "education_2021_paris = education_2021[education_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "education_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'P21_NSCOL15P_SUP2': 'pop_bac2',        # Bac+2\n",
    "    'P21_NSCOL15P_SUP34': 'pop_bac34',      # Bac+3/4\n",
    "    'P21_NSCOL15P_SUP5': 'pop_bac5_plus',   # Bac+5+\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in education_columns_mapping.keys() if col in education_2021_paris.columns]\n",
    "final_names = [education_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "education_2021_paris = education_2021_paris[cols_to_keep].copy()\n",
    "education_2021_paris.columns = final_names\n",
    "\n",
    "# Create aggregated column to match 2013 (all higher education)\n",
    "education_2021_paris['pop_bac_sup'] = (\n",
    "    education_2021_paris['pop_bac2'] + \n",
    "    education_2021_paris['pop_bac34'] + \n",
    "    education_2021_paris['pop_bac5_plus']\n",
    ")\n",
    "\n",
    "# Save to datasets folder\n",
    "education_2021_paris.to_parquet(datasets_dir / 'education_2021_paris.parquet', index=False)\n",
    "print(f\"EDUCATION 2021: {len(education_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(education_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d11bf545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - EDUCATION 2021\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 5\n",
      "Columns: ['code_iris', 'pop_bac2', 'pop_bac34', 'pop_bac5_plus', 'pop_bac_sup']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Education Statistics:\n",
      "  Total Bac+2:          123,521\n",
      "  Total Bac+3/4:        238,092\n",
      "  Total Bac+5+:         642,412\n",
      "  Total Higher Ed (all): 1,004,025\n",
      "\n",
      "Averages per IRIS:\n",
      "  Avg Bac+2:            124.5\n",
      "  Avg Bac+3/4:          240.0\n",
      "  Avg Bac+5+:           647.6\n",
      "  Avg Higher Ed (all):  1,012.1\n",
      "\n",
      "Data types:\n",
      "code_iris         object\n",
      "pop_bac2         float64\n",
      "pop_bac34        float64\n",
      "pop_bac5_plus    float64\n",
      "pop_bac_sup      float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris        0\n",
      "pop_bac2         0\n",
      "pop_bac34        0\n",
      "pop_bac5_plus    0\n",
      "pop_bac_sup      0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify EDUCATION 2021 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - EDUCATION 2021\")\n",
    "print(\"=\" * 60)\n",
    "loaded_education_2021 = pd.read_parquet(datasets_dir / 'education_2021_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_education_2021)}\")\n",
    "print(f\"Number of rows: {len(loaded_education_2021)}\")\n",
    "print(f\"Number of columns: {len(loaded_education_2021.columns)}\")\n",
    "print(f\"Columns: {list(loaded_education_2021.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_education_2021['code_iris'].head(10).tolist())\n",
    "print(f\"\\nEducation Statistics:\")\n",
    "print(f\"  Total Bac+2:          {loaded_education_2021['pop_bac2'].sum():,.0f}\")\n",
    "print(f\"  Total Bac+3/4:        {loaded_education_2021['pop_bac34'].sum():,.0f}\")\n",
    "print(f\"  Total Bac+5+:         {loaded_education_2021['pop_bac5_plus'].sum():,.0f}\")\n",
    "print(f\"  Total Higher Ed (all): {loaded_education_2021['pop_bac_sup'].sum():,.0f}\")\n",
    "print(f\"\\nAverages per IRIS:\")\n",
    "print(f\"  Avg Bac+2:            {loaded_education_2021['pop_bac2'].mean():,.1f}\")\n",
    "print(f\"  Avg Bac+3/4:          {loaded_education_2021['pop_bac34'].mean():,.1f}\")\n",
    "print(f\"  Avg Bac+5+:           {loaded_education_2021['pop_bac5_plus'].mean():,.1f}\")\n",
    "print(f\"  Avg Higher Ed (all):  {loaded_education_2021['pop_bac_sup'].mean():,.1f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_education_2021.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_education_2021.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e781af1",
   "metadata": {},
   "source": [
    "## 3. Load CENSUS Datasets (2013, 2017, 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb74ed8",
   "metadata": {},
   "source": [
    "CENSUS datasets contain demographic and occupational data at IRIS level.\n",
    "\n",
    "**Variables extracted (all years 2013, 2017, 2021):**\n",
    "- **Population totals**: `pop_total`, `pop_15plus`\n",
    "- **Age groups**: `pop_18_24`, `pop_25_39`, `pop_65plus`\n",
    "- **Occupations**: `pop_cadres` (executives), `pop_prof_inter` (intermediate professions), `pop_employes` (employees), `pop_ouvriers` (workers)\n",
    "- **Immigration**: `pop_immigres`, `pop_etrangers` (foreigners)\n",
    "- **IRIS type**: `typ_iris` (H=Habitat, D=Divers, A=Activité)\n",
    "\n",
    "**Year prefixes**: \n",
    "- 2013: `P13_` / `C13_`\n",
    "- 2017: `P17_` / `C17_`\n",
    "- 2021: `P21_` / `C21_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "w3y327puth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1b2LTSza0fRFkuVnvni60cKWKi51g3BQh\n",
      "To: /workspaces/thesis/raw_datasets/census_2013.xlsx\n",
      "100%|██████████| 70.7M/70.7M [00:00<00:00, 178MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2013: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2013\n",
    "print(\"Loading CENSUS 2013...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1b2LTSza0fRFkuVnvni60cKWKi51g3BQh'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2013.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2013 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2013.columns if 'IRIS' in col.upper()][0]\n",
    "census_2013_paris = census_2013[census_2013[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P13_POP': 'pop_total',\n",
    "    'C13_POP15P': 'pop_15plus',\n",
    "    'C13_POP15P_CS3': 'pop_cadres',\n",
    "    'C13_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C13_POP15P_CS5': 'pop_employes',\n",
    "    'C13_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P13_POP1824': 'pop_18_24',\n",
    "    'P13_POP2539': 'pop_25_39',\n",
    "    'P13_POP65P': 'pop_65plus',\n",
    "    'P13_POP_IMM': 'pop_immigres',\n",
    "    'P13_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2013_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2013_paris = census_2013_paris[cols_to_keep].copy()\n",
    "census_2013_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "census_2013_paris.to_parquet(datasets_dir / 'census_2013_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2013: {len(census_2013_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2013_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wbhb53fyaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - CENSUS 2013\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 13\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Total population across all IRIS: 2,229,621\n",
      "\n",
      "Data types:\n",
      "code_iris          object\n",
      "typ_iris           object\n",
      "pop_total         float64\n",
      "pop_15plus        float64\n",
      "pop_cadres        float64\n",
      "pop_prof_inter    float64\n",
      "pop_employes      float64\n",
      "pop_ouvriers      float64\n",
      "pop_18_24         float64\n",
      "pop_25_39         float64\n",
      "pop_65plus        float64\n",
      "pop_immigres      float64\n",
      "pop_etrangers     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris         0\n",
      "typ_iris          0\n",
      "pop_total         0\n",
      "pop_15plus        0\n",
      "pop_cadres        0\n",
      "pop_prof_inter    0\n",
      "pop_employes      0\n",
      "pop_ouvriers      0\n",
      "pop_18_24         0\n",
      "pop_25_39         0\n",
      "pop_65plus        0\n",
      "pop_immigres      0\n",
      "pop_etrangers     0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CENSUS 2013 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - CENSUS 2013\")\n",
    "print(\"=\" * 60)\n",
    "loaded_census_2013 = pd.read_parquet(datasets_dir / 'census_2013_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_census_2013)}\")\n",
    "print(f\"Number of rows: {len(loaded_census_2013)}\")\n",
    "print(f\"Number of columns: {len(loaded_census_2013.columns)}\")\n",
    "print(f\"Columns: {list(loaded_census_2013.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_census_2013['code_iris'].head(10).tolist())\n",
    "print(f\"\\nTotal population across all IRIS: {loaded_census_2013['pop_total'].sum():,.0f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_census_2013.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_census_2013.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2jpiae70h58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2017...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1KHGwB0S8D-gj7f3d3LBCzRjqBWxaewzw\n",
      "To: /workspaces/thesis/raw_datasets/census_2017.xlsx\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 187MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2017: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2017\n",
    "print(\"Loading CENSUS 2017...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1KHGwB0S8D-gj7f3d3LBCzRjqBWxaewzw'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2017.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2017 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2017.columns if 'IRIS' in col.upper()][0]\n",
    "census_2017_paris = census_2017[census_2017[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables (2017 uses P17_ prefix)\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P17_POP': 'pop_total',\n",
    "    'C17_POP15P': 'pop_15plus',\n",
    "    'C17_POP15P_CS3': 'pop_cadres',\n",
    "    'C17_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C17_POP15P_CS5': 'pop_employes',\n",
    "    'C17_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P17_POP1824': 'pop_18_24',\n",
    "    'P17_POP2539': 'pop_25_39',\n",
    "    'P17_POP65P': 'pop_65plus',\n",
    "    'P17_POP_IMM': 'pop_immigres',\n",
    "    'P17_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2017_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2017_paris = census_2017_paris[cols_to_keep].copy()\n",
    "census_2017_paris.columns = final_names\n",
    "\n",
    "# Save to datasets folder\n",
    "census_2017_paris.to_parquet(datasets_dir / 'census_2017_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2017: {len(census_2017_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2017_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6494ygacjh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - CENSUS 2017\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 13\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Total population across all IRIS: 2,187,526\n",
      "\n",
      "Data types:\n",
      "code_iris          object\n",
      "typ_iris           object\n",
      "pop_total         float64\n",
      "pop_15plus        float64\n",
      "pop_cadres        float64\n",
      "pop_prof_inter    float64\n",
      "pop_employes      float64\n",
      "pop_ouvriers      float64\n",
      "pop_18_24         float64\n",
      "pop_25_39         float64\n",
      "pop_65plus        float64\n",
      "pop_immigres      float64\n",
      "pop_etrangers     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris         0\n",
      "typ_iris          0\n",
      "pop_total         0\n",
      "pop_15plus        0\n",
      "pop_cadres        0\n",
      "pop_prof_inter    0\n",
      "pop_employes      0\n",
      "pop_ouvriers      0\n",
      "pop_18_24         0\n",
      "pop_25_39         0\n",
      "pop_65plus        0\n",
      "pop_immigres      0\n",
      "pop_etrangers     0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CENSUS 2017 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - CENSUS 2017\")\n",
    "print(\"=\" * 60)\n",
    "loaded_census_2017 = pd.read_parquet(datasets_dir / 'census_2017_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_census_2017)}\")\n",
    "print(f\"Number of rows: {len(loaded_census_2017)}\")\n",
    "print(f\"Number of columns: {len(loaded_census_2017.columns)}\")\n",
    "print(f\"Columns: {list(loaded_census_2017.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_census_2017['code_iris'].head(10).tolist())\n",
    "print(f\"\\nTotal population across all IRIS: {loaded_census_2017['pop_total'].sum():,.0f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_census_2017.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_census_2017.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adem7qp2of4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CENSUS 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1yfZ3EYbtnDaRhDWvP_u8ovC6HwQNuq9s\n",
      "From (redirected): https://drive.google.com/uc?id=1yfZ3EYbtnDaRhDWvP_u8ovC6HwQNuq9s&confirm=t&uuid=35b26091-d87d-490b-bf63-a93d1bbfded5\n",
      "To: /workspaces/thesis/raw_datasets/census_2021.xlsx\n",
      "100%|██████████| 49.7M/49.7M [00:00<00:00, 122MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENSUS 2021: 992 IRIS in Paris saved\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n"
     ]
    }
   ],
   "source": [
    "# CENSUS 2021\n",
    "print(\"Loading CENSUS 2021...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1yfZ3EYbtnDaRhDWvP_u8ovC6HwQNuq9s'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'census_2021.xlsx'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "census_2021 = pd.read_excel(raw_file, header=5)\n",
    "\n",
    "# Filter for Paris intra-muros\n",
    "iris_col = [col for col in census_2021.columns if 'IRIS' in col.upper()][0]\n",
    "census_2021_paris = census_2021[census_2021[iris_col].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Keep only selected variables (2021 uses P21_ prefix)\n",
    "census_columns_mapping = {\n",
    "    'IRIS': 'code_iris',\n",
    "    'TYP_IRIS': 'typ_iris',\n",
    "    'P21_POP': 'pop_total',\n",
    "    'C21_POP15P': 'pop_15plus',\n",
    "    'C21_POP15P_CS3': 'pop_cadres',\n",
    "    'C21_POP15P_CS4': 'pop_prof_inter',\n",
    "    'C21_POP15P_CS5': 'pop_employes',\n",
    "    'C21_POP15P_CS6': 'pop_ouvriers',\n",
    "    'P21_POP1824': 'pop_18_24',\n",
    "    'P21_POP2539': 'pop_25_39',\n",
    "    'P21_POP65P': 'pop_65plus',\n",
    "    'P21_POP_IMM': 'pop_immigres',\n",
    "    'P21_POP_ETR': 'pop_etrangers',\n",
    "}\n",
    "\n",
    "cols_to_keep = [col for col in census_columns_mapping.keys() if col in census_2021_paris.columns]\n",
    "final_names = [census_columns_mapping[col] for col in cols_to_keep]\n",
    "\n",
    "census_2021_paris = census_2021_paris[cols_to_keep].copy()\n",
    "census_2021_paris.columns = final_names\n",
    "\n",
    "# Save to data folder\n",
    "census_2021_paris.to_parquet(datasets_dir / 'census_2021_paris.parquet', index=False)\n",
    "print(f\"CENSUS 2021: {len(census_2021_paris)} IRIS in Paris saved\")\n",
    "print(f\"Columns: {list(census_2021_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "i91s2f90il9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - CENSUS 2021\n",
      "============================================================\n",
      "Number of IRIS: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 13\n",
      "Columns: ['code_iris', 'typ_iris', 'pop_total', 'pop_15plus', 'pop_cadres', 'pop_prof_inter', 'pop_employes', 'pop_ouvriers', 'pop_18_24', 'pop_25_39', 'pop_65plus', 'pop_immigres', 'pop_etrangers']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751010101', '751010102', '751010103', '751010104', '751010105', '751010199', '751010201', '751010202', '751010203', '751010204']\n",
      "\n",
      "Total population across all IRIS: 2,133,111\n",
      "\n",
      "Data types:\n",
      "code_iris          object\n",
      "typ_iris           object\n",
      "pop_total         float64\n",
      "pop_15plus        float64\n",
      "pop_cadres        float64\n",
      "pop_prof_inter    float64\n",
      "pop_employes      float64\n",
      "pop_ouvriers      float64\n",
      "pop_18_24         float64\n",
      "pop_25_39         float64\n",
      "pop_65plus        float64\n",
      "pop_immigres      float64\n",
      "pop_etrangers     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "code_iris         0\n",
      "typ_iris          0\n",
      "pop_total         0\n",
      "pop_15plus        0\n",
      "pop_cadres        0\n",
      "pop_prof_inter    0\n",
      "pop_employes      0\n",
      "pop_ouvriers      0\n",
      "pop_18_24         0\n",
      "pop_25_39         0\n",
      "pop_65plus        0\n",
      "pop_immigres      0\n",
      "pop_etrangers     0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify CENSUS 2021 data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - CENSUS 2021\")\n",
    "print(\"=\" * 60)\n",
    "loaded_census_2021 = pd.read_parquet(datasets_dir / 'census_2021_paris.parquet')\n",
    "print(f\"Number of IRIS: {len(loaded_census_2021)}\")\n",
    "print(f\"Number of rows: {len(loaded_census_2021)}\")\n",
    "print(f\"Number of columns: {len(loaded_census_2021.columns)}\")\n",
    "print(f\"Columns: {list(loaded_census_2021.columns)}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_census_2021['code_iris'].head(10).tolist())\n",
    "print(f\"\\nTotal population across all IRIS: {loaded_census_2021['pop_total'].sum():,.0f}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_census_2021.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_census_2021.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u7o4zrdrvym",
   "metadata": {},
   "source": [
    "## 4. Load DVF Mutations Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a19ece",
   "metadata": {},
   "source": [
    "Real estate transaction data (Demandes de Valeurs Foncières)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59a7888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DVF Mutations dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN\n",
      "From (redirected): https://drive.google.com/uc?id=1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN&confirm=t&uuid=84fe0012-ed57-4b5c-a7dd-e0cf9d56c27c\n",
      "To: /workspaces/thesis/raw_datasets/dvf_mutations.gpkg\n",
      "100%|██████████| 358M/358M [00:01<00:00, 216MB/s]  \n",
      "/workspaces/thesis/.venv/lib/python3.12/site-packages/pyogrio/geopandas.py:275: UserWarning: More than one layer found in 'dvf_mutations.gpkg': 'mutation_geompar' (default), 'mutation_geomparmut', 'mutation_geomlocmut'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVF Mutations: 457097 transactions in Paris saved\n",
      "Columns: ['datemut', 'anneemut', 'moismut', 'coddep', 'l_codinsee', 'valeurfonc', 'libtypbien', 'codtypbien', 'sbati', 'geometry']\n",
      "Geometry preserved: 456962 parcels with geometry (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# DVF Mutations - Download from Google Drive using gdown\n",
    "# File ID: 1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN\n",
    "print(\"Loading DVF Mutations dataset...\")\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# Download file\n",
    "file_id = '1tPQNJNFTpt0Hf_H5U9Ikk6L7c4y7d7nN'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'dvf_mutations.gpkg'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "# Read and filter (keep as GeoDataFrame to preserve geometry)\n",
    "dvf_mutations = gpd.read_file(raw_file)\n",
    "dvf_mutations_paris = dvf_mutations[dvf_mutations['coddep'] == '75'].copy()\n",
    "\n",
    "# Keep only selected columns + geometry\n",
    "columns_to_keep = [\n",
    "    'datemut', 'anneemut', 'moismut',  # temporal\n",
    "    'coddep', 'l_codinsee',  # spatial\n",
    "    'valeurfonc',  # transaction value\n",
    "    'libtypbien', 'codtypbien',  # property type\n",
    "    'sbati',  # built surface\n",
    "    'geometry',  # geographic data (parcels)\n",
    "]\n",
    "\n",
    "# Only keep columns that exist\n",
    "existing_columns = [col for col in columns_to_keep if col in dvf_mutations_paris.columns]\n",
    "dvf_mutations_paris = dvf_mutations_paris[existing_columns].copy()\n",
    "\n",
    "# Save as GeoParquet to preserve geometry\n",
    "dvf_mutations_paris.to_parquet(datasets_dir / 'dvf_mutations_paris.parquet', index=False)\n",
    "print(f\"DVF Mutations: {len(dvf_mutations_paris)} transactions in Paris saved\")\n",
    "print(f\"Columns: {list(dvf_mutations_paris.columns)}\")\n",
    "print(f\"Geometry preserved: {dvf_mutations_paris.geometry.notna().sum()} parcels with geometry ({dvf_mutations_paris.geometry.notna().sum()/len(dvf_mutations_paris)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8vuei9lymvo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - DVF MUTATIONS\n",
      "============================================================\n",
      "Number of transactions: 457097\n",
      "Number of rows: 457097\n",
      "Number of columns: 10\n",
      "Columns: ['datemut', 'anneemut', 'moismut', 'coddep', 'l_codinsee', 'valeurfonc', 'libtypbien', 'codtypbien', 'sbati', 'geometry']\n",
      "\n",
      "Date range: 2014-01-02 to 2024-12-31\n",
      "Years covered: [np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n",
      "\n",
      "Total transaction value: 337,968,281,467 EUR\n",
      "Average transaction value: 739,820.02 EUR\n",
      "\n",
      "Property types:\n",
      "libtypbien\n",
      "UN APPARTEMENT                               330601\n",
      "UNE DEPENDANCE                                51776\n",
      "ACTIVITE                                      29326\n",
      "DEUX APPARTEMENTS                             16431\n",
      "BATI MIXTE - LOGEMENT/ACTIVITE                 7705\n",
      "DES DEPENDANCES                                7327\n",
      "APPARTEMENT INDETERMINE                        6346\n",
      "BATI - INDETERMINE : Vefa sans descriptif      4184\n",
      "UNE MAISON                                     1614\n",
      "BATI - INDETERMINE : Vente avec volume(s)      1267\n",
      "TERRAIN ARTIFICIALISE MIXTE                     250\n",
      "TERRAIN DE TYPE TAB                             101\n",
      "BATI MIXTE - LOGEMENTS                           89\n",
      "DES MAISONS                                      53\n",
      "TERRAIN DE TYPE RESEAU                           17\n",
      "TERRAIN D'AGREMENT                                9\n",
      "MAISON - INDETERMINEE                             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Geometry information:\n",
      "  Has geometry column: True\n",
      "  Non-null geometries: 456962\n",
      "  Geometry types: ['MultiPolygon']\n",
      "\n",
      "Data types:\n",
      "datemut         object\n",
      "anneemut         int64\n",
      "moismut          int64\n",
      "coddep          object\n",
      "l_codinsee      object\n",
      "valeurfonc     float64\n",
      "libtypbien      object\n",
      "codtypbien      object\n",
      "sbati          float64\n",
      "geometry      geometry\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "datemut         0\n",
      "anneemut        0\n",
      "moismut         0\n",
      "coddep          0\n",
      "l_codinsee      0\n",
      "valeurfonc    272\n",
      "libtypbien      0\n",
      "codtypbien      0\n",
      "sbati           0\n",
      "geometry      135\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify DVF Mutations data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - DVF MUTATIONS\")\n",
    "print(\"=\" * 60)\n",
    "loaded_dvf = gpd.read_parquet(datasets_dir / 'dvf_mutations_paris.parquet')\n",
    "print(f\"Number of transactions: {len(loaded_dvf)}\")\n",
    "print(f\"Number of rows: {len(loaded_dvf)}\")\n",
    "print(f\"Number of columns: {len(loaded_dvf.columns)}\")\n",
    "print(f\"Columns: {list(loaded_dvf.columns)}\")\n",
    "print(f\"\\nDate range: {loaded_dvf['datemut'].min()} to {loaded_dvf['datemut'].max()}\")\n",
    "print(f\"Years covered: {sorted(loaded_dvf['anneemut'].unique())}\")\n",
    "print(f\"\\nTotal transaction value: {loaded_dvf['valeurfonc'].sum():,.0f} EUR\")\n",
    "print(f\"Average transaction value: {loaded_dvf['valeurfonc'].mean():,.2f} EUR\")\n",
    "print(f\"\\nProperty types:\")\n",
    "print(loaded_dvf['libtypbien'].value_counts())\n",
    "print(f\"\\nGeometry information:\")\n",
    "print(f\"  Has geometry column: {'geometry' in loaded_dvf.columns}\")\n",
    "if 'geometry' in loaded_dvf.columns:\n",
    "    print(f\"  Non-null geometries: {loaded_dvf.geometry.notna().sum()}\")\n",
    "    print(f\"  Geometry types: {loaded_dvf[loaded_dvf.geometry.notna()].geometry.geom_type.unique()}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_dvf.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_dvf.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s7uqc2xy30p",
   "metadata": {},
   "source": [
    "## 5. Load IRIS GeoJSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b2bbc",
   "metadata": {},
   "source": [
    "Geographic boundaries for IRIS zones in France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "qu2zsga8psj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IRIS GeoJSON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yWwsp5LcykD5UtvVPj_S695ALSKsCskP\n",
      "To: /workspaces/thesis/raw_datasets/iris.geojson\n",
      "100%|██████████| 11.6M/11.6M [00:00<00:00, 56.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS GeoJSON: 992 IRIS zones in Paris saved\n",
      "Columns: ['dep', 'insee_com', 'nom_com', 'iris', 'code_iris', 'nom_iris', 'typ_iris', 'geo_point_2d', 'id', 'geometry']\n"
     ]
    }
   ],
   "source": [
    "# IRIS GeoJSON - Geographic boundaries\n",
    "print(\"Loading IRIS GeoJSON...\")\n",
    "\n",
    "# Download file\n",
    "file_id = '1yWwsp5LcykD5UtvVPj_S695ALSKsCskP'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "raw_file = raw_datasets_dir / 'iris.geojson'\n",
    "gdown.download(url, str(raw_file), quiet=False)\n",
    "\n",
    "iris_geo = gpd.read_file(raw_file)\n",
    "\n",
    "# Filter for Paris intra-muros using the code_iris column (full 9-digit code)\n",
    "iris_geo_paris = iris_geo[iris_geo['code_iris'].astype(str).str.startswith('75')].copy()\n",
    "\n",
    "# Save to datasets folder\n",
    "iris_geo_paris.to_file(datasets_dir / 'iris_paris.geojson', driver='GeoJSON')\n",
    "print(f\"IRIS GeoJSON: {len(iris_geo_paris)} IRIS zones in Paris saved\")\n",
    "print(f\"Columns: {list(iris_geo_paris.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4xgrequ31u",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION - IRIS GEOJSON\n",
      "============================================================\n",
      "Number of IRIS zones: 992\n",
      "Number of rows: 992\n",
      "Number of columns: 10\n",
      "Columns: ['dep', 'insee_com', 'nom_com', 'iris', 'code_iris', 'nom_iris', 'typ_iris', 'geo_point_2d', 'id', 'geometry']\n",
      "\n",
      "CRS (Coordinate Reference System): EPSG:4326\n",
      "Geometry type: ['Polygon' 'MultiPolygon']\n",
      "\n",
      "Sample IRIS codes:\n",
      "['751072601', '751072603', '751093605', '751114108', '751114404', '751186903', '751208022', '751156099', '751072705', '751072804']\n",
      "\n",
      "IRIS type distribution:\n",
      "typ_iris\n",
      "H    861\n",
      "A     88\n",
      "D     43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "dep               object\n",
      "insee_com          int32\n",
      "nom_com           object\n",
      "iris              object\n",
      "code_iris         object\n",
      "nom_iris          object\n",
      "typ_iris          object\n",
      "geo_point_2d      object\n",
      "id                object\n",
      "geometry        geometry\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "dep             0\n",
      "insee_com       0\n",
      "nom_com         0\n",
      "iris            0\n",
      "code_iris       0\n",
      "nom_iris        0\n",
      "typ_iris        0\n",
      "geo_point_2d    0\n",
      "id              0\n",
      "geometry        0\n",
      "dtype: int64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify IRIS GeoJSON data\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION - IRIS GEOJSON\")\n",
    "print(\"=\" * 60)\n",
    "loaded_iris_geo = gpd.read_file(datasets_dir / 'iris_paris.geojson')\n",
    "print(f\"Number of IRIS zones: {len(loaded_iris_geo)}\")\n",
    "print(f\"Number of rows: {len(loaded_iris_geo)}\")\n",
    "print(f\"Number of columns: {len(loaded_iris_geo.columns)}\")\n",
    "print(f\"Columns: {list(loaded_iris_geo.columns)}\")\n",
    "print(f\"\\nCRS (Coordinate Reference System): {loaded_iris_geo.crs}\")\n",
    "print(f\"Geometry type: {loaded_iris_geo.geometry.geom_type.unique()}\")\n",
    "print(f\"\\nSample IRIS codes:\")\n",
    "print(loaded_iris_geo['code_iris'].head(10).tolist())\n",
    "print(f\"\\nIRIS type distribution:\")\n",
    "print(loaded_iris_geo['typ_iris'].value_counts())\n",
    "print(f\"\\nData types:\")\n",
    "print(loaded_iris_geo.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(loaded_iris_geo.isnull().sum())\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdhvk4jle5",
   "metadata": {},
   "source": [
    "## 6. Export & Quality Check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a6000",
   "metadata": {},
   "source": [
    "All datasets have been filtered for Paris intra-muros and saved to the `datasets/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ooxw0je35r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASETS LOADED - PARIS INTRA-MUROS ONLY\n",
      "================================================================================\n",
      "\n",
      "RAW DATASETS:\n",
      "----------------------------------------\n",
      "census_2013.xlsx: 67.43 MB\n",
      "census_2017.xlsx: 42.63 MB\n",
      "census_2021.xlsx: 47.39 MB\n",
      "dvf_mutations.gpkg: 341.20 MB\n",
      "education_2013.xlsx: 35.34 MB\n",
      "education_2017.xlsx: 25.23 MB\n",
      "education_2021.xlsx: 27.81 MB\n",
      "filosofi_2013.xlsx: 4.81 MB\n",
      "filosofi_2017.xlsx: 2.63 MB\n",
      "filosofi_2021.xlsx: 2.69 MB\n",
      "iris.geojson: 11.11 MB\n",
      "\n",
      "PROCESSED DATASETS:\n",
      "----------------------------------------\n",
      "census_2013_paris.parquet: 0.11 MB\n",
      "census_2017_paris.parquet: 0.11 MB\n",
      "census_2021_paris.parquet: 0.11 MB\n",
      "dvf_mutations_paris.parquet: 109.86 MB\n",
      "education_2013_paris.parquet: 0.02 MB\n",
      "education_2017_paris.parquet: 0.04 MB\n",
      "education_2021_paris.parquet: 0.04 MB\n",
      "filosofi_2013_paris.parquet: 0.02 MB\n",
      "filosofi_2017_paris.parquet: 0.02 MB\n",
      "filosofi_2021_paris.parquet: 0.02 MB\n",
      "iris_paris.geojson: 0.88 MB\n",
      "neighborhoods_paris.geojson: 0.18 MB\n",
      "neighborhoods_paris_geo.parquet: 0.06 MB\n",
      "paris_merged_2013.parquet: 0.03 MB\n",
      "paris_merged_2017.parquet: 0.03 MB\n",
      "paris_merged_2021.parquet: 0.03 MB\n",
      "paris_merged_all_years.parquet: 0.05 MB\n",
      "\n",
      "================================================================================\n",
      "DATA LOADING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Datasets summary:\n",
      "- 3 FILOSOFI datasets (2013, 2017, 2021) - Income data\n",
      "- 3 EDUCATION datasets (2013, 2017, 2021) - Higher education (Bac+3/4)\n",
      "- 3 CENSUS datasets (2013, 2017, 2021) - Population data\n",
      "- DVF Mutations - Real estate transactions\n",
      "- IRIS GeoJSON - Geographic boundaries for Paris IRIS zones\n",
      "\n",
      "Raw data saved in '../raw_datasets/' folder\n",
      "Processed data saved in '../datasets/' folder - all filtered for Paris only.\n"
     ]
    }
   ],
   "source": [
    "# Summary of all loaded datasets\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASETS LOADED - PARIS INTRA-MUROS ONLY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nRAW DATASETS:\")\n",
    "print(\"-\" * 40)\n",
    "raw_files = sorted(os.listdir(raw_datasets_dir))\n",
    "for file in raw_files:\n",
    "    file_path = raw_datasets_dir / file\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"{file}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\nPROCESSED DATASETS:\")\n",
    "print(\"-\" * 40)\n",
    "datasets_files = sorted(os.listdir(datasets_dir))\n",
    "for file in datasets_files:\n",
    "    file_path = datasets_dir / file\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"{file}: {size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA LOADING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDatasets summary:\")\n",
    "print(\"- 3 FILOSOFI datasets (2013, 2017, 2021) - Income data\")\n",
    "print(\"- 3 EDUCATION datasets (2013, 2017, 2021) - Higher education (Bac+3/4)\")\n",
    "print(\"- 3 CENSUS datasets (2013, 2017, 2021) - Population data\")\n",
    "print(\"- DVF Mutations - Real estate transactions\")\n",
    "print(\"- IRIS GeoJSON - Geographic boundaries for Paris IRIS zones\")\n",
    "print(f\"\\nRaw data saved in '{raw_datasets_dir}/' folder\")\n",
    "print(f\"Processed data saved in '{datasets_dir}/' folder - all filtered for Paris only.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
